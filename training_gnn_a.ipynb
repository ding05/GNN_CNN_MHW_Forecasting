{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02/11 GNN SODA A.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing SODA and Training GNNs\n",
        "\n",
        "by Ding"
      ],
      "metadata": {
        "id": "mzcaDeWwDnML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preprocessing"
      ],
      "metadata": {
        "id": "lF14MaayDoVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas\n",
        "\n",
        "import numpy as np\n",
        "from netCDF4 import Dataset\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from geopandas import GeoDataFrame\n",
        "from shapely.geometry import Point\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)\n",
        "\n",
        "!cp -a \"/gdrive/MyDrive/soda_331_pt_l5.nc\" \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdzGdalaDtWI",
        "outputId": "3bcc45ad-4ca2-4617-cb6f-746e98a474ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geopandas\n",
            "  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 13.9 MB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.1.post1)\n",
            "Collecting fiona>=1.8\n",
            "  Downloading Fiona-1.8.21-cp37-cp37m-manylinux2014_x86_64.whl (16.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.7 MB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.4.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2018.9)\n",
            "Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.21 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n",
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soda = xr.open_dataset(\"soda_331_pt_l5.nc\", decode_times=False)\n",
        "\n",
        "soda_array = soda.to_array(dim=\"temp\")\n",
        "soda_smaller = soda_array[:,:,:,::5,::5].to_dataset(dim=\"temp\")\n",
        "\n",
        "start_year = 1980\n",
        "end_year = 2009\n",
        "target_year = end_year + +1\n",
        "start_month = (start_year - 1980) * 12\n",
        "end_month = (end_year + 1 - 1980) * 12\n",
        "\n",
        "soda_sst_1980_2009 = np.zeros((end_month-start_month+12,1,66,144)) # Include one more year.\n",
        "soda_sst_1980_2009[:,:,:,:] = soda_smaller.variables[\"temp\"][0:end_month-start_month+12,:,:,:]\n",
        "soda_sst_1980_2009 = np.squeeze(soda_sst_1980_2009, axis=1)\n",
        "print(soda_sst_1980_2009.shape)\n",
        "\n",
        "soda_sst_2010 = np.zeros((12,1,66,144))\n",
        "soda_sst_2010[:,:,:,:] = soda_smaller.variables[\"temp\"][end_month-start_month:end_month-start_month+12,:,:,:]\n",
        "soda_sst_2010 = np.squeeze(soda_sst_2010, axis=1)\n",
        "print(soda_sst_2010.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGUbMZ42LNQe",
        "outputId": "25e5c2ec-4431-46c6-acb8-7f6b99cfc57c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(372, 66, 144)\n",
            "(12, 66, 144)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst_1980_2009_transposed = soda_sst_1980_2009.transpose(1,2,0)\n",
        "soda_sst_1980_2009_flattened = soda_sst_1980_2009_transposed.reshape(soda_sst_1980_2009.shape[1] * soda_sst_1980_2009.shape[2],len(soda_sst_1980_2009))\n",
        "print(soda_sst_1980_2009_flattened.shape)\n",
        "\n",
        "soda_sst_2010_transposed = soda_sst_2010.transpose(1,2,0)\n",
        "soda_sst_2010_flattened = soda_sst_2010_transposed.reshape(soda_sst_2010.shape[1] * soda_sst_2010.shape[2],len(soda_sst_2010))\n",
        "print(soda_sst_2010_flattened.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo4HSa6jNKww",
        "outputId": "769581fe-6316-4815-9540-43a0492b3901"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9504, 372)\n",
            "(9504, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dropna(arr, *args, **kwarg):\n",
        "    assert isinstance(arr, np.ndarray)\n",
        "    dropped=pd.DataFrame(arr).dropna(*args, **kwarg).values\n",
        "    if arr.ndim==1:\n",
        "        dropped=dropped.flatten()\n",
        "    return dropped\n",
        "\n",
        "soda_sst_ocean_1980_2009_flattened = dropna(soda_sst_1980_2009_flattened)\n",
        "print(soda_sst_ocean_1980_2009_flattened.shape)\n",
        "\n",
        "soda_sst_ocean_2010_flattened = dropna(soda_sst_2010_flattened)\n",
        "print(soda_sst_ocean_2010_flattened.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7mbHccmR6ad",
        "outputId": "42043c3e-de50-4cee-a5f4-4185d9e1f1a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6924, 372)\n",
            "(6924, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_month = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
        "#target_month = [\"Jan\"]\n",
        "\n",
        "soda_sst_ocean_1980_2009_flattened_all = []\n",
        "soda_sst_ocean_2010_mhw_all = []\n",
        "\n",
        "for month in target_month:\n",
        "\n",
        "  index = target_month.index(month)\n",
        "  soda_sst_ocean_1980_2009_flattened_all.append(soda_sst_ocean_1980_2009_flattened[:,index:(index+soda_sst_ocean_1980_2009_flattened.shape[1]-12)])\n",
        "\n",
        "  soda_sst_ocean_2010_mhw = []\n",
        "  for row in range(len(soda_sst_ocean_1980_2009_flattened)):\n",
        "    sst_node = soda_sst_ocean_1980_2009_flattened[row][index::12]\n",
        "    #print(np.mean(sst_node))\n",
        "    if soda_sst_ocean_2010_flattened[row][index] > sorted(sst_node)[-4]:\n",
        "      soda_sst_ocean_2010_mhw.append(1)\n",
        "    else:\n",
        "      soda_sst_ocean_2010_mhw.append(0)\n",
        "  \n",
        "  print(month, target_year, \":\", soda_sst_ocean_2010_mhw.count(1), \"MHW\")\n",
        "  print(month, target_year, \":\", soda_sst_ocean_2010_mhw.count(0), \"no MHW\")\n",
        "  print()\n",
        "\n",
        "  soda_sst_ocean_2010_mhw = np.array(soda_sst_ocean_2010_mhw)\n",
        "  soda_sst_ocean_2010_mhw_all.append(soda_sst_ocean_2010_mhw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr1xOR6poSbL",
        "outputId": "4a46872d-cf2e-4bb6-8bcb-1912df6aff5d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jan 2010 : 1318 MHW\n",
            "Jan 2010 : 5606 no MHW\n",
            "\n",
            "Feb 2010 : 1427 MHW\n",
            "Feb 2010 : 5497 no MHW\n",
            "\n",
            "Mar 2010 : 1542 MHW\n",
            "Mar 2010 : 5382 no MHW\n",
            "\n",
            "Apr 2010 : 1440 MHW\n",
            "Apr 2010 : 5484 no MHW\n",
            "\n",
            "May 2010 : 1370 MHW\n",
            "May 2010 : 5554 no MHW\n",
            "\n",
            "Jun 2010 : 1363 MHW\n",
            "Jun 2010 : 5561 no MHW\n",
            "\n",
            "Jul 2010 : 1283 MHW\n",
            "Jul 2010 : 5641 no MHW\n",
            "\n",
            "Aug 2010 : 1444 MHW\n",
            "Aug 2010 : 5480 no MHW\n",
            "\n",
            "Sep 2010 : 1413 MHW\n",
            "Sep 2010 : 5511 no MHW\n",
            "\n",
            "Oct 2010 : 1368 MHW\n",
            "Oct 2010 : 5556 no MHW\n",
            "\n",
            "Nov 2010 : 1251 MHW\n",
            "Nov 2010 : 5673 no MHW\n",
            "\n",
            "Dec 2010 : 1367 MHW\n",
            "Dec 2010 : 5557 no MHW\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lons, lats = np.meshgrid(soda_smaller.longitude.values, soda_smaller.latitude.values)\n",
        "\n",
        "soda_time_1 = soda_smaller.temp.isel(depth=0,time=240)\n",
        "soda_time_1_lons, soda_time_1_lats = np.meshgrid(soda_time_1.longitude.values, soda_time_1.latitude.values)\n",
        "soda_masked = soda_time_1.where(abs(soda_time_1_lons) + abs(soda_time_1_lats) > 0)\n",
        "\n",
        "soda_masked.values.flatten()[soda_masked.notnull().values.flatten()]\n",
        "\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "\n",
        "lons_ocean = soda_time_1_lons.flatten()[soda_masked.notnull().values.flatten()]\n",
        "lons_ocean = lons_ocean[::]\n",
        "lats_ocean = soda_time_1_lats.flatten()[soda_masked.notnull().values.flatten()]\n",
        "lats_ocean = lats_ocean[::]\n",
        "\n",
        "lons_ocean *= np.pi/180\n",
        "lats_ocean *= np.pi/180\n",
        "\n",
        "points_ocean = np.concatenate([np.expand_dims(lats_ocean.flatten(),-1), np.expand_dims(lons_ocean.flatten(),-1)],-1)\n",
        "\n",
        "distance_ocean = 6371*haversine_distances(points_ocean)\n",
        "\n",
        "distance_ocean_diag = distance_ocean\n",
        "distance_ocean_diag[distance_ocean_diag==0] = 1\n",
        "\n",
        "distance_ocean_recip = np.reciprocal(distance_ocean_diag)\n",
        "\n",
        "distance_ocean_recip.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8K8AXQwly2F",
        "outputId": "ff22be48-74fb-470e-821d-6c486d0bb2bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6924, 6924)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_matrix = distance_ocean_recip\n",
        "\n",
        "w = []\n",
        "\n",
        "for i in range(distance_ocean_recip.shape[0]):\n",
        "  for j in range(distance_ocean_recip.shape[1]):\n",
        "    if i != j:\n",
        "      w.append(distance_ocean_recip[i][j])"
      ],
      "metadata": {
        "id": "v3OsJt4omDGE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. GNN"
      ],
      "metadata": {
        "id": "vHV3fKk0ttuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl -f https://data.dgl.ai/wheels/repo.html\n",
        "\n",
        "import random\n",
        "\n",
        "import torch\n",
        "\n",
        "import dgl\n",
        "import dgl.nn as dglnn\n",
        "import dgl.data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOvjjT3gud5H",
        "outputId": "28515f39-8d46-49d2-8900-ed2f72176770"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/dgl-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.1 MB 368 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dgl) (4.62.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.8.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_num = len(soda_sst_ocean_1980_2009_flattened_all[index])\n",
        "\n",
        "def graph_structure():\n",
        "  u = []\n",
        "  v = []\n",
        "  for i in range(node_num):\n",
        "    for j in range(node_num):\n",
        "      if j == i:\n",
        "        pass\n",
        "      else:\n",
        "        u.append(i)\n",
        "        v.append(j)\n",
        "  return torch.tensor(u), torch.tensor(v)\n",
        "  \n",
        "u, v = graph_structure()\n",
        "graph = dgl.graph((u, v))"
      ],
      "metadata": {
        "id": "o-Z4FC2HyZow"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.tensor(w)"
      ],
      "metadata": {
        "id": "2f1bO-d1tnWE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(a, n):\n",
        "    k, m = divmod(len(a), n)\n",
        "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))"
      ],
      "metadata": {
        "id": "6MEOgzyh0GfG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.SAGEConv(\n",
        "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
        "        self.conv2 = dglnn.SAGEConv(\n",
        "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        # Inputs are features of nodes.\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = torch.tanh(h) # sigmoid(h), relu(h)\n",
        "        h = self.conv2(graph, h)\n",
        "        return h\n",
        "\n",
        "def evaluate(model, graph, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(graph, features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        _, indices = torch.max(logits, dim=1)\n",
        "        #print(\"Validation / test observed class:\", labels.tolist(), \"| predicted class:\", indices.tolist())\n",
        "        #correct = torch.sum(indices == labels)\n",
        "        combine = indices + labels\n",
        "        accuracy = torch.sum(indices == labels).item() * 1.0 / len(labels)\n",
        "        precision = (torch.sum(combine == 2).item() * 1.0) / (torch.sum(labels == 1).item() * 1.0)\n",
        "\n",
        "        tp = (torch.sum(combine == 2).item() * 1.0)\n",
        "        fp = (torch.sum(labels == 1).item() * 1.0) - (torch.sum(combine == 2).item() * 1.0)\n",
        "        tn = (torch.sum(combine == 0).item() * 1.0)\n",
        "        fn = (torch.sum(indices == 1).item() * 1.0) - (torch.sum(combine == 2).item() * 1.0)\n",
        "        kappa = (2 * (tp * tn - fn * fp)) / ((tp + fp) * (fp + tn) + (tp + fn) * (fn + tn))\n",
        "\n",
        "        return accuracy, precision, kappa"
      ],
      "metadata": {
        "id": "RRWvhmmF2VHB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = []\n",
        "\n",
        "for month in target_month:\n",
        "  \n",
        "  print(\"--------------------\")\n",
        "  print(\"Start training for\", month, \".\")\n",
        "  print()\n",
        "\n",
        "  index = target_month.index(month)\n",
        "  node_num = len(soda_sst_ocean_1980_2009_flattened_all[index])\n",
        "\n",
        "  node_feature = torch.tensor(soda_sst_ocean_1980_2009_flattened_all[index])\n",
        "  node_class = torch.tensor(soda_sst_ocean_2010_mhw_all[index])\n",
        "\n",
        "  graph.ndata[\"feat\"] = node_feature\n",
        "  graph.ndata[\"label\"] = node_class\n",
        "\n",
        "  graph.edata['w'] = weights\n",
        "\n",
        "  def masks():\n",
        "    train = [True] * node_num\n",
        "    val = [False] * node_num\n",
        "    test = [False] * node_num\n",
        "    randomlist = []\n",
        "    for i in range(0, round(node_num * 0.3)):\n",
        "      n = random.randint(0, node_num-1) # Need to substract 1 to be in the list index range.\n",
        "      randomlist.append(n)\n",
        "    #print(randomlist)\n",
        "    randomlist_split = list(split(randomlist, 3))\n",
        "    for i in randomlist_split[0]:\n",
        "      val[i] = True\n",
        "    for i in randomlist_split[1]:\n",
        "      test[i] = True\n",
        "    for i in randomlist_split[2]:\n",
        "      test[i] = True\n",
        "    for i in randomlist:\n",
        "      train[i] = False\n",
        "    #print(\"Training mask:\")\n",
        "    #print(train)\n",
        "    return torch.tensor(train), torch.tensor(val), torch.tensor(test)\n",
        "\n",
        "  graph.ndata[\"train_mask\"], graph.ndata[\"val_mask\"], graph.ndata[\"test_mask\"] = masks()\n",
        "  #print(graph.ndata)\n",
        "\n",
        "  node_features = graph.ndata['feat']\n",
        "  node_labels = graph.ndata['label']\n",
        "  train_mask = graph.ndata['train_mask']\n",
        "  valid_mask = graph.ndata['val_mask']\n",
        "  test_mask = graph.ndata['test_mask']\n",
        "  n_features = node_features.shape[1]\n",
        "  n_labels = int(node_labels.max().item() + 1)\n",
        "\n",
        "  model = SAGE(in_feats=n_features, hid_feats=200, out_feats=n_labels)\n",
        "  #opt = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "  opt = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.99)\n",
        "\n",
        "  for epoch in range(5):\n",
        "      print(\"Epoch:\", epoch+1)\n",
        "      model.train()\n",
        "      # Forward propagation by using all nodes\n",
        "      logits = model(graph, node_features.float())\n",
        "      # Compute loss.\n",
        "      loss = F.cross_entropy(logits[train_mask], node_labels[train_mask])\n",
        "      # Compute validation accuracy.\n",
        "      acc, pre, kappa = evaluate(model, graph, node_features.float(), node_labels, valid_mask)\n",
        "      # Backward propagation\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      print(\"Training loss: %.4f\" % loss.item(), \"| validation accuracy: %.4f\" % acc, \"| validation precision: %.4f\" % pre, \"| test kappa statistics: %.4f\" % kappa)\n",
        "      print()\n",
        "\n",
        "  print(\"----------\")\n",
        "  test_acc, test_pre, test_kappa = evaluate(model, graph, node_features.float(), node_labels, test_mask)\n",
        "  print(\"Test accuracy: %.4f\" % test_acc, \"| test precision: %.4f\" % test_pre, \"| test kappa statistics: %.4f\" % test_kappa)\n",
        "  \n",
        "  test_results.append([test_acc, test_pre])\n",
        "  print(\"The test results for\", month, \"have been appended.\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwUfkbrvttSw",
        "outputId": "750e6f5a-acc0-43cb-eb9c-53a09b46fcd8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "Start training for Jan .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.9768 | validation accuracy: 0.5372 | validation precision: 0.2960 | test kappa statistics: -0.0791\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.9086 | validation accuracy: 0.5402 | validation precision: 0.2400 | test kappa statistics: -0.1111\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.8267 | validation accuracy: 0.5721 | validation precision: 0.2160 | test kappa statistics: -0.1018\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.7572 | validation accuracy: 0.6161 | validation precision: 0.2000 | test kappa statistics: -0.0744\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.6983 | validation accuracy: 0.6616 | validation precision: 0.1760 | test kappa statistics: -0.0463\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.7750 | test precision: 0.0391 | test kappa statistics: -0.0317\n",
            "The test results for Jan have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for Feb .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 1.6513 | validation accuracy: 0.1918 | validation precision: 0.9918 | test kappa statistics: 0.0011\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 1.0797 | validation accuracy: 0.3097 | validation precision: 0.6803 | test kappa statistics: -0.0426\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.6836 | validation accuracy: 0.6284 | validation precision: 0.1803 | test kappa statistics: -0.0786\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.6195 | validation accuracy: 0.7749 | validation precision: 0.0082 | test kappa statistics: -0.0619\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.6346 | validation accuracy: 0.8066 | validation precision: 0.0000 | test kappa statistics: -0.0176\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.7924 | test precision: 0.0000 | test kappa statistics: 0.0000\n",
            "The test results for Feb have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for Mar .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.8928 | validation accuracy: 0.3912 | validation precision: 0.6538 | test kappa statistics: -0.0224\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.7933 | validation accuracy: 0.4932 | validation precision: 0.3269 | test kappa statistics: -0.1008\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.6902 | validation accuracy: 0.6210 | validation precision: 0.0962 | test kappa statistics: -0.1288\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.6429 | validation accuracy: 0.6423 | validation precision: 0.0705 | test kappa statistics: -0.1242\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.6160 | validation accuracy: 0.6712 | validation precision: 0.0577 | test kappa statistics: -0.0967\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.6913 | test precision: 0.0404 | test kappa statistics: -0.0879\n",
            "The test results for Mar have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for Apr .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 4.2846 | validation accuracy: 0.1928 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 3.9637 | validation accuracy: 0.1928 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 3.4297 | validation accuracy: 0.1928 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 2.8528 | validation accuracy: 0.1928 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 2.2298 | validation accuracy: 0.1928 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.3044 | test precision: 0.8000 | test kappa statistics: -0.0110\n",
            "The test results for Apr have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for May .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.8702 | validation accuracy: 0.7906 | validation precision: 0.0075 | test kappa statistics: -0.0060\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.8524 | validation accuracy: 0.7906 | validation precision: 0.0075 | test kappa statistics: -0.0060\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.8276 | validation accuracy: 0.7891 | validation precision: 0.0075 | test kappa statistics: -0.0089\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.8067 | validation accuracy: 0.7876 | validation precision: 0.0075 | test kappa statistics: -0.0118\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.7790 | validation accuracy: 0.7876 | validation precision: 0.0075 | test kappa statistics: -0.0118\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.7912 | test precision: 0.0123 | test kappa statistics: -0.0129\n",
            "The test results for May have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for Jun .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 1.6872 | validation accuracy: 0.2561 | validation precision: 0.9348 | test kappa statistics: 0.0039\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 1.4931 | validation accuracy: 0.2715 | validation precision: 0.9275 | test kappa statistics: 0.0104\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 1.2159 | validation accuracy: 0.3758 | validation precision: 0.8406 | test kappa statistics: 0.0467\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 1.0117 | validation accuracy: 0.3972 | validation precision: 0.8333 | test kappa statistics: 0.0591\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.8647 | validation accuracy: 0.4264 | validation precision: 0.7971 | test kappa statistics: 0.0673\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.5168 | test precision: 0.3462 | test kappa statistics: -0.0656\n",
            "The test results for Jun have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for Jul .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 3.0476 | validation accuracy: 0.2500 | validation precision: 0.9386 | test kappa statistics: 0.0177\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 2.7387 | validation accuracy: 0.3497 | validation precision: 0.4737 | test kappa statistics: -0.0959\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 2.3584 | validation accuracy: 0.3765 | validation precision: 0.3860 | test kappa statistics: -0.1213\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 1.8942 | validation accuracy: 0.4345 | validation precision: 0.2895 | test kappa statistics: -0.1399\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 1.5485 | validation accuracy: 0.4628 | validation precision: 0.2456 | test kappa statistics: -0.1490\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.5257 | test precision: 0.2063 | test kappa statistics: -0.1393\n",
            "The test results for Jul have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for Aug .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 4.2256 | validation accuracy: 0.2145 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 4.0059 | validation accuracy: 0.2145 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 3.5488 | validation accuracy: 0.2145 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 2.9100 | validation accuracy: 0.2145 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 2.2310 | validation accuracy: 0.2326 | validation precision: 0.7676 | test kappa statistics: -0.0684\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.3888 | test precision: 0.4331 | test kappa statistics: -0.1105\n",
            "The test results for Aug have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for Sep .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 3.4898 | validation accuracy: 0.2063 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 3.1006 | validation accuracy: 0.2063 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 2.6234 | validation accuracy: 0.2063 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 2.1654 | validation accuracy: 0.2063 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 1.6908 | validation accuracy: 0.2967 | validation precision: 0.9124 | test kappa statistics: 0.0223\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.4212 | test precision: 0.8158 | test kappa statistics: 0.0713\n",
            "The test results for Sep have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for Oct .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 4.5215 | validation accuracy: 0.2113 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 3.9441 | validation accuracy: 0.2144 | validation precision: 1.0000 | test kappa statistics: 0.0016\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 2.9785 | validation accuracy: 0.2971 | validation precision: 0.9203 | test kappa statistics: 0.0233\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 2.3873 | validation accuracy: 0.3170 | validation precision: 0.8768 | test kappa statistics: 0.0209\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 1.8289 | validation accuracy: 0.3522 | validation precision: 0.8623 | test kappa statistics: 0.0385\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.3830 | test precision: 0.7625 | test kappa statistics: 0.0270\n",
            "The test results for Oct have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for Nov .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 4.6464 | validation accuracy: 0.1847 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 4.4714 | validation accuracy: 0.1847 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 4.1640 | validation accuracy: 0.1847 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 3.7520 | validation accuracy: 0.1847 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 3.2819 | validation accuracy: 0.1847 | validation precision: 1.0000 | test kappa statistics: 0.0000\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.1775 | test precision: 0.9955 | test kappa statistics: -0.0013\n",
            "The test results for Nov have been appended.\n",
            "\n",
            "--------------------\n",
            "Start training for Dec .\n",
            "\n",
            "Epoch: 1\n",
            "Training loss: 0.9509 | validation accuracy: 0.7893 | validation precision: 0.0148 | test kappa statistics: 0.0080\n",
            "\n",
            "Epoch: 2\n",
            "Training loss: 0.8891 | validation accuracy: 0.7863 | validation precision: 0.0148 | test kappa statistics: 0.0021\n",
            "\n",
            "Epoch: 3\n",
            "Training loss: 0.8231 | validation accuracy: 0.7863 | validation precision: 0.0296 | test kappa statistics: 0.0185\n",
            "\n",
            "Epoch: 4\n",
            "Training loss: 0.7948 | validation accuracy: 0.7817 | validation precision: 0.0370 | test kappa statistics: 0.0177\n",
            "\n",
            "Epoch: 5\n",
            "Training loss: 0.7719 | validation accuracy: 0.7802 | validation precision: 0.0370 | test kappa statistics: 0.0148\n",
            "\n",
            "----------\n",
            "Test accuracy: 0.7772 | test precision: 0.0344 | test kappa statistics: 0.0132\n",
            "The test results for Dec have been appended.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for element in test_results:\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6wV6K3D6UTk",
        "outputId": "2488ca30-6e9a-42eb-c102-d0f8ddad4bdd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7749803304484658, 0.0391304347826087]\n",
            "[0.7924071082390953, 0.0]\n",
            "[0.6913385826771653, 0.04040404040404041]\n",
            "[0.3044176706827309, 0.8]\n",
            "[0.7912, 0.012345679012345678]\n",
            "[0.5168, 0.34615384615384615]\n",
            "[0.525691699604743, 0.2062780269058296]\n",
            "[0.388756927949327, 0.4330708661417323]\n",
            "[0.4211802748585287, 0.8157894736842105]\n",
            "[0.38301282051282054, 0.7625]\n",
            "[0.1774580335731415, 0.9954954954954955]\n",
            "[0.7772435897435898, 0.03435114503816794]\n"
          ]
        }
      ]
    }
  ]
}