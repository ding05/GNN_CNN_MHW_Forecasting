{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " 01/20 EDA SODA B.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing SODA and Training GNNs and CNNs\n",
        "\n",
        "(Simplified, without Comments)\n",
        "\n",
        "by Ding"
      ],
      "metadata": {
        "id": "GwcGeA2p_8Qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For exploratory steps and comments, please see [this notebook](https://github.com/ding05/GNN_CNN_MHW_Forecasting_EEs/blob/main/preprocessing_c.ipynb)."
      ],
      "metadata": {
        "id": "qUL-XZwRbfMh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri0AIDMB_7lQ",
        "outputId": "f19f22e4-eee1-44c6-c9ed-c09134ef3896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geopandas\n",
            "  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 256 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 266 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 276 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 317 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 327 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 337 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 348 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 358 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 378 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 399 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 409 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 430 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 440 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 450 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 460 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 471 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 481 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 491 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 501 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 512 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 522 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 532 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 542 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 552 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 563 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 573 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 593 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 604 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 624 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 634 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 645 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 655 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 665 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 675 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 686 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 696 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 706 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 716 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 727 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 737 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 747 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 757 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 768 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 778 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 788 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 798 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 819 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 829 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 839 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 849 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 860 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 870 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 880 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 890 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 901 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 911 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 921 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 931 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 942 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 952 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 962 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 972 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 983 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 993 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n",
            "Collecting pyproj>=2.2.0\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.0)\n",
            "Collecting fiona>=1.8\n",
            "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4 MB 65.9 MB/s \n",
            "\u001b[?25hCollecting click-plugins>=1.0\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.4.0)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
            "Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install geopandas\n",
        "\n",
        "import numpy as np\n",
        "from netCDF4 import Dataset\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from geopandas import GeoDataFrame\n",
        "from shapely.geometry import Point"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thb8N-PXAI78",
        "outputId": "73aab8ec-cfe6-435b-e238-98be46fcf821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cp -a \"/gdrive/MyDrive/soda_331_pt_l5.nc\" \"/content/\"\n",
        "#cp -a \"/gdrive/MyDrive/sst_anomaly.nc\" \"/content/\""
      ],
      "metadata": {
        "id": "C4I6eNAbAcUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soda = xr.open_dataset(\"soda_331_pt_l5.nc\", decode_times=False)\n",
        "soda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "gbTLloZyAg4E",
        "outputId": "ca62e179-eb3e-4b38-b67a-f273d4b7b69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
              "<defs>\n",
              "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
              "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "</symbol>\n",
              "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
              "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "</symbol>\n",
              "</defs>\n",
              "</svg>\n",
              "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
              " *\n",
              " */\n",
              "\n",
              ":root {\n",
              "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
              "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
              "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
              "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
              "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
              "  --xr-background-color: var(--jp-layout-color0, white);\n",
              "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
              "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
              "}\n",
              "\n",
              "html[theme=dark],\n",
              "body.vscode-dark {\n",
              "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
              "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
              "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
              "  --xr-border-color: #1F1F1F;\n",
              "  --xr-disabled-color: #515151;\n",
              "  --xr-background-color: #111111;\n",
              "  --xr-background-color-row-even: #111111;\n",
              "  --xr-background-color-row-odd: #313131;\n",
              "}\n",
              "\n",
              ".xr-wrap {\n",
              "  display: block;\n",
              "  min-width: 300px;\n",
              "  max-width: 700px;\n",
              "}\n",
              "\n",
              ".xr-text-repr-fallback {\n",
              "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-header {\n",
              "  padding-top: 6px;\n",
              "  padding-bottom: 6px;\n",
              "  margin-bottom: 4px;\n",
              "  border-bottom: solid 1px var(--xr-border-color);\n",
              "}\n",
              "\n",
              ".xr-header > div,\n",
              ".xr-header > ul {\n",
              "  display: inline;\n",
              "  margin-top: 0;\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-obj-type,\n",
              ".xr-array-name {\n",
              "  margin-left: 2px;\n",
              "  margin-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-obj-type {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-sections {\n",
              "  padding-left: 0 !important;\n",
              "  display: grid;\n",
              "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
              "}\n",
              "\n",
              ".xr-section-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-section-item input {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-item input + label {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label {\n",
              "  cursor: pointer;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label:hover {\n",
              "  color: var(--xr-font-color0);\n",
              "}\n",
              "\n",
              ".xr-section-summary {\n",
              "  grid-column: 1;\n",
              "  color: var(--xr-font-color2);\n",
              "  font-weight: 500;\n",
              "}\n",
              "\n",
              ".xr-section-summary > span {\n",
              "  display: inline-block;\n",
              "  padding-left: 0.5em;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in + label:before {\n",
              "  display: inline-block;\n",
              "  content: '►';\n",
              "  font-size: 11px;\n",
              "  width: 15px;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label:before {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label:before {\n",
              "  content: '▼';\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label > span {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-summary,\n",
              ".xr-section-inline-details {\n",
              "  padding-top: 4px;\n",
              "  padding-bottom: 4px;\n",
              "}\n",
              "\n",
              ".xr-section-inline-details {\n",
              "  grid-column: 2 / -1;\n",
              "}\n",
              "\n",
              ".xr-section-details {\n",
              "  display: none;\n",
              "  grid-column: 1 / -1;\n",
              "  margin-bottom: 5px;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked ~ .xr-section-details {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-array-wrap {\n",
              "  grid-column: 1 / -1;\n",
              "  display: grid;\n",
              "  grid-template-columns: 20px auto;\n",
              "}\n",
              "\n",
              ".xr-array-wrap > label {\n",
              "  grid-column: 1;\n",
              "  vertical-align: top;\n",
              "}\n",
              "\n",
              ".xr-preview {\n",
              "  color: var(--xr-font-color3);\n",
              "}\n",
              "\n",
              ".xr-array-preview,\n",
              ".xr-array-data {\n",
              "  padding: 0 5px !important;\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-array-data,\n",
              ".xr-array-in:checked ~ .xr-array-preview {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-array-in:checked ~ .xr-array-data,\n",
              ".xr-array-preview {\n",
              "  display: inline-block;\n",
              "}\n",
              "\n",
              ".xr-dim-list {\n",
              "  display: inline-block !important;\n",
              "  list-style: none;\n",
              "  padding: 0 !important;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list li {\n",
              "  display: inline-block;\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list:before {\n",
              "  content: '(';\n",
              "}\n",
              "\n",
              ".xr-dim-list:after {\n",
              "  content: ')';\n",
              "}\n",
              "\n",
              ".xr-dim-list li:not(:last-child):after {\n",
              "  content: ',';\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-has-index {\n",
              "  font-weight: bold;\n",
              "}\n",
              "\n",
              ".xr-var-list,\n",
              ".xr-var-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-var-item > div,\n",
              ".xr-var-item label,\n",
              ".xr-var-item > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-even);\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-var-item > .xr-var-name:hover span {\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-var-list > li:nth-child(odd) > div,\n",
              ".xr-var-list > li:nth-child(odd) > label,\n",
              ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-odd);\n",
              "}\n",
              "\n",
              ".xr-var-name {\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-var-dims {\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-var-dtype {\n",
              "  grid-column: 3;\n",
              "  text-align: right;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-var-preview {\n",
              "  grid-column: 4;\n",
              "}\n",
              "\n",
              ".xr-var-name,\n",
              ".xr-var-dims,\n",
              ".xr-var-dtype,\n",
              ".xr-preview,\n",
              ".xr-attrs dt {\n",
              "  white-space: nowrap;\n",
              "  overflow: hidden;\n",
              "  text-overflow: ellipsis;\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-var-name:hover,\n",
              ".xr-var-dims:hover,\n",
              ".xr-var-dtype:hover,\n",
              ".xr-attrs dt:hover {\n",
              "  overflow: visible;\n",
              "  width: auto;\n",
              "  z-index: 1;\n",
              "}\n",
              "\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  display: none;\n",
              "  background-color: var(--xr-background-color) !important;\n",
              "  padding-bottom: 5px !important;\n",
              "}\n",
              "\n",
              ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
              ".xr-var-data-in:checked ~ .xr-var-data {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              ".xr-var-data > table {\n",
              "  float: right;\n",
              "}\n",
              "\n",
              ".xr-var-name span,\n",
              ".xr-var-data,\n",
              ".xr-attrs {\n",
              "  padding-left: 25px !important;\n",
              "}\n",
              "\n",
              ".xr-attrs,\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  grid-column: 1 / -1;\n",
              "}\n",
              "\n",
              "dl.xr-attrs {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  display: grid;\n",
              "  grid-template-columns: 125px auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt,\n",
              ".xr-attrs dd {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  float: left;\n",
              "  padding-right: 10px;\n",
              "  width: auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt {\n",
              "  font-weight: normal;\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-attrs dt:hover span {\n",
              "  display: inline-block;\n",
              "  background: var(--xr-background-color);\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-attrs dd {\n",
              "  grid-column: 2;\n",
              "  white-space: pre-wrap;\n",
              "  word-break: break-all;\n",
              "}\n",
              "\n",
              ".xr-icon-database,\n",
              ".xr-icon-file-text2 {\n",
              "  display: inline-block;\n",
              "  vertical-align: middle;\n",
              "  width: 1em;\n",
              "  height: 1.5em !important;\n",
              "  stroke-width: 0;\n",
              "  stroke: currentColor;\n",
              "  fill: currentColor;\n",
              "}\n",
              "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
              "Dimensions:    (depth: 1, latitude: 330, longitude: 720, time: 432)\n",
              "Coordinates:\n",
              "  * time       (time) float64 3.168e+08 3.195e+08 ... 1.448e+09 1.45e+09\n",
              "  * depth      (depth) float32 5.034\n",
              "  * latitude   (latitude) float32 -74.75 -74.25 -73.75 ... 88.75 89.25 89.75\n",
              "  * longitude  (longitude) float32 0.25 0.75 1.25 1.75 ... 358.8 359.2 359.8\n",
              "Data variables:\n",
              "    temp       (time, depth, latitude, longitude) float32 ...\n",
              "Attributes: (12/47)\n",
              "    _CoordSysBuilder:              ucar.nc2.internal.dataset.conv.DefaultConv...\n",
              "    acknowledgement:               The SODA3 project is funded by the US Nati...\n",
              "    cdm_data_type:                 Grid\n",
              "    Conventions:                   COARDS, CF-1.6, ACDD-1.3\n",
              "    Created_by:                    Gennady Chepurin and Ligang Chen\n",
              "    creation_date:                 October, 2016\n",
              "    ...                            ...\n",
              "    summary:                       SODA3.3.1 ocean state, forced by MERRA2. T...\n",
              "    time_coverage_end:             2015-12-16T00:00:00Z\n",
              "    time_coverage_start:           1980-01-16T00:00:00Z\n",
              "    title:                         SODA 3.3.1 Ocean State, 1/2°, Global, 1980...\n",
              "    Website:                       https://www.atmos.umd.edu/~ocean/\n",
              "    Westernmost_Easting:           0.25</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-9db3aa7b-99a1-40ca-a1a3-a344af73f0cb' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-9db3aa7b-99a1-40ca-a1a3-a344af73f0cb' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>depth</span>: 1</li><li><span class='xr-has-index'>latitude</span>: 330</li><li><span class='xr-has-index'>longitude</span>: 720</li><li><span class='xr-has-index'>time</span>: 432</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-1dc7b2ba-fc9c-42f6-a32c-035a7d716b39' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1dc7b2ba-fc9c-42f6-a32c-035a7d716b39' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>3.168e+08 3.195e+08 ... 1.45e+09</div><input id='attrs-a248da61-e075-4e6a-a360-a68e6c79a055' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a248da61-e075-4e6a-a360-a68e6c79a055' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9939fe7e-b9f3-4edb-a74a-48b4d95392b1' class='xr-var-data-in' type='checkbox'><label for='data-9939fe7e-b9f3-4edb-a74a-48b4d95392b1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Time</dd><dt><span>actual_range :</span></dt><dd>[3.168288e+08 1.450224e+09]</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>ioos_category :</span></dt><dd>Time</dd><dt><span>long_name :</span></dt><dd>Time</dd><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>time_origin :</span></dt><dd>01-JAN-1970 00:00:00</dd><dt><span>units :</span></dt><dd>seconds since 1970-01-01T00:00:00Z</dd></dl></div><div class='xr-var-data'><pre>array([3.168288e+08, 3.195072e+08, 3.220128e+08, ..., 1.444954e+09,\n",
              "       1.447632e+09, 1.450224e+09])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>depth</span></div><div class='xr-var-dims'>(depth)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>5.034</div><input id='attrs-837ecc1b-616b-41fc-98a8-8d2f1fb26019' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-837ecc1b-616b-41fc-98a8-8d2f1fb26019' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1fa1592f-7f6a-4614-98ef-7c608cc9a917' class='xr-var-data-in' type='checkbox'><label for='data-1fa1592f-7f6a-4614-98ef-7c608cc9a917' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Height</dd><dt><span>_CoordinateZisPositive :</span></dt><dd>down</dd><dt><span>actual_range :</span></dt><dd>[5.03355 5.03355]</dd><dt><span>axis :</span></dt><dd>Z</dd><dt><span>ioos_category :</span></dt><dd>Location</dd><dt><span>long_name :</span></dt><dd>Depth</dd><dt><span>positive :</span></dt><dd>down</dd><dt><span>standard_name :</span></dt><dd>depth</dd><dt><span>units :</span></dt><dd>m</dd></dl></div><div class='xr-var-data'><pre>array([5.03355], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-74.75 -74.25 ... 89.25 89.75</div><input id='attrs-2be22eec-4725-4495-9061-7e24885588c9' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2be22eec-4725-4495-9061-7e24885588c9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-68537a31-6afe-4340-b7ea-f44af31ffd5f' class='xr-var-data-in' type='checkbox'><label for='data-68537a31-6afe-4340-b7ea-f44af31ffd5f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Lat</dd><dt><span>actual_range :</span></dt><dd>[-74.75  89.75]</dd><dt><span>axis :</span></dt><dd>Y</dd><dt><span>ioos_category :</span></dt><dd>Location</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd></dl></div><div class='xr-var-data'><pre>array([-74.75, -74.25, -73.75, ...,  88.75,  89.25,  89.75], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.25 0.75 1.25 ... 359.2 359.8</div><input id='attrs-5e7ec099-561f-451c-9e0e-c35ba5405268' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-5e7ec099-561f-451c-9e0e-c35ba5405268' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a81e8c8e-11dd-426e-830e-11c77b7a4df0' class='xr-var-data-in' type='checkbox'><label for='data-a81e8c8e-11dd-426e-830e-11c77b7a4df0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Lon</dd><dt><span>actual_range :</span></dt><dd>[2.5000e-01 3.5975e+02]</dd><dt><span>axis :</span></dt><dd>X</dd><dt><span>ioos_category :</span></dt><dd>Location</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>modulo :</span></dt><dd>360.0</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd></dl></div><div class='xr-var-data'><pre>array([2.5000e-01, 7.5000e-01, 1.2500e+00, ..., 3.5875e+02, 3.5925e+02,\n",
              "       3.5975e+02], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f7fa4ff2-f5f2-4dba-ad32-2c1b8c5c0840' class='xr-section-summary-in' type='checkbox'  checked><label for='section-f7fa4ff2-f5f2-4dba-ad32-2c1b8c5c0840' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>temp</span></div><div class='xr-var-dims'>(time, depth, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-e688ccc2-f28e-4f57-adfe-43658b0da992' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e688ccc2-f28e-4f57-adfe-43658b0da992' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-78dc71ad-3258-4e0b-97f1-f3efd4219461' class='xr-var-data-in' type='checkbox'><label for='data-78dc71ad-3258-4e0b-97f1-f3efd4219461' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>cell_methods :</span></dt><dd>time: mean</dd><dt><span>colorBarMaximum :</span></dt><dd>32.0</dd><dt><span>colorBarMinimum :</span></dt><dd>0.0</dd><dt><span>ioos_category :</span></dt><dd>Temperature</dd><dt><span>long_name :</span></dt><dd>Potential temperature</dd><dt><span>standard_name :</span></dt><dd>sea_water_potential_temperature</dd><dt><span>units :</span></dt><dd>degrees C</dd><dt><span>valid_range :</span></dt><dd>[-10. 500.]</dd></dl></div><div class='xr-var-data'><pre>[102643200 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-39874346-eda1-4f23-8d8c-b54894066571' class='xr-section-summary-in' type='checkbox'  ><label for='section-39874346-eda1-4f23-8d8c-b54894066571' class='xr-section-summary' >Attributes: <span>(47)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>_CoordSysBuilder :</span></dt><dd>ucar.nc2.internal.dataset.conv.DefaultConventions</dd><dt><span>acknowledgement :</span></dt><dd>The SODA3 project is funded by the US National Science Foundation. Please cite: Carton, Chepurin, and Chen (2017)</dd><dt><span>cdm_data_type :</span></dt><dd>Grid</dd><dt><span>Conventions :</span></dt><dd>COARDS, CF-1.6, ACDD-1.3</dd><dt><span>Created_by :</span></dt><dd>Gennady Chepurin and Ligang Chen</dd><dt><span>creation_date :</span></dt><dd>October, 2016</dd><dt><span>creator_email :</span></dt><dd>carton@atmos.umd.edu</dd><dt><span>creator_name :</span></dt><dd>James A. Carton</dd><dt><span>creator_type :</span></dt><dd>person</dd><dt><span>creator_url :</span></dt><dd>https://www.atmos.umd.edu/~ocean/</dd><dt><span>defaultGraphQuery :</span></dt><dd>temp[last][0][0:last][0:last]&amp;.draw=surface&amp;.vars=longitude|latitude|temp</dd><dt><span>Easternmost_Easting :</span></dt><dd>359.75</dd><dt><span>geospatial_lat_max :</span></dt><dd>89.75</dd><dt><span>geospatial_lat_min :</span></dt><dd>-74.75</dd><dt><span>geospatial_lat_resolution :</span></dt><dd>0.5</dd><dt><span>geospatial_lat_units :</span></dt><dd>degrees_north</dd><dt><span>geospatial_lon_max :</span></dt><dd>359.75</dd><dt><span>geospatial_lon_min :</span></dt><dd>0.25</dd><dt><span>geospatial_lon_resolution :</span></dt><dd>0.5</dd><dt><span>geospatial_lon_units :</span></dt><dd>degrees_east</dd><dt><span>geospatial_vertical_max :</span></dt><dd>5.03355</dd><dt><span>geospatial_vertical_min :</span></dt><dd>5.03355</dd><dt><span>geospatial_vertical_positive :</span></dt><dd>down</dd><dt><span>geospatial_vertical_units :</span></dt><dd>m</dd><dt><span>history :</span></dt><dd>2021-11-11T08:12:35Z (local files)\n",
              "2021-11-11T08:12:35Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSoda331oceanmday.nc?temp%5B(1980-01-16):1:(2015-12-16)%5D%5B(5.03355):1:(5.03355)%5D%5B(-74.75):1:(89.75)%5D%5B(0.25):1:(359.75)%5D</dd><dt><span>infoUrl :</span></dt><dd>https://www.atmos.umd.edu/~ocean/</dd><dt><span>institution :</span></dt><dd>University of Maryland</dd><dt><span>keywords :</span></dt><dd>3.3.1, assimilation, circulation, current, currents, data, dbar, density, depth, dia, dia-surface, Earth Science &gt; Oceans &gt; Ocean Circulation &gt; Ocean Currents, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Potential Temperature, Earth Science &gt; Oceans &gt; Salinity/Density &gt; Potential Density, Earth Science &gt; Oceans &gt; Salinity/Density &gt; Salinity, i-current, j-current, latitude, level, longitude, maryland, ocean, points, potential, practical, prho, reanalysis, referenced, salinity, salt, sea, sea_water_potential_density, sea_water_potential_temperature, sea_water_practical_salinity, sea_water_x_velocity, sea_water_y_velocity, seawater, simple, soda, soda3.3.1, state, surface, t-points, temperature, time, u, university, v, velocity, water</dd><dt><span>keywords_vocabulary :</span></dt><dd>GCMD Science Keywords</dd><dt><span>license :</span></dt><dd>The data may be used and redistributed for free but is not intended\n",
              "for legal use, since it may contain inaccuracies. Neither the data\n",
              "Contributor, ERD, NOAA, nor the United States Government, nor any\n",
              "of their employees or contractors, makes any warranty, express or\n",
              "implied, including warranties of merchantability and fitness for a\n",
              "particular purpose, or assumes any legal liability for the accuracy,\n",
              "completeness, or usefulness, of this information.</dd><dt><span>Northernmost_Northing :</span></dt><dd>89.75</dd><dt><span>Principle_investigator :</span></dt><dd>James A. Carton</dd><dt><span>Principle_investigator_email :</span></dt><dd>carton@atmos.umd.edu</dd><dt><span>publisher_email :</span></dt><dd>erd.data@noaa.gov</dd><dt><span>publisher_name :</span></dt><dd>NOAA NMFS SWFSC ERD</dd><dt><span>publisher_type :</span></dt><dd>institution</dd><dt><span>publisher_url :</span></dt><dd>https://www.pfeg.noaa.gov</dd><dt><span>references :</span></dt><dd>Carton, Chepurin, and Chen (2017)</dd><dt><span>sourceUrl :</span></dt><dd>(local files)</dd><dt><span>Southernmost_Northing :</span></dt><dd>-74.75</dd><dt><span>standard_name_vocabulary :</span></dt><dd>CF Standard Name Table v70</dd><dt><span>summary :</span></dt><dd>SODA3.3.1 ocean state, forced by MERRA2. The goal of SODA is to reconstruct the historical physical (and eventually biogeochemical) history of the ocean. As its name implies, the Simple Ocean Data Assimilation ocean/sea ice reanalysis (SODA) uses a simple architecture based on community standard codes with resolution chosen to match available data and the scales of motion that are resolvable. Agreement with direct measurements (to within observational error estimates) as well as unbiased statistics are expected. Please cite: Carton, Chepurin, and Chen (2017).</dd><dt><span>time_coverage_end :</span></dt><dd>2015-12-16T00:00:00Z</dd><dt><span>time_coverage_start :</span></dt><dd>1980-01-16T00:00:00Z</dd><dt><span>title :</span></dt><dd>SODA 3.3.1 Ocean State, 1/2°, Global, 1980-2015, Monthly Composite</dd><dt><span>Website :</span></dt><dd>https://www.atmos.umd.edu/~ocean/</dd><dt><span>Westernmost_Easting :</span></dt><dd>0.25</dd></dl></div></li></ul></div></div>"
            ],
            "text/plain": [
              "<xarray.Dataset>\n",
              "Dimensions:    (depth: 1, latitude: 330, longitude: 720, time: 432)\n",
              "Coordinates:\n",
              "  * time       (time) float64 3.168e+08 3.195e+08 ... 1.448e+09 1.45e+09\n",
              "  * depth      (depth) float32 5.034\n",
              "  * latitude   (latitude) float32 -74.75 -74.25 -73.75 ... 88.75 89.25 89.75\n",
              "  * longitude  (longitude) float32 0.25 0.75 1.25 1.75 ... 358.8 359.2 359.8\n",
              "Data variables:\n",
              "    temp       (time, depth, latitude, longitude) float32 ...\n",
              "Attributes: (12/47)\n",
              "    _CoordSysBuilder:              ucar.nc2.internal.dataset.conv.DefaultConv...\n",
              "    acknowledgement:               The SODA3 project is funded by the US Nati...\n",
              "    cdm_data_type:                 Grid\n",
              "    Conventions:                   COARDS, CF-1.6, ACDD-1.3\n",
              "    Created_by:                    Gennady Chepurin and Ligang Chen\n",
              "    creation_date:                 October, 2016\n",
              "    ...                            ...\n",
              "    summary:                       SODA3.3.1 ocean state, forced by MERRA2. T...\n",
              "    time_coverage_end:             2015-12-16T00:00:00Z\n",
              "    time_coverage_start:           1980-01-16T00:00:00Z\n",
              "    title:                         SODA 3.3.1 Ocean State, 1/2°, Global, 1980...\n",
              "    Website:                       https://www.atmos.umd.edu/~ocean/\n",
              "    Westernmost_Easting:           0.25"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soda_array = soda.to_array(dim=\"temp\")\n",
        "soda_smaller = soda_array[:,:,:,::5,::5].to_dataset(dim=\"temp\")\n",
        "soda_smaller"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "1NZKcmg8Jsm8",
        "outputId": "db280cd9-39fd-47a3-c9c8-22b06073290d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
              "<defs>\n",
              "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
              "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "</symbol>\n",
              "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
              "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "</symbol>\n",
              "</defs>\n",
              "</svg>\n",
              "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
              " *\n",
              " */\n",
              "\n",
              ":root {\n",
              "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
              "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
              "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
              "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
              "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
              "  --xr-background-color: var(--jp-layout-color0, white);\n",
              "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
              "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
              "}\n",
              "\n",
              "html[theme=dark],\n",
              "body.vscode-dark {\n",
              "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
              "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
              "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
              "  --xr-border-color: #1F1F1F;\n",
              "  --xr-disabled-color: #515151;\n",
              "  --xr-background-color: #111111;\n",
              "  --xr-background-color-row-even: #111111;\n",
              "  --xr-background-color-row-odd: #313131;\n",
              "}\n",
              "\n",
              ".xr-wrap {\n",
              "  display: block;\n",
              "  min-width: 300px;\n",
              "  max-width: 700px;\n",
              "}\n",
              "\n",
              ".xr-text-repr-fallback {\n",
              "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-header {\n",
              "  padding-top: 6px;\n",
              "  padding-bottom: 6px;\n",
              "  margin-bottom: 4px;\n",
              "  border-bottom: solid 1px var(--xr-border-color);\n",
              "}\n",
              "\n",
              ".xr-header > div,\n",
              ".xr-header > ul {\n",
              "  display: inline;\n",
              "  margin-top: 0;\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-obj-type,\n",
              ".xr-array-name {\n",
              "  margin-left: 2px;\n",
              "  margin-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-obj-type {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-sections {\n",
              "  padding-left: 0 !important;\n",
              "  display: grid;\n",
              "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
              "}\n",
              "\n",
              ".xr-section-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-section-item input {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-item input + label {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label {\n",
              "  cursor: pointer;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label:hover {\n",
              "  color: var(--xr-font-color0);\n",
              "}\n",
              "\n",
              ".xr-section-summary {\n",
              "  grid-column: 1;\n",
              "  color: var(--xr-font-color2);\n",
              "  font-weight: 500;\n",
              "}\n",
              "\n",
              ".xr-section-summary > span {\n",
              "  display: inline-block;\n",
              "  padding-left: 0.5em;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in + label:before {\n",
              "  display: inline-block;\n",
              "  content: '►';\n",
              "  font-size: 11px;\n",
              "  width: 15px;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label:before {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label:before {\n",
              "  content: '▼';\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label > span {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-summary,\n",
              ".xr-section-inline-details {\n",
              "  padding-top: 4px;\n",
              "  padding-bottom: 4px;\n",
              "}\n",
              "\n",
              ".xr-section-inline-details {\n",
              "  grid-column: 2 / -1;\n",
              "}\n",
              "\n",
              ".xr-section-details {\n",
              "  display: none;\n",
              "  grid-column: 1 / -1;\n",
              "  margin-bottom: 5px;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked ~ .xr-section-details {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-array-wrap {\n",
              "  grid-column: 1 / -1;\n",
              "  display: grid;\n",
              "  grid-template-columns: 20px auto;\n",
              "}\n",
              "\n",
              ".xr-array-wrap > label {\n",
              "  grid-column: 1;\n",
              "  vertical-align: top;\n",
              "}\n",
              "\n",
              ".xr-preview {\n",
              "  color: var(--xr-font-color3);\n",
              "}\n",
              "\n",
              ".xr-array-preview,\n",
              ".xr-array-data {\n",
              "  padding: 0 5px !important;\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-array-data,\n",
              ".xr-array-in:checked ~ .xr-array-preview {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-array-in:checked ~ .xr-array-data,\n",
              ".xr-array-preview {\n",
              "  display: inline-block;\n",
              "}\n",
              "\n",
              ".xr-dim-list {\n",
              "  display: inline-block !important;\n",
              "  list-style: none;\n",
              "  padding: 0 !important;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list li {\n",
              "  display: inline-block;\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list:before {\n",
              "  content: '(';\n",
              "}\n",
              "\n",
              ".xr-dim-list:after {\n",
              "  content: ')';\n",
              "}\n",
              "\n",
              ".xr-dim-list li:not(:last-child):after {\n",
              "  content: ',';\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-has-index {\n",
              "  font-weight: bold;\n",
              "}\n",
              "\n",
              ".xr-var-list,\n",
              ".xr-var-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-var-item > div,\n",
              ".xr-var-item label,\n",
              ".xr-var-item > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-even);\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-var-item > .xr-var-name:hover span {\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-var-list > li:nth-child(odd) > div,\n",
              ".xr-var-list > li:nth-child(odd) > label,\n",
              ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-odd);\n",
              "}\n",
              "\n",
              ".xr-var-name {\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-var-dims {\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-var-dtype {\n",
              "  grid-column: 3;\n",
              "  text-align: right;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-var-preview {\n",
              "  grid-column: 4;\n",
              "}\n",
              "\n",
              ".xr-var-name,\n",
              ".xr-var-dims,\n",
              ".xr-var-dtype,\n",
              ".xr-preview,\n",
              ".xr-attrs dt {\n",
              "  white-space: nowrap;\n",
              "  overflow: hidden;\n",
              "  text-overflow: ellipsis;\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-var-name:hover,\n",
              ".xr-var-dims:hover,\n",
              ".xr-var-dtype:hover,\n",
              ".xr-attrs dt:hover {\n",
              "  overflow: visible;\n",
              "  width: auto;\n",
              "  z-index: 1;\n",
              "}\n",
              "\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  display: none;\n",
              "  background-color: var(--xr-background-color) !important;\n",
              "  padding-bottom: 5px !important;\n",
              "}\n",
              "\n",
              ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
              ".xr-var-data-in:checked ~ .xr-var-data {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              ".xr-var-data > table {\n",
              "  float: right;\n",
              "}\n",
              "\n",
              ".xr-var-name span,\n",
              ".xr-var-data,\n",
              ".xr-attrs {\n",
              "  padding-left: 25px !important;\n",
              "}\n",
              "\n",
              ".xr-attrs,\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  grid-column: 1 / -1;\n",
              "}\n",
              "\n",
              "dl.xr-attrs {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  display: grid;\n",
              "  grid-template-columns: 125px auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt,\n",
              ".xr-attrs dd {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  float: left;\n",
              "  padding-right: 10px;\n",
              "  width: auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt {\n",
              "  font-weight: normal;\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-attrs dt:hover span {\n",
              "  display: inline-block;\n",
              "  background: var(--xr-background-color);\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-attrs dd {\n",
              "  grid-column: 2;\n",
              "  white-space: pre-wrap;\n",
              "  word-break: break-all;\n",
              "}\n",
              "\n",
              ".xr-icon-database,\n",
              ".xr-icon-file-text2 {\n",
              "  display: inline-block;\n",
              "  vertical-align: middle;\n",
              "  width: 1em;\n",
              "  height: 1.5em !important;\n",
              "  stroke-width: 0;\n",
              "  stroke: currentColor;\n",
              "  fill: currentColor;\n",
              "}\n",
              "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
              "Dimensions:    (depth: 1, latitude: 66, longitude: 144, time: 432)\n",
              "Coordinates:\n",
              "  * time       (time) float64 3.168e+08 3.195e+08 ... 1.448e+09 1.45e+09\n",
              "  * depth      (depth) float32 5.034\n",
              "  * latitude   (latitude) float32 -74.75 -72.25 -69.75 ... 82.75 85.25 87.75\n",
              "  * longitude  (longitude) float32 0.25 2.75 5.25 7.75 ... 352.8 355.2 357.8\n",
              "Data variables:\n",
              "    temp       (time, depth, latitude, longitude) float32 nan nan ... -1.636\n",
              "Attributes: (12/47)\n",
              "    _CoordSysBuilder:              ucar.nc2.internal.dataset.conv.DefaultConv...\n",
              "    acknowledgement:               The SODA3 project is funded by the US Nati...\n",
              "    cdm_data_type:                 Grid\n",
              "    Conventions:                   COARDS, CF-1.6, ACDD-1.3\n",
              "    Created_by:                    Gennady Chepurin and Ligang Chen\n",
              "    creation_date:                 October, 2016\n",
              "    ...                            ...\n",
              "    summary:                       SODA3.3.1 ocean state, forced by MERRA2. T...\n",
              "    time_coverage_end:             2015-12-16T00:00:00Z\n",
              "    time_coverage_start:           1980-01-16T00:00:00Z\n",
              "    title:                         SODA 3.3.1 Ocean State, 1/2°, Global, 1980...\n",
              "    Website:                       https://www.atmos.umd.edu/~ocean/\n",
              "    Westernmost_Easting:           0.25</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-b4d481e0-92b3-4666-a031-7277d417a22c' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-b4d481e0-92b3-4666-a031-7277d417a22c' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>depth</span>: 1</li><li><span class='xr-has-index'>latitude</span>: 66</li><li><span class='xr-has-index'>longitude</span>: 144</li><li><span class='xr-has-index'>time</span>: 432</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-93b2bdbb-0acd-42d4-abf8-898f13274aae' class='xr-section-summary-in' type='checkbox'  checked><label for='section-93b2bdbb-0acd-42d4-abf8-898f13274aae' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>3.168e+08 3.195e+08 ... 1.45e+09</div><input id='attrs-e1643201-6809-45ed-857e-91b47b510766' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e1643201-6809-45ed-857e-91b47b510766' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2e608b86-a285-4400-be86-4fd34420757d' class='xr-var-data-in' type='checkbox'><label for='data-2e608b86-a285-4400-be86-4fd34420757d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Time</dd><dt><span>actual_range :</span></dt><dd>[3.168288e+08 1.450224e+09]</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>ioos_category :</span></dt><dd>Time</dd><dt><span>long_name :</span></dt><dd>Time</dd><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>time_origin :</span></dt><dd>01-JAN-1970 00:00:00</dd><dt><span>units :</span></dt><dd>seconds since 1970-01-01T00:00:00Z</dd></dl></div><div class='xr-var-data'><pre>array([3.168288e+08, 3.195072e+08, 3.220128e+08, ..., 1.444954e+09,\n",
              "       1.447632e+09, 1.450224e+09])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>depth</span></div><div class='xr-var-dims'>(depth)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>5.034</div><input id='attrs-c454a8d0-44d1-4990-860f-261458984244' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c454a8d0-44d1-4990-860f-261458984244' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4da59bdd-7ae2-4df9-899c-74634e2bc17e' class='xr-var-data-in' type='checkbox'><label for='data-4da59bdd-7ae2-4df9-899c-74634e2bc17e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Height</dd><dt><span>_CoordinateZisPositive :</span></dt><dd>down</dd><dt><span>actual_range :</span></dt><dd>[5.03355 5.03355]</dd><dt><span>axis :</span></dt><dd>Z</dd><dt><span>ioos_category :</span></dt><dd>Location</dd><dt><span>long_name :</span></dt><dd>Depth</dd><dt><span>positive :</span></dt><dd>down</dd><dt><span>standard_name :</span></dt><dd>depth</dd><dt><span>units :</span></dt><dd>m</dd></dl></div><div class='xr-var-data'><pre>array([5.03355], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-74.75 -72.25 ... 85.25 87.75</div><input id='attrs-cb8b0b65-2e37-4bf6-8662-4d1186ba415a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-cb8b0b65-2e37-4bf6-8662-4d1186ba415a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-96c410a5-a05e-4d61-aab1-c0a0b4549e43' class='xr-var-data-in' type='checkbox'><label for='data-96c410a5-a05e-4d61-aab1-c0a0b4549e43' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Lat</dd><dt><span>actual_range :</span></dt><dd>[-74.75  89.75]</dd><dt><span>axis :</span></dt><dd>Y</dd><dt><span>ioos_category :</span></dt><dd>Location</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd></dl></div><div class='xr-var-data'><pre>array([-74.75, -72.25, -69.75, -67.25, -64.75, -62.25, -59.75, -57.25, -54.75,\n",
              "       -52.25, -49.75, -47.25, -44.75, -42.25, -39.75, -37.25, -34.75, -32.25,\n",
              "       -29.75, -27.25, -24.75, -22.25, -19.75, -17.25, -14.75, -12.25,  -9.75,\n",
              "        -7.25,  -4.75,  -2.25,   0.25,   2.75,   5.25,   7.75,  10.25,  12.75,\n",
              "        15.25,  17.75,  20.25,  22.75,  25.25,  27.75,  30.25,  32.75,  35.25,\n",
              "        37.75,  40.25,  42.75,  45.25,  47.75,  50.25,  52.75,  55.25,  57.75,\n",
              "        60.25,  62.75,  65.25,  67.75,  70.25,  72.75,  75.25,  77.75,  80.25,\n",
              "        82.75,  85.25,  87.75], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.25 2.75 5.25 ... 355.2 357.8</div><input id='attrs-a1ddff8f-1685-4639-b8d4-d840f8ffb25a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a1ddff8f-1685-4639-b8d4-d840f8ffb25a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-41059bf1-f883-48af-89ed-766f9afde76b' class='xr-var-data-in' type='checkbox'><label for='data-41059bf1-f883-48af-89ed-766f9afde76b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Lon</dd><dt><span>actual_range :</span></dt><dd>[2.5000e-01 3.5975e+02]</dd><dt><span>axis :</span></dt><dd>X</dd><dt><span>ioos_category :</span></dt><dd>Location</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>modulo :</span></dt><dd>360.0</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd></dl></div><div class='xr-var-data'><pre>array([2.5000e-01, 2.7500e+00, 5.2500e+00, 7.7500e+00, 1.0250e+01, 1.2750e+01,\n",
              "       1.5250e+01, 1.7750e+01, 2.0250e+01, 2.2750e+01, 2.5250e+01, 2.7750e+01,\n",
              "       3.0250e+01, 3.2750e+01, 3.5250e+01, 3.7750e+01, 4.0250e+01, 4.2750e+01,\n",
              "       4.5250e+01, 4.7750e+01, 5.0250e+01, 5.2750e+01, 5.5250e+01, 5.7750e+01,\n",
              "       6.0250e+01, 6.2750e+01, 6.5250e+01, 6.7750e+01, 7.0250e+01, 7.2750e+01,\n",
              "       7.5250e+01, 7.7750e+01, 8.0250e+01, 8.2750e+01, 8.5250e+01, 8.7750e+01,\n",
              "       9.0250e+01, 9.2750e+01, 9.5250e+01, 9.7750e+01, 1.0025e+02, 1.0275e+02,\n",
              "       1.0525e+02, 1.0775e+02, 1.1025e+02, 1.1275e+02, 1.1525e+02, 1.1775e+02,\n",
              "       1.2025e+02, 1.2275e+02, 1.2525e+02, 1.2775e+02, 1.3025e+02, 1.3275e+02,\n",
              "       1.3525e+02, 1.3775e+02, 1.4025e+02, 1.4275e+02, 1.4525e+02, 1.4775e+02,\n",
              "       1.5025e+02, 1.5275e+02, 1.5525e+02, 1.5775e+02, 1.6025e+02, 1.6275e+02,\n",
              "       1.6525e+02, 1.6775e+02, 1.7025e+02, 1.7275e+02, 1.7525e+02, 1.7775e+02,\n",
              "       1.8025e+02, 1.8275e+02, 1.8525e+02, 1.8775e+02, 1.9025e+02, 1.9275e+02,\n",
              "       1.9525e+02, 1.9775e+02, 2.0025e+02, 2.0275e+02, 2.0525e+02, 2.0775e+02,\n",
              "       2.1025e+02, 2.1275e+02, 2.1525e+02, 2.1775e+02, 2.2025e+02, 2.2275e+02,\n",
              "       2.2525e+02, 2.2775e+02, 2.3025e+02, 2.3275e+02, 2.3525e+02, 2.3775e+02,\n",
              "       2.4025e+02, 2.4275e+02, 2.4525e+02, 2.4775e+02, 2.5025e+02, 2.5275e+02,\n",
              "       2.5525e+02, 2.5775e+02, 2.6025e+02, 2.6275e+02, 2.6525e+02, 2.6775e+02,\n",
              "       2.7025e+02, 2.7275e+02, 2.7525e+02, 2.7775e+02, 2.8025e+02, 2.8275e+02,\n",
              "       2.8525e+02, 2.8775e+02, 2.9025e+02, 2.9275e+02, 2.9525e+02, 2.9775e+02,\n",
              "       3.0025e+02, 3.0275e+02, 3.0525e+02, 3.0775e+02, 3.1025e+02, 3.1275e+02,\n",
              "       3.1525e+02, 3.1775e+02, 3.2025e+02, 3.2275e+02, 3.2525e+02, 3.2775e+02,\n",
              "       3.3025e+02, 3.3275e+02, 3.3525e+02, 3.3775e+02, 3.4025e+02, 3.4275e+02,\n",
              "       3.4525e+02, 3.4775e+02, 3.5025e+02, 3.5275e+02, 3.5525e+02, 3.5775e+02],\n",
              "      dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-d126001b-9054-4053-bf75-045f903479c1' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d126001b-9054-4053-bf75-045f903479c1' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>temp</span></div><div class='xr-var-dims'>(time, depth, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>nan nan nan ... -1.637 -1.636</div><input id='attrs-fdcd93da-309a-4987-b8d1-ef2821affd34' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-fdcd93da-309a-4987-b8d1-ef2821affd34' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-20600eb6-8848-4c0c-a226-31bc61e99672' class='xr-var-data-in' type='checkbox'><label for='data-20600eb6-8848-4c0c-a226-31bc61e99672' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[[        nan,         nan,         nan, ...,         nan,\n",
              "                  nan,         nan],\n",
              "         [        nan,         nan,         nan, ...,         nan,\n",
              "                  nan,         nan],\n",
              "         [ 0.28955904,  0.34579098,  0.50984013, ..., -0.93544596,\n",
              "          -0.5082726 , -0.03497132],\n",
              "         ...,\n",
              "         [-1.8300331 , -1.8189937 , -1.7242854 , ..., -1.7689496 ,\n",
              "          -1.7463971 , -1.7759693 ],\n",
              "         [-1.8058563 , -1.8087624 , -1.8313749 , ..., -1.7900593 ,\n",
              "          -1.7990079 , -1.8031368 ],\n",
              "         [-1.798486  , -1.8048061 , -1.7968581 , ..., -1.8097764 ,\n",
              "          -1.812069  , -1.807284  ]]],\n",
              "\n",
              "\n",
              "       [[[        nan,         nan,         nan, ...,         nan,\n",
              "                  nan,         nan],\n",
              "         [        nan,         nan,         nan, ...,         nan,\n",
              "                  nan,         nan],\n",
              "         [ 0.23241383,  0.3606001 ,  0.516367  , ..., -1.0015209 ,\n",
              "...\n",
              "          -1.7176938 , -1.7563124 ],\n",
              "         [-1.6760321 , -1.6732434 , -1.6717967 , ..., -1.6373361 ,\n",
              "          -1.6483647 , -1.6711769 ],\n",
              "         [-1.6257565 , -1.6231518 , -1.6213276 , ..., -1.6299335 ,\n",
              "          -1.6282517 , -1.6274574 ]]],\n",
              "\n",
              "\n",
              "       [[[        nan,         nan,         nan, ...,         nan,\n",
              "                  nan,         nan],\n",
              "         [        nan,         nan,         nan, ...,         nan,\n",
              "                  nan,         nan],\n",
              "         [-1.7196294 , -1.7397997 , -1.7422922 , ..., -1.7454606 ,\n",
              "          -1.7532911 , -1.7483433 ],\n",
              "         ...,\n",
              "         [-1.7597408 , -1.7577887 , -1.721458  , ..., -1.7094891 ,\n",
              "          -1.7302477 , -1.7633747 ],\n",
              "         [-1.6603819 , -1.6607248 , -1.6550025 , ..., -1.6539228 ,\n",
              "          -1.6650708 , -1.661588  ],\n",
              "         [-1.6334422 , -1.6308022 , -1.6280283 , ..., -1.6388179 ,\n",
              "          -1.6370755 , -1.6355495 ]]]], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-64400344-c6a4-47db-8667-a222c526a433' class='xr-section-summary-in' type='checkbox'  ><label for='section-64400344-c6a4-47db-8667-a222c526a433' class='xr-section-summary' >Attributes: <span>(47)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>_CoordSysBuilder :</span></dt><dd>ucar.nc2.internal.dataset.conv.DefaultConventions</dd><dt><span>acknowledgement :</span></dt><dd>The SODA3 project is funded by the US National Science Foundation. Please cite: Carton, Chepurin, and Chen (2017)</dd><dt><span>cdm_data_type :</span></dt><dd>Grid</dd><dt><span>Conventions :</span></dt><dd>COARDS, CF-1.6, ACDD-1.3</dd><dt><span>Created_by :</span></dt><dd>Gennady Chepurin and Ligang Chen</dd><dt><span>creation_date :</span></dt><dd>October, 2016</dd><dt><span>creator_email :</span></dt><dd>carton@atmos.umd.edu</dd><dt><span>creator_name :</span></dt><dd>James A. Carton</dd><dt><span>creator_type :</span></dt><dd>person</dd><dt><span>creator_url :</span></dt><dd>https://www.atmos.umd.edu/~ocean/</dd><dt><span>defaultGraphQuery :</span></dt><dd>temp[last][0][0:last][0:last]&amp;.draw=surface&amp;.vars=longitude|latitude|temp</dd><dt><span>Easternmost_Easting :</span></dt><dd>359.75</dd><dt><span>geospatial_lat_max :</span></dt><dd>89.75</dd><dt><span>geospatial_lat_min :</span></dt><dd>-74.75</dd><dt><span>geospatial_lat_resolution :</span></dt><dd>0.5</dd><dt><span>geospatial_lat_units :</span></dt><dd>degrees_north</dd><dt><span>geospatial_lon_max :</span></dt><dd>359.75</dd><dt><span>geospatial_lon_min :</span></dt><dd>0.25</dd><dt><span>geospatial_lon_resolution :</span></dt><dd>0.5</dd><dt><span>geospatial_lon_units :</span></dt><dd>degrees_east</dd><dt><span>geospatial_vertical_max :</span></dt><dd>5.03355</dd><dt><span>geospatial_vertical_min :</span></dt><dd>5.03355</dd><dt><span>geospatial_vertical_positive :</span></dt><dd>down</dd><dt><span>geospatial_vertical_units :</span></dt><dd>m</dd><dt><span>history :</span></dt><dd>2021-11-11T08:12:35Z (local files)\n",
              "2021-11-11T08:12:35Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/erdSoda331oceanmday.nc?temp%5B(1980-01-16):1:(2015-12-16)%5D%5B(5.03355):1:(5.03355)%5D%5B(-74.75):1:(89.75)%5D%5B(0.25):1:(359.75)%5D</dd><dt><span>infoUrl :</span></dt><dd>https://www.atmos.umd.edu/~ocean/</dd><dt><span>institution :</span></dt><dd>University of Maryland</dd><dt><span>keywords :</span></dt><dd>3.3.1, assimilation, circulation, current, currents, data, dbar, density, depth, dia, dia-surface, Earth Science &gt; Oceans &gt; Ocean Circulation &gt; Ocean Currents, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Potential Temperature, Earth Science &gt; Oceans &gt; Salinity/Density &gt; Potential Density, Earth Science &gt; Oceans &gt; Salinity/Density &gt; Salinity, i-current, j-current, latitude, level, longitude, maryland, ocean, points, potential, practical, prho, reanalysis, referenced, salinity, salt, sea, sea_water_potential_density, sea_water_potential_temperature, sea_water_practical_salinity, sea_water_x_velocity, sea_water_y_velocity, seawater, simple, soda, soda3.3.1, state, surface, t-points, temperature, time, u, university, v, velocity, water</dd><dt><span>keywords_vocabulary :</span></dt><dd>GCMD Science Keywords</dd><dt><span>license :</span></dt><dd>The data may be used and redistributed for free but is not intended\n",
              "for legal use, since it may contain inaccuracies. Neither the data\n",
              "Contributor, ERD, NOAA, nor the United States Government, nor any\n",
              "of their employees or contractors, makes any warranty, express or\n",
              "implied, including warranties of merchantability and fitness for a\n",
              "particular purpose, or assumes any legal liability for the accuracy,\n",
              "completeness, or usefulness, of this information.</dd><dt><span>Northernmost_Northing :</span></dt><dd>89.75</dd><dt><span>Principle_investigator :</span></dt><dd>James A. Carton</dd><dt><span>Principle_investigator_email :</span></dt><dd>carton@atmos.umd.edu</dd><dt><span>publisher_email :</span></dt><dd>erd.data@noaa.gov</dd><dt><span>publisher_name :</span></dt><dd>NOAA NMFS SWFSC ERD</dd><dt><span>publisher_type :</span></dt><dd>institution</dd><dt><span>publisher_url :</span></dt><dd>https://www.pfeg.noaa.gov</dd><dt><span>references :</span></dt><dd>Carton, Chepurin, and Chen (2017)</dd><dt><span>sourceUrl :</span></dt><dd>(local files)</dd><dt><span>Southernmost_Northing :</span></dt><dd>-74.75</dd><dt><span>standard_name_vocabulary :</span></dt><dd>CF Standard Name Table v70</dd><dt><span>summary :</span></dt><dd>SODA3.3.1 ocean state, forced by MERRA2. The goal of SODA is to reconstruct the historical physical (and eventually biogeochemical) history of the ocean. As its name implies, the Simple Ocean Data Assimilation ocean/sea ice reanalysis (SODA) uses a simple architecture based on community standard codes with resolution chosen to match available data and the scales of motion that are resolvable. Agreement with direct measurements (to within observational error estimates) as well as unbiased statistics are expected. Please cite: Carton, Chepurin, and Chen (2017).</dd><dt><span>time_coverage_end :</span></dt><dd>2015-12-16T00:00:00Z</dd><dt><span>time_coverage_start :</span></dt><dd>1980-01-16T00:00:00Z</dd><dt><span>title :</span></dt><dd>SODA 3.3.1 Ocean State, 1/2°, Global, 1980-2015, Monthly Composite</dd><dt><span>Website :</span></dt><dd>https://www.atmos.umd.edu/~ocean/</dd><dt><span>Westernmost_Easting :</span></dt><dd>0.25</dd></dl></div></li></ul></div></div>"
            ],
            "text/plain": [
              "<xarray.Dataset>\n",
              "Dimensions:    (depth: 1, latitude: 66, longitude: 144, time: 432)\n",
              "Coordinates:\n",
              "  * time       (time) float64 3.168e+08 3.195e+08 ... 1.448e+09 1.45e+09\n",
              "  * depth      (depth) float32 5.034\n",
              "  * latitude   (latitude) float32 -74.75 -72.25 -69.75 ... 82.75 85.25 87.75\n",
              "  * longitude  (longitude) float32 0.25 2.75 5.25 7.75 ... 352.8 355.2 357.8\n",
              "Data variables:\n",
              "    temp       (time, depth, latitude, longitude) float32 nan nan ... -1.636\n",
              "Attributes: (12/47)\n",
              "    _CoordSysBuilder:              ucar.nc2.internal.dataset.conv.DefaultConv...\n",
              "    acknowledgement:               The SODA3 project is funded by the US Nati...\n",
              "    cdm_data_type:                 Grid\n",
              "    Conventions:                   COARDS, CF-1.6, ACDD-1.3\n",
              "    Created_by:                    Gennady Chepurin and Ligang Chen\n",
              "    creation_date:                 October, 2016\n",
              "    ...                            ...\n",
              "    summary:                       SODA3.3.1 ocean state, forced by MERRA2. T...\n",
              "    time_coverage_end:             2015-12-16T00:00:00Z\n",
              "    time_coverage_start:           1980-01-16T00:00:00Z\n",
              "    title:                         SODA 3.3.1 Ocean State, 1/2°, Global, 1980...\n",
              "    Website:                       https://www.atmos.umd.edu/~ocean/\n",
              "    Westernmost_Easting:           0.25"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_year = 1980\n",
        "end_year = 2016"
      ],
      "metadata": {
        "id": "esqIWxkdchG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_month = (start_year - 1980) * 12\n",
        "end_month = (end_year - 1980) * 12\n",
        "\n",
        "soda_sst = np.zeros((end_month-start_month,1,66,144))\n",
        "soda_sst[:,:,:,:] = soda_smaller.variables[\"temp\"][0:end_month-start_month,:,:,:]"
      ],
      "metadata": {
        "id": "3ZWeMd9achIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst = np.squeeze(soda_sst, axis=1)\n",
        "\n",
        "soda_sst_list = soda_sst.tolist()\n",
        "\n",
        "months = list(range(0, 432))\n",
        "monthly_average_all = []\n",
        "\n",
        "for i in range(12):\n",
        "  individual_month = months[i + start_month : end_month : 12]\n",
        "  average = np.zeros((66,144))\n",
        "  for j in range(len(individual_month)):\n",
        "    average += soda_sst[individual_month[j]]\n",
        "    # average_map += np.array(individual_month[j])\n",
        "  monthly_average = average / len(individual_month)\n",
        "  monthly_average_all.append(monthly_average)\n",
        "  print(\"Month \" + str(i+1) + \" is appended.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4kKYz2Bdm7d",
        "outputId": "bf254810-e94e-4fcb-f0f0-3d78248c9932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Month 1 is appended.\n",
            "Month 2 is appended.\n",
            "Month 3 is appended.\n",
            "Month 4 is appended.\n",
            "Month 5 is appended.\n",
            "Month 6 is appended.\n",
            "Month 7 is appended.\n",
            "Month 8 is appended.\n",
            "Month 9 is appended.\n",
            "Month 10 is appended.\n",
            "Month 11 is appended.\n",
            "Month 12 is appended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_average_all_432 = []\n",
        "monthly_average_all_432 = monthly_average_all\n",
        "print(len(monthly_average_all))\n",
        "print(len(monthly_average_all_432))\n",
        "\n",
        "for i in range(432 - 12):\n",
        "  monthly_average_all_432.append(monthly_average_all_432[i])\n",
        "\n",
        "print(len(monthly_average_all_432))\n",
        "\n",
        "soda_sst_anomaly_list = []\n",
        "\n",
        "for i in range(432):\n",
        "  soda_sst_anomaly_list.append(soda_sst[i] - monthly_average_all_432[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZPuFIL8dz80",
        "outputId": "aad98e8b-e25b-49a4-c3c9-350cebf7e3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "12\n",
            "432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst_anomaly = np.array(soda_sst_anomaly_list)\n",
        "\n",
        "soda_sst_anomaly.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj-N8lyMd96Q",
        "outputId": "6b42a4fc-e9e9-46be-8d9a-f031eed81eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(432, 66, 144)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------"
      ],
      "metadata": {
        "id": "aZBO5r9a_rYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soda_smaller_bop = soda_smaller.loc[dict(latitude=\"-34.75\", longitude=\"177.75\")]\n",
        "\n",
        "soda_sst_bop = np.zeros((end_month-start_month,1))\n",
        "soda_sst_bop[:,:] = soda_smaller_bop.variables[\"temp\"][:,:]\n",
        "\n",
        "print(soda_sst_bop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNbQwI4I44K4",
        "outputId": "04e93bf3-91f8-4304-84e6-e2529d73b001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[20.99832344]\n",
            " [21.79081154]\n",
            " [20.60656357]\n",
            " [19.01729202]\n",
            " [18.35627174]\n",
            " [16.8011055 ]\n",
            " [14.99956512]\n",
            " [14.56353569]\n",
            " [15.07971001]\n",
            " [16.14177513]\n",
            " [17.45836639]\n",
            " [19.13077354]\n",
            " [21.79137993]\n",
            " [22.22587204]\n",
            " [21.55210495]\n",
            " [20.73086357]\n",
            " [18.87947655]\n",
            " [17.26327705]\n",
            " [16.5136528 ]\n",
            " [16.17926979]\n",
            " [16.01082802]\n",
            " [16.73580742]\n",
            " [17.0369873 ]\n",
            " [19.68212128]\n",
            " [21.40428734]\n",
            " [20.97167206]\n",
            " [20.92926979]\n",
            " [19.90824127]\n",
            " [17.99365234]\n",
            " [16.92311478]\n",
            " [16.46268654]\n",
            " [15.89421272]\n",
            " [15.79411983]\n",
            " [16.05239105]\n",
            " [17.40579796]\n",
            " [19.19625282]\n",
            " [20.42951202]\n",
            " [20.65821838]\n",
            " [21.26511574]\n",
            " [20.50668907]\n",
            " [18.65052605]\n",
            " [17.1424675 ]\n",
            " [16.40631485]\n",
            " [15.7081995 ]\n",
            " [15.72676659]\n",
            " [16.41251564]\n",
            " [17.5380764 ]\n",
            " [18.53281021]\n",
            " [20.26769066]\n",
            " [20.86043739]\n",
            " [21.16428566]\n",
            " [20.81809425]\n",
            " [18.97973442]\n",
            " [17.78092384]\n",
            " [17.29343987]\n",
            " [16.34168816]\n",
            " [16.67136383]\n",
            " [16.80033302]\n",
            " [18.7995739 ]\n",
            " [20.84270287]\n",
            " [22.26089287]\n",
            " [21.45246315]\n",
            " [21.21871948]\n",
            " [19.94374466]\n",
            " [18.96822929]\n",
            " [17.32666588]\n",
            " [16.92034531]\n",
            " [16.40367699]\n",
            " [16.17431259]\n",
            " [16.90256882]\n",
            " [17.56794548]\n",
            " [19.35790443]\n",
            " [21.76838112]\n",
            " [21.89110565]\n",
            " [21.63169861]\n",
            " [20.37473869]\n",
            " [19.13556862]\n",
            " [17.31259918]\n",
            " [16.1552887 ]\n",
            " [15.65767956]\n",
            " [15.68858147]\n",
            " [16.64609146]\n",
            " [17.51868439]\n",
            " [18.7309494 ]\n",
            " [20.39892006]\n",
            " [21.44877243]\n",
            " [20.73242378]\n",
            " [19.41936874]\n",
            " [18.42399216]\n",
            " [17.6605072 ]\n",
            " [16.86229515]\n",
            " [16.37205124]\n",
            " [16.22849464]\n",
            " [16.92393494]\n",
            " [18.03831482]\n",
            " [19.76733208]\n",
            " [20.95366096]\n",
            " [22.4074955 ]\n",
            " [21.70041275]\n",
            " [20.22109413]\n",
            " [19.05573082]\n",
            " [18.2573719 ]\n",
            " [17.38365555]\n",
            " [16.51202011]\n",
            " [16.63154411]\n",
            " [17.29200363]\n",
            " [18.26272964]\n",
            " [20.67690468]\n",
            " [21.80380058]\n",
            " [21.36866379]\n",
            " [21.12281609]\n",
            " [20.25737953]\n",
            " [19.46048164]\n",
            " [17.92525482]\n",
            " [17.14123726]\n",
            " [16.61405182]\n",
            " [16.58852196]\n",
            " [17.04235649]\n",
            " [18.55586243]\n",
            " [19.5921402 ]\n",
            " [21.49889374]\n",
            " [22.57980156]\n",
            " [22.3877964 ]\n",
            " [20.72471046]\n",
            " [19.26286125]\n",
            " [17.59605408]\n",
            " [16.38936615]\n",
            " [16.15054131]\n",
            " [15.99658298]\n",
            " [17.23626137]\n",
            " [18.45246887]\n",
            " [20.10521507]\n",
            " [20.69381523]\n",
            " [22.08159256]\n",
            " [20.85621071]\n",
            " [19.53244209]\n",
            " [18.27468872]\n",
            " [17.03299141]\n",
            " [15.47928905]\n",
            " [14.86413574]\n",
            " [14.93168831]\n",
            " [15.61790466]\n",
            " [15.83235836]\n",
            " [17.57940483]\n",
            " [19.73925972]\n",
            " [21.31085014]\n",
            " [19.88952446]\n",
            " [18.68817902]\n",
            " [17.26474762]\n",
            " [15.69797039]\n",
            " [15.01496506]\n",
            " [14.55018425]\n",
            " [14.53361511]\n",
            " [15.01692486]\n",
            " [17.03162575]\n",
            " [18.93622208]\n",
            " [20.39454079]\n",
            " [19.96020699]\n",
            " [19.46651649]\n",
            " [19.24843979]\n",
            " [18.22237396]\n",
            " [17.18651581]\n",
            " [16.67061424]\n",
            " [16.08920097]\n",
            " [15.15795231]\n",
            " [15.93599129]\n",
            " [16.90532112]\n",
            " [18.7306633 ]\n",
            " [22.11408424]\n",
            " [20.55249023]\n",
            " [20.03125763]\n",
            " [18.93708801]\n",
            " [17.83217049]\n",
            " [16.64674759]\n",
            " [16.09566498]\n",
            " [15.77600193]\n",
            " [15.7388382 ]\n",
            " [16.3318119 ]\n",
            " [18.03072929]\n",
            " [19.95214462]\n",
            " [20.90141678]\n",
            " [21.56451797]\n",
            " [21.34277725]\n",
            " [20.70659828]\n",
            " [19.21005821]\n",
            " [17.46960068]\n",
            " [16.14302826]\n",
            " [16.00208282]\n",
            " [15.87827015]\n",
            " [16.57226181]\n",
            " [18.07321358]\n",
            " [20.56787682]\n",
            " [21.89831161]\n",
            " [22.55315208]\n",
            " [21.28708839]\n",
            " [20.54055023]\n",
            " [19.55596161]\n",
            " [17.51400185]\n",
            " [16.71861458]\n",
            " [16.00414276]\n",
            " [15.97334194]\n",
            " [16.42277336]\n",
            " [17.4964962 ]\n",
            " [19.29759789]\n",
            " [20.39893532]\n",
            " [20.59957695]\n",
            " [20.25700188]\n",
            " [19.24552727]\n",
            " [18.1607914 ]\n",
            " [17.17173004]\n",
            " [16.65373611]\n",
            " [16.14826202]\n",
            " [15.89355755]\n",
            " [16.4894371 ]\n",
            " [18.02145767]\n",
            " [20.51247978]\n",
            " [21.34450912]\n",
            " [23.23172188]\n",
            " [22.30470467]\n",
            " [21.40002251]\n",
            " [20.10756874]\n",
            " [18.75075722]\n",
            " [17.40045547]\n",
            " [17.31285095]\n",
            " [17.33383942]\n",
            " [17.984272  ]\n",
            " [18.59892845]\n",
            " [19.72474098]\n",
            " [21.21152878]\n",
            " [21.12631226]\n",
            " [20.95186043]\n",
            " [20.9118309 ]\n",
            " [19.80223274]\n",
            " [18.56252098]\n",
            " [16.98887825]\n",
            " [15.76242161]\n",
            " [16.46760368]\n",
            " [17.62866783]\n",
            " [18.51069641]\n",
            " [19.399786  ]\n",
            " [20.47579193]\n",
            " [21.10918045]\n",
            " [21.04057503]\n",
            " [20.1089325 ]\n",
            " [19.08877182]\n",
            " [17.54431343]\n",
            " [16.63293839]\n",
            " [15.80201149]\n",
            " [15.74452305]\n",
            " [16.23924255]\n",
            " [16.98049355]\n",
            " [19.17833519]\n",
            " [20.95990372]\n",
            " [21.71811867]\n",
            " [21.14821625]\n",
            " [19.83506775]\n",
            " [19.17942238]\n",
            " [17.47238159]\n",
            " [16.41484451]\n",
            " [15.96182442]\n",
            " [15.95747089]\n",
            " [17.0958252 ]\n",
            " [18.58023834]\n",
            " [20.34995461]\n",
            " [21.43003273]\n",
            " [21.46515274]\n",
            " [21.36348343]\n",
            " [20.79070663]\n",
            " [19.48886681]\n",
            " [18.00528145]\n",
            " [17.07735252]\n",
            " [16.16279602]\n",
            " [15.99701977]\n",
            " [16.09295082]\n",
            " [16.82927132]\n",
            " [19.15351105]\n",
            " [20.86514854]\n",
            " [21.61723328]\n",
            " [21.34974098]\n",
            " [20.6296196 ]\n",
            " [19.1675663 ]\n",
            " [18.07161522]\n",
            " [16.84083366]\n",
            " [16.16911316]\n",
            " [15.86299419]\n",
            " [16.52303505]\n",
            " [17.81685829]\n",
            " [20.33447647]\n",
            " [22.14434814]\n",
            " [22.10246849]\n",
            " [20.55640984]\n",
            " [19.62667465]\n",
            " [18.60891342]\n",
            " [17.64035797]\n",
            " [16.14523888]\n",
            " [15.93045616]\n",
            " [15.56655979]\n",
            " [16.20988655]\n",
            " [18.04634094]\n",
            " [18.15660095]\n",
            " [19.64403152]\n",
            " [21.07264709]\n",
            " [21.72353172]\n",
            " [21.16397285]\n",
            " [19.15659523]\n",
            " [17.21925926]\n",
            " [16.37850761]\n",
            " [15.92729473]\n",
            " [16.15381432]\n",
            " [16.55532074]\n",
            " [18.13290405]\n",
            " [19.75640297]\n",
            " [21.56176758]\n",
            " [22.67319679]\n",
            " [21.48240852]\n",
            " [20.52246284]\n",
            " [19.05263519]\n",
            " [17.27653503]\n",
            " [15.97521114]\n",
            " [15.60246181]\n",
            " [16.40553284]\n",
            " [16.6401062 ]\n",
            " [17.52925682]\n",
            " [18.62840271]\n",
            " [20.76158524]\n",
            " [21.58411217]\n",
            " [21.46434975]\n",
            " [20.4340744 ]\n",
            " [19.04035187]\n",
            " [17.77128983]\n",
            " [16.77464676]\n",
            " [15.9608717 ]\n",
            " [15.9825592 ]\n",
            " [16.37787247]\n",
            " [17.51979256]\n",
            " [19.47533607]\n",
            " [21.11709404]\n",
            " [21.49786377]\n",
            " [21.09847069]\n",
            " [20.29055786]\n",
            " [18.89152527]\n",
            " [17.01105309]\n",
            " [15.87277603]\n",
            " [15.38184547]\n",
            " [15.5998745 ]\n",
            " [16.37080383]\n",
            " [17.63920784]\n",
            " [20.15165329]\n",
            " [22.04670525]\n",
            " [22.69949341]\n",
            " [21.77620506]\n",
            " [20.10162926]\n",
            " [18.42014885]\n",
            " [16.76965904]\n",
            " [15.63876534]\n",
            " [15.40495014]\n",
            " [15.81625652]\n",
            " [16.3334198 ]\n",
            " [17.57381439]\n",
            " [19.79959679]\n",
            " [20.93378639]\n",
            " [22.25676155]\n",
            " [21.25169563]\n",
            " [19.74518394]\n",
            " [18.86244965]\n",
            " [17.42312241]\n",
            " [16.17758751]\n",
            " [15.79895878]\n",
            " [15.43163872]\n",
            " [16.60854721]\n",
            " [17.35688019]\n",
            " [19.94188499]\n",
            " [22.11748314]\n",
            " [23.07208252]\n",
            " [21.89195251]\n",
            " [20.23139572]\n",
            " [19.20557594]\n",
            " [17.93247414]\n",
            " [16.56336021]\n",
            " [15.67179394]\n",
            " [15.69833565]\n",
            " [16.85586166]\n",
            " [18.09648705]\n",
            " [19.20958138]\n",
            " [20.78093147]\n",
            " [21.4084549 ]\n",
            " [20.32474899]\n",
            " [19.68964005]\n",
            " [18.72720718]\n",
            " [17.64875793]\n",
            " [16.73929405]\n",
            " [16.41443062]\n",
            " [16.20888329]\n",
            " [16.48832321]\n",
            " [17.42503929]\n",
            " [19.84886932]\n",
            " [20.99320793]\n",
            " [21.08189774]\n",
            " [20.52011681]\n",
            " [20.51310539]\n",
            " [19.36187553]\n",
            " [17.93548965]\n",
            " [16.4809742 ]\n",
            " [16.2931118 ]\n",
            " [15.85114479]\n",
            " [16.64599419]\n",
            " [18.31202698]\n",
            " [20.77078819]\n",
            " [21.60673714]\n",
            " [21.11923599]\n",
            " [20.95995331]\n",
            " [20.42938423]\n",
            " [19.54596329]\n",
            " [18.58562851]\n",
            " [16.98614502]\n",
            " [15.51044273]\n",
            " [15.70727921]\n",
            " [16.19749832]\n",
            " [17.64938545]\n",
            " [19.72351456]\n",
            " [21.64782524]\n",
            " [21.33032227]\n",
            " [20.92250061]\n",
            " [20.11548424]\n",
            " [18.9409523 ]\n",
            " [17.52771568]\n",
            " [16.88215637]\n",
            " [15.91228008]\n",
            " [15.62820625]\n",
            " [16.41443825]\n",
            " [17.62103844]\n",
            " [19.27601624]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst_bop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY-K1WPDCYqc",
        "outputId": "9dde73d2-4070-4068-ea3e-d54097277280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20.99832344],\n",
              "       [21.79081154],\n",
              "       [20.60656357],\n",
              "       [19.01729202],\n",
              "       [18.35627174],\n",
              "       [16.8011055 ],\n",
              "       [14.99956512],\n",
              "       [14.56353569],\n",
              "       [15.07971001],\n",
              "       [16.14177513],\n",
              "       [17.45836639],\n",
              "       [19.13077354],\n",
              "       [21.79137993],\n",
              "       [22.22587204],\n",
              "       [21.55210495],\n",
              "       [20.73086357],\n",
              "       [18.87947655],\n",
              "       [17.26327705],\n",
              "       [16.5136528 ],\n",
              "       [16.17926979],\n",
              "       [16.01082802],\n",
              "       [16.73580742],\n",
              "       [17.0369873 ],\n",
              "       [19.68212128],\n",
              "       [21.40428734],\n",
              "       [20.97167206],\n",
              "       [20.92926979],\n",
              "       [19.90824127],\n",
              "       [17.99365234],\n",
              "       [16.92311478],\n",
              "       [16.46268654],\n",
              "       [15.89421272],\n",
              "       [15.79411983],\n",
              "       [16.05239105],\n",
              "       [17.40579796],\n",
              "       [19.19625282],\n",
              "       [20.42951202],\n",
              "       [20.65821838],\n",
              "       [21.26511574],\n",
              "       [20.50668907],\n",
              "       [18.65052605],\n",
              "       [17.1424675 ],\n",
              "       [16.40631485],\n",
              "       [15.7081995 ],\n",
              "       [15.72676659],\n",
              "       [16.41251564],\n",
              "       [17.5380764 ],\n",
              "       [18.53281021],\n",
              "       [20.26769066],\n",
              "       [20.86043739],\n",
              "       [21.16428566],\n",
              "       [20.81809425],\n",
              "       [18.97973442],\n",
              "       [17.78092384],\n",
              "       [17.29343987],\n",
              "       [16.34168816],\n",
              "       [16.67136383],\n",
              "       [16.80033302],\n",
              "       [18.7995739 ],\n",
              "       [20.84270287],\n",
              "       [22.26089287],\n",
              "       [21.45246315],\n",
              "       [21.21871948],\n",
              "       [19.94374466],\n",
              "       [18.96822929],\n",
              "       [17.32666588],\n",
              "       [16.92034531],\n",
              "       [16.40367699],\n",
              "       [16.17431259],\n",
              "       [16.90256882],\n",
              "       [17.56794548],\n",
              "       [19.35790443],\n",
              "       [21.76838112],\n",
              "       [21.89110565],\n",
              "       [21.63169861],\n",
              "       [20.37473869],\n",
              "       [19.13556862],\n",
              "       [17.31259918],\n",
              "       [16.1552887 ],\n",
              "       [15.65767956],\n",
              "       [15.68858147],\n",
              "       [16.64609146],\n",
              "       [17.51868439],\n",
              "       [18.7309494 ],\n",
              "       [20.39892006],\n",
              "       [21.44877243],\n",
              "       [20.73242378],\n",
              "       [19.41936874],\n",
              "       [18.42399216],\n",
              "       [17.6605072 ],\n",
              "       [16.86229515],\n",
              "       [16.37205124],\n",
              "       [16.22849464],\n",
              "       [16.92393494],\n",
              "       [18.03831482],\n",
              "       [19.76733208],\n",
              "       [20.95366096],\n",
              "       [22.4074955 ],\n",
              "       [21.70041275],\n",
              "       [20.22109413],\n",
              "       [19.05573082],\n",
              "       [18.2573719 ],\n",
              "       [17.38365555],\n",
              "       [16.51202011],\n",
              "       [16.63154411],\n",
              "       [17.29200363],\n",
              "       [18.26272964],\n",
              "       [20.67690468],\n",
              "       [21.80380058],\n",
              "       [21.36866379],\n",
              "       [21.12281609],\n",
              "       [20.25737953],\n",
              "       [19.46048164],\n",
              "       [17.92525482],\n",
              "       [17.14123726],\n",
              "       [16.61405182],\n",
              "       [16.58852196],\n",
              "       [17.04235649],\n",
              "       [18.55586243],\n",
              "       [19.5921402 ],\n",
              "       [21.49889374],\n",
              "       [22.57980156],\n",
              "       [22.3877964 ],\n",
              "       [20.72471046],\n",
              "       [19.26286125],\n",
              "       [17.59605408],\n",
              "       [16.38936615],\n",
              "       [16.15054131],\n",
              "       [15.99658298],\n",
              "       [17.23626137],\n",
              "       [18.45246887],\n",
              "       [20.10521507],\n",
              "       [20.69381523],\n",
              "       [22.08159256],\n",
              "       [20.85621071],\n",
              "       [19.53244209],\n",
              "       [18.27468872],\n",
              "       [17.03299141],\n",
              "       [15.47928905],\n",
              "       [14.86413574],\n",
              "       [14.93168831],\n",
              "       [15.61790466],\n",
              "       [15.83235836],\n",
              "       [17.57940483],\n",
              "       [19.73925972],\n",
              "       [21.31085014],\n",
              "       [19.88952446],\n",
              "       [18.68817902],\n",
              "       [17.26474762],\n",
              "       [15.69797039],\n",
              "       [15.01496506],\n",
              "       [14.55018425],\n",
              "       [14.53361511],\n",
              "       [15.01692486],\n",
              "       [17.03162575],\n",
              "       [18.93622208],\n",
              "       [20.39454079],\n",
              "       [19.96020699],\n",
              "       [19.46651649],\n",
              "       [19.24843979],\n",
              "       [18.22237396],\n",
              "       [17.18651581],\n",
              "       [16.67061424],\n",
              "       [16.08920097],\n",
              "       [15.15795231],\n",
              "       [15.93599129],\n",
              "       [16.90532112],\n",
              "       [18.7306633 ],\n",
              "       [22.11408424],\n",
              "       [20.55249023],\n",
              "       [20.03125763],\n",
              "       [18.93708801],\n",
              "       [17.83217049],\n",
              "       [16.64674759],\n",
              "       [16.09566498],\n",
              "       [15.77600193],\n",
              "       [15.7388382 ],\n",
              "       [16.3318119 ],\n",
              "       [18.03072929],\n",
              "       [19.95214462],\n",
              "       [20.90141678],\n",
              "       [21.56451797],\n",
              "       [21.34277725],\n",
              "       [20.70659828],\n",
              "       [19.21005821],\n",
              "       [17.46960068],\n",
              "       [16.14302826],\n",
              "       [16.00208282],\n",
              "       [15.87827015],\n",
              "       [16.57226181],\n",
              "       [18.07321358],\n",
              "       [20.56787682],\n",
              "       [21.89831161],\n",
              "       [22.55315208],\n",
              "       [21.28708839],\n",
              "       [20.54055023],\n",
              "       [19.55596161],\n",
              "       [17.51400185],\n",
              "       [16.71861458],\n",
              "       [16.00414276],\n",
              "       [15.97334194],\n",
              "       [16.42277336],\n",
              "       [17.4964962 ],\n",
              "       [19.29759789],\n",
              "       [20.39893532],\n",
              "       [20.59957695],\n",
              "       [20.25700188],\n",
              "       [19.24552727],\n",
              "       [18.1607914 ],\n",
              "       [17.17173004],\n",
              "       [16.65373611],\n",
              "       [16.14826202],\n",
              "       [15.89355755],\n",
              "       [16.4894371 ],\n",
              "       [18.02145767],\n",
              "       [20.51247978],\n",
              "       [21.34450912],\n",
              "       [23.23172188],\n",
              "       [22.30470467],\n",
              "       [21.40002251],\n",
              "       [20.10756874],\n",
              "       [18.75075722],\n",
              "       [17.40045547],\n",
              "       [17.31285095],\n",
              "       [17.33383942],\n",
              "       [17.984272  ],\n",
              "       [18.59892845],\n",
              "       [19.72474098],\n",
              "       [21.21152878],\n",
              "       [21.12631226],\n",
              "       [20.95186043],\n",
              "       [20.9118309 ],\n",
              "       [19.80223274],\n",
              "       [18.56252098],\n",
              "       [16.98887825],\n",
              "       [15.76242161],\n",
              "       [16.46760368],\n",
              "       [17.62866783],\n",
              "       [18.51069641],\n",
              "       [19.399786  ],\n",
              "       [20.47579193],\n",
              "       [21.10918045],\n",
              "       [21.04057503],\n",
              "       [20.1089325 ],\n",
              "       [19.08877182],\n",
              "       [17.54431343],\n",
              "       [16.63293839],\n",
              "       [15.80201149],\n",
              "       [15.74452305],\n",
              "       [16.23924255],\n",
              "       [16.98049355],\n",
              "       [19.17833519],\n",
              "       [20.95990372],\n",
              "       [21.71811867],\n",
              "       [21.14821625],\n",
              "       [19.83506775],\n",
              "       [19.17942238],\n",
              "       [17.47238159],\n",
              "       [16.41484451],\n",
              "       [15.96182442],\n",
              "       [15.95747089],\n",
              "       [17.0958252 ],\n",
              "       [18.58023834],\n",
              "       [20.34995461],\n",
              "       [21.43003273],\n",
              "       [21.46515274],\n",
              "       [21.36348343],\n",
              "       [20.79070663],\n",
              "       [19.48886681],\n",
              "       [18.00528145],\n",
              "       [17.07735252],\n",
              "       [16.16279602],\n",
              "       [15.99701977],\n",
              "       [16.09295082],\n",
              "       [16.82927132],\n",
              "       [19.15351105],\n",
              "       [20.86514854],\n",
              "       [21.61723328],\n",
              "       [21.34974098],\n",
              "       [20.6296196 ],\n",
              "       [19.1675663 ],\n",
              "       [18.07161522],\n",
              "       [16.84083366],\n",
              "       [16.16911316],\n",
              "       [15.86299419],\n",
              "       [16.52303505],\n",
              "       [17.81685829],\n",
              "       [20.33447647],\n",
              "       [22.14434814],\n",
              "       [22.10246849],\n",
              "       [20.55640984],\n",
              "       [19.62667465],\n",
              "       [18.60891342],\n",
              "       [17.64035797],\n",
              "       [16.14523888],\n",
              "       [15.93045616],\n",
              "       [15.56655979],\n",
              "       [16.20988655],\n",
              "       [18.04634094],\n",
              "       [18.15660095],\n",
              "       [19.64403152],\n",
              "       [21.07264709],\n",
              "       [21.72353172],\n",
              "       [21.16397285],\n",
              "       [19.15659523],\n",
              "       [17.21925926],\n",
              "       [16.37850761],\n",
              "       [15.92729473],\n",
              "       [16.15381432],\n",
              "       [16.55532074],\n",
              "       [18.13290405],\n",
              "       [19.75640297],\n",
              "       [21.56176758],\n",
              "       [22.67319679],\n",
              "       [21.48240852],\n",
              "       [20.52246284],\n",
              "       [19.05263519],\n",
              "       [17.27653503],\n",
              "       [15.97521114],\n",
              "       [15.60246181],\n",
              "       [16.40553284],\n",
              "       [16.6401062 ],\n",
              "       [17.52925682],\n",
              "       [18.62840271],\n",
              "       [20.76158524],\n",
              "       [21.58411217],\n",
              "       [21.46434975],\n",
              "       [20.4340744 ],\n",
              "       [19.04035187],\n",
              "       [17.77128983],\n",
              "       [16.77464676],\n",
              "       [15.9608717 ],\n",
              "       [15.9825592 ],\n",
              "       [16.37787247],\n",
              "       [17.51979256],\n",
              "       [19.47533607],\n",
              "       [21.11709404],\n",
              "       [21.49786377],\n",
              "       [21.09847069],\n",
              "       [20.29055786],\n",
              "       [18.89152527],\n",
              "       [17.01105309],\n",
              "       [15.87277603],\n",
              "       [15.38184547],\n",
              "       [15.5998745 ],\n",
              "       [16.37080383],\n",
              "       [17.63920784],\n",
              "       [20.15165329],\n",
              "       [22.04670525],\n",
              "       [22.69949341],\n",
              "       [21.77620506],\n",
              "       [20.10162926],\n",
              "       [18.42014885],\n",
              "       [16.76965904],\n",
              "       [15.63876534],\n",
              "       [15.40495014],\n",
              "       [15.81625652],\n",
              "       [16.3334198 ],\n",
              "       [17.57381439],\n",
              "       [19.79959679],\n",
              "       [20.93378639],\n",
              "       [22.25676155],\n",
              "       [21.25169563],\n",
              "       [19.74518394],\n",
              "       [18.86244965],\n",
              "       [17.42312241],\n",
              "       [16.17758751],\n",
              "       [15.79895878],\n",
              "       [15.43163872],\n",
              "       [16.60854721],\n",
              "       [17.35688019],\n",
              "       [19.94188499],\n",
              "       [22.11748314],\n",
              "       [23.07208252],\n",
              "       [21.89195251],\n",
              "       [20.23139572],\n",
              "       [19.20557594],\n",
              "       [17.93247414],\n",
              "       [16.56336021],\n",
              "       [15.67179394],\n",
              "       [15.69833565],\n",
              "       [16.85586166],\n",
              "       [18.09648705],\n",
              "       [19.20958138],\n",
              "       [20.78093147],\n",
              "       [21.4084549 ],\n",
              "       [20.32474899],\n",
              "       [19.68964005],\n",
              "       [18.72720718],\n",
              "       [17.64875793],\n",
              "       [16.73929405],\n",
              "       [16.41443062],\n",
              "       [16.20888329],\n",
              "       [16.48832321],\n",
              "       [17.42503929],\n",
              "       [19.84886932],\n",
              "       [20.99320793],\n",
              "       [21.08189774],\n",
              "       [20.52011681],\n",
              "       [20.51310539],\n",
              "       [19.36187553],\n",
              "       [17.93548965],\n",
              "       [16.4809742 ],\n",
              "       [16.2931118 ],\n",
              "       [15.85114479],\n",
              "       [16.64599419],\n",
              "       [18.31202698],\n",
              "       [20.77078819],\n",
              "       [21.60673714],\n",
              "       [21.11923599],\n",
              "       [20.95995331],\n",
              "       [20.42938423],\n",
              "       [19.54596329],\n",
              "       [18.58562851],\n",
              "       [16.98614502],\n",
              "       [15.51044273],\n",
              "       [15.70727921],\n",
              "       [16.19749832],\n",
              "       [17.64938545],\n",
              "       [19.72351456],\n",
              "       [21.64782524],\n",
              "       [21.33032227],\n",
              "       [20.92250061],\n",
              "       [20.11548424],\n",
              "       [18.9409523 ],\n",
              "       [17.52771568],\n",
              "       [16.88215637],\n",
              "       [15.91228008],\n",
              "       [15.62820625],\n",
              "       [16.41443825],\n",
              "       [17.62103844],\n",
              "       [19.27601624]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst_bop = np.squeeze(soda_sst_bop)"
      ],
      "metadata": {
        "id": "XKNC-izl_7wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst_bop_monthly_average = []\n",
        "\n",
        "for i in range(12):\n",
        "  monthly_sst_anomaly = soda_sst_bop[i::12]\n",
        "  soda_sst_bop_monthly_average.append(sum(monthly_sst_anomaly)/len(monthly_sst_anomaly))\n",
        "\n",
        "soda_sst_bop_anomaly = []\n",
        "\n",
        "for i in range(len(soda_sst_bop)):\n",
        "  j = i % 12\n",
        "  soda_sst_bop_anomaly.append(soda_sst_bop[i] - soda_sst_bop_monthly_average[j])"
      ],
      "metadata": {
        "id": "7jKlz1wtQqd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst_bop_anomaly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD_HQLcOQ3kP",
        "outputId": "2c118ecf-791d-4461-dab2-e32a97478e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.1505244572957345,\n",
              " 0.16736830605400854,\n",
              " -0.4926727612813302,\n",
              " -1.1316187116834868,\n",
              " -0.5419487953186035,\n",
              " -0.6949253877003976,\n",
              " -1.4802605840894927,\n",
              " -1.3478768931494827,\n",
              " -0.8122795952690964,\n",
              " -0.4092029200659866,\n",
              " -0.27065221468607703,\n",
              " -0.4267527792188872,\n",
              " 0.6425320307413749,\n",
              " 0.6024288071526414,\n",
              " 0.4528686205546073,\n",
              " 0.5819528367784272,\n",
              " -0.01874399185180664,\n",
              " -0.2327538331349679,\n",
              " 0.033827092912460444,\n",
              " 0.2678572071923142,\n",
              " 0.11883841620551294,\n",
              " 0.18482936753166967,\n",
              " -0.6920313040415458,\n",
              " 0.1245949533250581,\n",
              " 0.25543944040934363,\n",
              " -0.6517711745368118,\n",
              " -0.1699665387471505,\n",
              " -0.2406694624159087,\n",
              " -0.9045681953430176,\n",
              " -0.5729161103566476,\n",
              " -0.01713916990492237,\n",
              " -0.017199860678779544,\n",
              " -0.09786976708306128,\n",
              " -0.49858699904547876,\n",
              " -0.32322065035502234,\n",
              " -0.3612735006544341,\n",
              " -0.719335873921711,\n",
              " -0.965224848853218,\n",
              " 0.1658794085184745,\n",
              " 0.3577783372667085,\n",
              " -0.2476944923400879,\n",
              " -0.35356338818867883,\n",
              " -0.0735108587476958,\n",
              " -0.2032130824195022,\n",
              " -0.16522301567925268,\n",
              " -0.13846241103278345,\n",
              " -0.19094220797220984,\n",
              " -1.02471611234877,\n",
              " -0.8811572392781564,\n",
              " -0.763005839453804,\n",
              " 0.06504933039347449,\n",
              " 0.6691835191514741,\n",
              " 0.08151388168334961,\n",
              " 0.28489295641581336,\n",
              " 0.8136141565110933,\n",
              " 0.43027557267082983,\n",
              " 0.7793742285834426,\n",
              " 0.24935497177971655,\n",
              " 1.070555289586384,\n",
              " 1.2851765420701753,\n",
              " 1.1120449701944999,\n",
              " -0.17098008261786646,\n",
              " 0.11948315302531043,\n",
              " -0.20516607496473682,\n",
              " 0.07000875473022461,\n",
              " -0.16936500867207727,\n",
              " 0.44051959779527294,\n",
              " 0.4922644032372361,\n",
              " 0.28232298956977075,\n",
              " 0.35159076584709936,\n",
              " -0.1610731283823661,\n",
              " -0.1996218893263091,\n",
              " 0.6195332209269218,\n",
              " 0.26766241921318823,\n",
              " 0.5324622790018729,\n",
              " 0.22582795884873974,\n",
              " 0.23734807968139648,\n",
              " -0.18343170483906945,\n",
              " -0.32453701231214893,\n",
              " -0.2537330256568069,\n",
              " -0.20340813530815893,\n",
              " 0.09511340989006811,\n",
              " -0.21033422152201453,\n",
              " -0.8265769216749419,\n",
              " -0.7499278386433907,\n",
              " -0.17467080222235865,\n",
              " -0.36681254704793176,\n",
              " -0.7295419904920806,\n",
              " -0.4742283821105957,\n",
              " 0.1644763151804618,\n",
              " 0.3824694421556245,\n",
              " 0.460638655556572,\n",
              " 0.33650504218207544,\n",
              " 0.372956885231865,\n",
              " 0.3092962106068917,\n",
              " 0.20980575349595654,\n",
              " -0.195186932881672,\n",
              " 0.784052266014946,\n",
              " 0.601176420847576,\n",
              " 0.07218339708116162,\n",
              " 0.15751028060913086,\n",
              " 0.7613410154978446,\n",
              " 0.9038298394944917,\n",
              " 0.6006075276268845,\n",
              " 0.7395545111762161,\n",
              " 0.7410255803002244,\n",
              " 0.5337110360463448,\n",
              " 1.119378354814316,\n",
              " 0.6549526850382499,\n",
              " -0.25477944480048365,\n",
              " 0.023579756418865117,\n",
              " 0.10846879747178662,\n",
              " 0.5622611045837402,\n",
              " 0.42922393480936805,\n",
              " 0.6614115503099214,\n",
              " 0.7026392353905564,\n",
              " 0.6965323554144973,\n",
              " 0.4913784397972947,\n",
              " 0.8268438180287667,\n",
              " 0.0346138742234956,\n",
              " 0.35004583994547644,\n",
              " 0.9563583268059617,\n",
              " 1.2885600725809745,\n",
              " 0.5757997300889741,\n",
              " 0.3646407127380371,\n",
              " 0.1000231901804618,\n",
              " -0.09045955869886768,\n",
              " 0.23912872208489233,\n",
              " 0.10459338294135279,\n",
              " 0.685283316506279,\n",
              " 0.7234502633412667,\n",
              " 0.5476887491014253,\n",
              " -0.4550326665242501,\n",
              " 0.4581493271721726,\n",
              " -0.2430256207784005,\n",
              " -0.6164686414930571,\n",
              " -0.6235318183898926,\n",
              " -0.4630394776662179,\n",
              " -1.000536653730606,\n",
              " -1.0472768412695999,\n",
              " -0.9603012932671433,\n",
              " -0.933073388205635,\n",
              " -1.8966602484385184,\n",
              " -1.9781214925977935,\n",
              " -1.4095881779988595,\n",
              " -0.31259308920966333,\n",
              " -1.2097118695576974,\n",
              " -1.4607317182752837,\n",
              " -1.6334729194641113,\n",
              " -1.7980604966481515,\n",
              " -1.4648606512281646,\n",
              " -1.3612283335791702,\n",
              " -1.3583744896782761,\n",
              " -1.5340531931983108,\n",
              " -0.6973928610483817,\n",
              " -0.621304247114395,\n",
              " -0.7543071111043282,\n",
              " -1.6632362471686477,\n",
              " -1.632719834645588,\n",
              " -0.9004709455702056,\n",
              " -0.6758465766906738,\n",
              " -0.30951507886250695,\n",
              " 0.1907885339524995,\n",
              " 0.17778839005364233,\n",
              " -0.7340372933281785,\n",
              " -0.6149867640601272,\n",
              " -0.8236974875132255,\n",
              " -0.8268630239698638,\n",
              " 0.9652363459269218,\n",
              " -1.0709529982672805,\n",
              " -1.0679787000020333,\n",
              " -1.2118227216932524,\n",
              " -1.0660500526428223,\n",
              " -0.8492832978566476,\n",
              " -0.3841607305738677,\n",
              " -0.13541065322028345,\n",
              " -0.15315140618218237,\n",
              " -0.21916614638434595,\n",
              " 0.3017106850941964,\n",
              " 0.3946182992723237,\n",
              " -0.24743111928303918,\n",
              " -0.058925257788764895,\n",
              " 0.24354092280070105,\n",
              " 0.5576875474717866,\n",
              " 0.31183767318725586,\n",
              " -0.02643020947774133,\n",
              " -0.3367974493238677,\n",
              " 0.0906702412499314,\n",
              " -0.013719452752006589,\n",
              " 0.021283759011161862,\n",
              " 0.34419496854146203,\n",
              " 1.0103504922654878,\n",
              " 0.7494637171427421,\n",
              " 0.9297088517083054,\n",
              " 0.1878520647684745,\n",
              " 0.3916394975450288,\n",
              " 0.6577410697937012,\n",
              " 0.01797095934550086,\n",
              " 0.23878886964585888,\n",
              " 0.0927301777733689,\n",
              " 0.08135233985053247,\n",
              " -0.12820469008551783,\n",
              " -0.23252240816752234,\n",
              " -0.2599284383985747,\n",
              " -0.7499125798543282,\n",
              " -1.0238662825690383,\n",
              " -0.8422344525655099,\n",
              " -0.9033834669325103,\n",
              " -0.737429141998291,\n",
              " -0.32430084546406945,\n",
              " 0.1739104059007417,\n",
              " 0.2368494404686814,\n",
              " 0.0015679465399855985,\n",
              " -0.06154094802008814,\n",
              " 0.29243906339009484,\n",
              " 0.9549534585740815,\n",
              " 0.19566122690836707,\n",
              " 1.6082786454094773,\n",
              " 1.2054683367411307,\n",
              " 1.2511117723253022,\n",
              " 1.209348201751709,\n",
              " 1.2547263304392509,\n",
              " 0.9206297662523042,\n",
              " 1.4014383686913376,\n",
              " 1.4418498145209426,\n",
              " 1.4332939518822556,\n",
              " 0.8699098428090402,\n",
              " 0.1672146585252534,\n",
              " 0.06268088022867957,\n",
              " -0.4971309767829055,\n",
              " -0.14737590154011926,\n",
              " 0.7629201677110444,\n",
              " 0.9040122032165527,\n",
              " 1.0664900938669852,\n",
              " 0.5090525415208589,\n",
              " -0.14899097548590845,\n",
              " 0.5756140814887161,\n",
              " 1.077689780129326,\n",
              " 0.7816778024037667,\n",
              " -0.1577403280470122,\n",
              " -0.6730559666951486,\n",
              " -0.5142627822028274,\n",
              " -0.05866130193074426,\n",
              " -0.03997823927137745,\n",
              " 0.1905512809753418,\n",
              " 0.04828254381815711,\n",
              " 0.1531126764085542,\n",
              " -0.1094010935889358,\n",
              " -0.14746655358208471,\n",
              " -0.311735497580635,\n",
              " -0.7485250631968192,\n",
              " -0.3791911337110747,\n",
              " -0.18894418080647668,\n",
              " 0.09467543496025854,\n",
              " 0.04897991816202918,\n",
              " -0.31384298536512745,\n",
              " 0.2812018394470215,\n",
              " -0.023649295171100704,\n",
              " -0.0649811956617583,\n",
              " 0.050411833657157956,\n",
              " 0.06548129187689966,\n",
              " 0.5448471440209275,\n",
              " 0.8512197335561105,\n",
              " 0.7924282815721284,\n",
              " 0.28118483225504676,\n",
              " -0.1582904921637649,\n",
              " 0.26424709955851355,\n",
              " 0.6417959001329194,\n",
              " 0.5906462669372559,\n",
              " 0.5092505613962821,\n",
              " 0.5975268152024995,\n",
              " 0.25138343705071264,\n",
              " 0.10503016577826685,\n",
              " -0.45802723036872095,\n",
              " -0.8997472922007255,\n",
              " -0.4040152761671294,\n",
              " -0.28369935353596887,\n",
              " -0.00620995627509302,\n",
              " 0.2505046526590995,\n",
              " 0.48070886400010693,\n",
              " 0.269345760345459,\n",
              " 0.5755843321482352,\n",
              " 0.36100795533921826,\n",
              " 0.25770057572258764,\n",
              " -0.0289954079522019,\n",
              " -0.02794300185309595,\n",
              " 0.08783968289693078,\n",
              " 0.776950147416855,\n",
              " 0.9955002466837577,\n",
              " 0.4790252579583054,\n",
              " -0.5428264935811349,\n",
              " -0.5222360822889556,\n",
              " -0.2893071174621582,\n",
              " 0.14432708422343055,\n",
              " -0.334586832258438,\n",
              " 0.01904357804192358,\n",
              " -0.3254298104180222,\n",
              " -0.3410915003882522,\n",
              " 0.3173223336537667,\n",
              " -1.4009253713819732,\n",
              " -1.5048163731892892,\n",
              " -0.550796137915718,\n",
              " 0.6242953936258964,\n",
              " 1.0150621202256929,\n",
              " 0.2583746910095215,\n",
              " -0.27677162488301477,\n",
              " -0.10131809446546924,\n",
              " 0.015882147683036862,\n",
              " 0.2618247138129348,\n",
              " 0.004342688454521237,\n",
              " 0.4038854440053292,\n",
              " 0.1988766458299409,\n",
              " 0.4129196802775077,\n",
              " 1.0497535599602585,\n",
              " 0.38317219416300574,\n",
              " 0.37355211046006787,\n",
              " 0.15441465377807617,\n",
              " -0.2194958527882882,\n",
              " -0.5046145651075591,\n",
              " -0.30895076857672876,\n",
              " 0.5135432349310989,\n",
              " 0.08912814988030249,\n",
              " -0.19976178805033484,\n",
              " -0.9291236135694732,\n",
              " -0.3872626622517892,\n",
              " -0.03933106528388208,\n",
              " 0.365113417307537,\n",
              " 0.2851636674669038,\n",
              " 0.14213132858276367,\n",
              " 0.2752589384714774,\n",
              " 0.2948210504319917,\n",
              " 0.04945911301506811,\n",
              " 0.09056960211859888,\n",
              " -0.1731055842505569,\n",
              " -0.20922605196635047,\n",
              " -0.08219024870130909,\n",
              " -0.03175385793050012,\n",
              " -0.12557946311103052,\n",
              " -0.0007656415303536335,\n",
              " 0.14164712693956005,\n",
              " -0.006695270538330078,\n",
              " -0.48497780164082727,\n",
              " -0.6070496771070708,\n",
              " -0.5295671092139358,\n",
              " -0.2921151055230027,\n",
              " -0.18017421828376,\n",
              " -0.08981076876322547,\n",
              " 0.5941269662645112,\n",
              " 0.8978573481241874,\n",
              " 1.0760501755608445,\n",
              " 0.6769687334696464,\n",
              " -0.04728147718641651,\n",
              " -0.4780716896057129,\n",
              " -0.7263718446095773,\n",
              " -0.8410603735182036,\n",
              " -0.5064624415503616,\n",
              " -0.0757330788506394,\n",
              " -0.217558251486885,\n",
              " -0.15520421663920203,\n",
              " 0.2420704629686128,\n",
              " -0.21506150563557824,\n",
              " 0.6333183182610398,\n",
              " 0.15245930353800574,\n",
              " -0.4037267896864165,\n",
              " -0.03577089309692383,\n",
              " -0.07290848096211633,\n",
              " -0.302238199445938,\n",
              " -0.1124538050757522,\n",
              " -0.46035088433159643,\n",
              " 0.05756915940178686,\n",
              " -0.37213842074076453,\n",
              " 0.3843586709764253,\n",
              " 0.9686352411905936,\n",
              " 1.4486392868889695,\n",
              " 0.7927161852518729,\n",
              " 0.08248498704698193,\n",
              " 0.3073554039001465,\n",
              " 0.43644324938456336,\n",
              " 0.083534505632187,\n",
              " -0.2396186457739944,\n",
              " -0.1936539543999558,\n",
              " 0.30488361252678686,\n",
              " 0.36746843655904016,\n",
              " -0.34794494840834034,\n",
              " -0.367916425069172,\n",
              " -0.21498833762274927,\n",
              " -0.7744873364766427,\n",
              " -0.4592706892225493,\n",
              " -0.17101335525512695,\n",
              " 0.1527270476023368,\n",
              " 0.259468343522812,\n",
              " 0.503018034829033,\n",
              " 0.3168936835394973,\n",
              " -0.06265483962165064,\n",
              " -0.30397931734720984,\n",
              " 0.2913430002000581,\n",
              " -0.15563996632893762,\n",
              " -0.5415454970465774,\n",
              " -0.5791195233662911,\n",
              " 0.36419465806748974,\n",
              " 0.4636549949645996,\n",
              " 0.4394587675730399,\n",
              " 0.001148488786483881,\n",
              " 0.3816992176903611,\n",
              " -0.04084481133354956,\n",
              " 0.09501613510979467,\n",
              " 0.5830083688100167,\n",
              " 1.2132618692186128,\n",
              " 0.457889238993328,\n",
              " -0.5042072402106399,\n",
              " -0.13928302129109582,\n",
              " 0.28047349717881787,\n",
              " 0.647742748260498,\n",
              " 1.0895976225535087,\n",
              " 0.5063193109300386,\n",
              " -0.4009698496924514,\n",
              " -0.184710396660698,\n",
              " -0.3534797297583694,\n",
              " -0.07963315645853797,\n",
              " 0.16598823335435497,\n",
              " 0.4989773432413749,\n",
              " -0.2931209670172805,\n",
              " -0.17673571904500207,\n",
              " -0.03342649671766651,\n",
              " 0.04273176193237305,\n",
              " 0.031684796015422734,\n",
              " 0.40233066346910107,\n",
              " 0.0008674992455368624,\n",
              " -0.2637833489312058,\n",
              " -0.13653980361090845,\n",
              " -0.10798017183939734,\n",
              " -0.28151008817884815]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst_bop_anomaly = np.array(soda_sst_bop_anomaly)"
      ],
      "metadata": {
        "id": "YBQMzEtuR20O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(soda_sst_bop_anomaly, decimals=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPbqGHoIR7Ek",
        "outputId": "5cd07874-866b-46d7-9331-f3a8b31d890e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.15,  0.17, -0.49, -1.13, -0.54, -0.69, -1.48, -1.35, -0.81,\n",
              "       -0.41, -0.27, -0.43,  0.64,  0.6 ,  0.45,  0.58, -0.02, -0.23,\n",
              "        0.03,  0.27,  0.12,  0.18, -0.69,  0.12,  0.26, -0.65, -0.17,\n",
              "       -0.24, -0.9 , -0.57, -0.02, -0.02, -0.1 , -0.5 , -0.32, -0.36,\n",
              "       -0.72, -0.97,  0.17,  0.36, -0.25, -0.35, -0.07, -0.2 , -0.17,\n",
              "       -0.14, -0.19, -1.02, -0.88, -0.76,  0.07,  0.67,  0.08,  0.28,\n",
              "        0.81,  0.43,  0.78,  0.25,  1.07,  1.29,  1.11, -0.17,  0.12,\n",
              "       -0.21,  0.07, -0.17,  0.44,  0.49,  0.28,  0.35, -0.16, -0.2 ,\n",
              "        0.62,  0.27,  0.53,  0.23,  0.24, -0.18, -0.32, -0.25, -0.2 ,\n",
              "        0.1 , -0.21, -0.83, -0.75, -0.17, -0.37, -0.73, -0.47,  0.16,\n",
              "        0.38,  0.46,  0.34,  0.37,  0.31,  0.21, -0.2 ,  0.78,  0.6 ,\n",
              "        0.07,  0.16,  0.76,  0.9 ,  0.6 ,  0.74,  0.74,  0.53,  1.12,\n",
              "        0.65, -0.25,  0.02,  0.11,  0.56,  0.43,  0.66,  0.7 ,  0.7 ,\n",
              "        0.49,  0.83,  0.03,  0.35,  0.96,  1.29,  0.58,  0.36,  0.1 ,\n",
              "       -0.09,  0.24,  0.1 ,  0.69,  0.72,  0.55, -0.46,  0.46, -0.24,\n",
              "       -0.62, -0.62, -0.46, -1.  , -1.05, -0.96, -0.93, -1.9 , -1.98,\n",
              "       -1.41, -0.31, -1.21, -1.46, -1.63, -1.8 , -1.46, -1.36, -1.36,\n",
              "       -1.53, -0.7 , -0.62, -0.75, -1.66, -1.63, -0.9 , -0.68, -0.31,\n",
              "        0.19,  0.18, -0.73, -0.61, -0.82, -0.83,  0.97, -1.07, -1.07,\n",
              "       -1.21, -1.07, -0.85, -0.38, -0.14, -0.15, -0.22,  0.3 ,  0.39,\n",
              "       -0.25, -0.06,  0.24,  0.56,  0.31, -0.03, -0.34,  0.09, -0.01,\n",
              "        0.02,  0.34,  1.01,  0.75,  0.93,  0.19,  0.39,  0.66,  0.02,\n",
              "        0.24,  0.09,  0.08, -0.13, -0.23, -0.26, -0.75, -1.02, -0.84,\n",
              "       -0.9 , -0.74, -0.32,  0.17,  0.24,  0.  , -0.06,  0.29,  0.95,\n",
              "        0.2 ,  1.61,  1.21,  1.25,  1.21,  1.25,  0.92,  1.4 ,  1.44,\n",
              "        1.43,  0.87,  0.17,  0.06, -0.5 , -0.15,  0.76,  0.9 ,  1.07,\n",
              "        0.51, -0.15,  0.58,  1.08,  0.78, -0.16, -0.67, -0.51, -0.06,\n",
              "       -0.04,  0.19,  0.05,  0.15, -0.11, -0.15, -0.31, -0.75, -0.38,\n",
              "       -0.19,  0.09,  0.05, -0.31,  0.28, -0.02, -0.06,  0.05,  0.07,\n",
              "        0.54,  0.85,  0.79,  0.28, -0.16,  0.26,  0.64,  0.59,  0.51,\n",
              "        0.6 ,  0.25,  0.11, -0.46, -0.9 , -0.4 , -0.28, -0.01,  0.25,\n",
              "        0.48,  0.27,  0.58,  0.36,  0.26, -0.03, -0.03,  0.09,  0.78,\n",
              "        1.  ,  0.48, -0.54, -0.52, -0.29,  0.14, -0.33,  0.02, -0.33,\n",
              "       -0.34,  0.32, -1.4 , -1.5 , -0.55,  0.62,  1.02,  0.26, -0.28,\n",
              "       -0.1 ,  0.02,  0.26,  0.  ,  0.4 ,  0.2 ,  0.41,  1.05,  0.38,\n",
              "        0.37,  0.15, -0.22, -0.5 , -0.31,  0.51,  0.09, -0.2 , -0.93,\n",
              "       -0.39, -0.04,  0.37,  0.29,  0.14,  0.28,  0.29,  0.05,  0.09,\n",
              "       -0.17, -0.21, -0.08, -0.03, -0.13, -0.  ,  0.14, -0.01, -0.48,\n",
              "       -0.61, -0.53, -0.29, -0.18, -0.09,  0.59,  0.9 ,  1.08,  0.68,\n",
              "       -0.05, -0.48, -0.73, -0.84, -0.51, -0.08, -0.22, -0.16,  0.24,\n",
              "       -0.22,  0.63,  0.15, -0.4 , -0.04, -0.07, -0.3 , -0.11, -0.46,\n",
              "        0.06, -0.37,  0.38,  0.97,  1.45,  0.79,  0.08,  0.31,  0.44,\n",
              "        0.08, -0.24, -0.19,  0.3 ,  0.37, -0.35, -0.37, -0.21, -0.77,\n",
              "       -0.46, -0.17,  0.15,  0.26,  0.5 ,  0.32, -0.06, -0.3 ,  0.29,\n",
              "       -0.16, -0.54, -0.58,  0.36,  0.46,  0.44,  0.  ,  0.38, -0.04,\n",
              "        0.1 ,  0.58,  1.21,  0.46, -0.5 , -0.14,  0.28,  0.65,  1.09,\n",
              "        0.51, -0.4 , -0.18, -0.35, -0.08,  0.17,  0.5 , -0.29, -0.18,\n",
              "       -0.03,  0.04,  0.03,  0.4 ,  0.  , -0.26, -0.14, -0.11, -0.28])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------"
      ],
      "metadata": {
        "id": "fJ3n_i30sO2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst_anomaly_transposed = soda_sst_anomaly.transpose(1,2,0)\n",
        "soda_sst_anomaly_flattened = soda_sst_anomaly_transposed.reshape(soda_sst_anomaly.shape[1] * soda_sst_anomaly.shape[2],432)\n",
        "soda_sst_anomaly_flattened.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJtXLYfpeCP-",
        "outputId": "61cbe11a-d69e-4fb3-cd3c-a85125f596dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9504, 432)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dropna(arr, *args, **kwarg):\n",
        "    assert isinstance(arr, np.ndarray)\n",
        "    dropped=pd.DataFrame(arr).dropna(*args, **kwarg).values\n",
        "    if arr.ndim==1:\n",
        "        dropped=dropped.flatten()\n",
        "    return dropped\n",
        "\n",
        "soda_sst_anomaly_ocean_flattened = dropna(soda_sst_anomaly_flattened)\n",
        "soda_sst_anomaly_ocean_flattened.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQTW35kuey5M",
        "outputId": "ee506996-3950-4240-bf52-416e36887157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6924, 432)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_matrix = soda_sst_anomaly_ocean_flattened"
      ],
      "metadata": {
        "id": "b3KYLgDJgLSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lons, lats = np.meshgrid(soda_smaller.longitude.values, soda_smaller.latitude.values)\n",
        "\n",
        "soda_time_1 = soda_smaller.temp.isel(depth=0,time=240)\n",
        "\n",
        "soda_time_1_lons, soda_time_1_lats = np.meshgrid(soda_time_1.longitude.values, soda_time_1.latitude.values)\n",
        "\n",
        "soda_masked = soda_time_1.where(abs(soda_time_1_lons) + abs(soda_time_1_lats) > 0)\n",
        "soda_masked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "WeygILKTe48m",
        "outputId": "e2136603-e419-4603-b5d6-d2395f7dc98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
              "<defs>\n",
              "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
              "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "</symbol>\n",
              "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
              "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "</symbol>\n",
              "</defs>\n",
              "</svg>\n",
              "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
              " *\n",
              " */\n",
              "\n",
              ":root {\n",
              "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
              "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
              "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
              "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
              "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
              "  --xr-background-color: var(--jp-layout-color0, white);\n",
              "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
              "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
              "}\n",
              "\n",
              "html[theme=dark],\n",
              "body.vscode-dark {\n",
              "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
              "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
              "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
              "  --xr-border-color: #1F1F1F;\n",
              "  --xr-disabled-color: #515151;\n",
              "  --xr-background-color: #111111;\n",
              "  --xr-background-color-row-even: #111111;\n",
              "  --xr-background-color-row-odd: #313131;\n",
              "}\n",
              "\n",
              ".xr-wrap {\n",
              "  display: block;\n",
              "  min-width: 300px;\n",
              "  max-width: 700px;\n",
              "}\n",
              "\n",
              ".xr-text-repr-fallback {\n",
              "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-header {\n",
              "  padding-top: 6px;\n",
              "  padding-bottom: 6px;\n",
              "  margin-bottom: 4px;\n",
              "  border-bottom: solid 1px var(--xr-border-color);\n",
              "}\n",
              "\n",
              ".xr-header > div,\n",
              ".xr-header > ul {\n",
              "  display: inline;\n",
              "  margin-top: 0;\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-obj-type,\n",
              ".xr-array-name {\n",
              "  margin-left: 2px;\n",
              "  margin-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-obj-type {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-sections {\n",
              "  padding-left: 0 !important;\n",
              "  display: grid;\n",
              "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
              "}\n",
              "\n",
              ".xr-section-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-section-item input {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-item input + label {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label {\n",
              "  cursor: pointer;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label:hover {\n",
              "  color: var(--xr-font-color0);\n",
              "}\n",
              "\n",
              ".xr-section-summary {\n",
              "  grid-column: 1;\n",
              "  color: var(--xr-font-color2);\n",
              "  font-weight: 500;\n",
              "}\n",
              "\n",
              ".xr-section-summary > span {\n",
              "  display: inline-block;\n",
              "  padding-left: 0.5em;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in + label:before {\n",
              "  display: inline-block;\n",
              "  content: '►';\n",
              "  font-size: 11px;\n",
              "  width: 15px;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label:before {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label:before {\n",
              "  content: '▼';\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label > span {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-summary,\n",
              ".xr-section-inline-details {\n",
              "  padding-top: 4px;\n",
              "  padding-bottom: 4px;\n",
              "}\n",
              "\n",
              ".xr-section-inline-details {\n",
              "  grid-column: 2 / -1;\n",
              "}\n",
              "\n",
              ".xr-section-details {\n",
              "  display: none;\n",
              "  grid-column: 1 / -1;\n",
              "  margin-bottom: 5px;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked ~ .xr-section-details {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-array-wrap {\n",
              "  grid-column: 1 / -1;\n",
              "  display: grid;\n",
              "  grid-template-columns: 20px auto;\n",
              "}\n",
              "\n",
              ".xr-array-wrap > label {\n",
              "  grid-column: 1;\n",
              "  vertical-align: top;\n",
              "}\n",
              "\n",
              ".xr-preview {\n",
              "  color: var(--xr-font-color3);\n",
              "}\n",
              "\n",
              ".xr-array-preview,\n",
              ".xr-array-data {\n",
              "  padding: 0 5px !important;\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-array-data,\n",
              ".xr-array-in:checked ~ .xr-array-preview {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-array-in:checked ~ .xr-array-data,\n",
              ".xr-array-preview {\n",
              "  display: inline-block;\n",
              "}\n",
              "\n",
              ".xr-dim-list {\n",
              "  display: inline-block !important;\n",
              "  list-style: none;\n",
              "  padding: 0 !important;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list li {\n",
              "  display: inline-block;\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list:before {\n",
              "  content: '(';\n",
              "}\n",
              "\n",
              ".xr-dim-list:after {\n",
              "  content: ')';\n",
              "}\n",
              "\n",
              ".xr-dim-list li:not(:last-child):after {\n",
              "  content: ',';\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-has-index {\n",
              "  font-weight: bold;\n",
              "}\n",
              "\n",
              ".xr-var-list,\n",
              ".xr-var-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-var-item > div,\n",
              ".xr-var-item label,\n",
              ".xr-var-item > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-even);\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-var-item > .xr-var-name:hover span {\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-var-list > li:nth-child(odd) > div,\n",
              ".xr-var-list > li:nth-child(odd) > label,\n",
              ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-odd);\n",
              "}\n",
              "\n",
              ".xr-var-name {\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-var-dims {\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-var-dtype {\n",
              "  grid-column: 3;\n",
              "  text-align: right;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-var-preview {\n",
              "  grid-column: 4;\n",
              "}\n",
              "\n",
              ".xr-var-name,\n",
              ".xr-var-dims,\n",
              ".xr-var-dtype,\n",
              ".xr-preview,\n",
              ".xr-attrs dt {\n",
              "  white-space: nowrap;\n",
              "  overflow: hidden;\n",
              "  text-overflow: ellipsis;\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-var-name:hover,\n",
              ".xr-var-dims:hover,\n",
              ".xr-var-dtype:hover,\n",
              ".xr-attrs dt:hover {\n",
              "  overflow: visible;\n",
              "  width: auto;\n",
              "  z-index: 1;\n",
              "}\n",
              "\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  display: none;\n",
              "  background-color: var(--xr-background-color) !important;\n",
              "  padding-bottom: 5px !important;\n",
              "}\n",
              "\n",
              ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
              ".xr-var-data-in:checked ~ .xr-var-data {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              ".xr-var-data > table {\n",
              "  float: right;\n",
              "}\n",
              "\n",
              ".xr-var-name span,\n",
              ".xr-var-data,\n",
              ".xr-attrs {\n",
              "  padding-left: 25px !important;\n",
              "}\n",
              "\n",
              ".xr-attrs,\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  grid-column: 1 / -1;\n",
              "}\n",
              "\n",
              "dl.xr-attrs {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  display: grid;\n",
              "  grid-template-columns: 125px auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt,\n",
              ".xr-attrs dd {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  float: left;\n",
              "  padding-right: 10px;\n",
              "  width: auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt {\n",
              "  font-weight: normal;\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-attrs dt:hover span {\n",
              "  display: inline-block;\n",
              "  background: var(--xr-background-color);\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-attrs dd {\n",
              "  grid-column: 2;\n",
              "  white-space: pre-wrap;\n",
              "  word-break: break-all;\n",
              "}\n",
              "\n",
              ".xr-icon-database,\n",
              ".xr-icon-file-text2 {\n",
              "  display: inline-block;\n",
              "  vertical-align: middle;\n",
              "  width: 1em;\n",
              "  height: 1.5em !important;\n",
              "  stroke-width: 0;\n",
              "  stroke: currentColor;\n",
              "  fill: currentColor;\n",
              "}\n",
              "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;temp&#x27; (latitude: 66, longitude: 144)&gt;\n",
              "array([[       nan,        nan,        nan, ...,        nan,        nan,\n",
              "               nan],\n",
              "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
              "               nan],\n",
              "       [-1.1247305, -1.4289024, -1.4716144, ..., -1.7336361, -1.7187185,\n",
              "        -1.6495545],\n",
              "       ...,\n",
              "       [-1.7470648, -1.7409257, -1.7132384, ..., -1.7103977, -1.7174913,\n",
              "        -1.7176341],\n",
              "       [-1.7337334, -1.7335713, -1.740988 , ..., -1.7035117, -1.7163125,\n",
              "        -1.7244432],\n",
              "       [-1.7108924, -1.7107269, -1.7117507, ..., -1.7120712, -1.7136484,\n",
              "        -1.7127907]], dtype=float32)\n",
              "Coordinates:\n",
              "    time       float64 9.48e+08\n",
              "    depth      float32 5.034\n",
              "  * latitude   (latitude) float32 -74.75 -72.25 -69.75 ... 82.75 85.25 87.75\n",
              "  * longitude  (longitude) float32 0.25 2.75 5.25 7.75 ... 352.8 355.2 357.8</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'temp'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>latitude</span>: 66</li><li><span class='xr-has-index'>longitude</span>: 144</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-3a6aceae-5e90-459b-9481-ba1ee1544b8e' class='xr-array-in' type='checkbox' checked><label for='section-3a6aceae-5e90-459b-9481-ba1ee1544b8e' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>nan nan nan nan nan nan ... -1.703 -1.707 -1.71 -1.712 -1.714 -1.713</span></div><div class='xr-array-data'><pre>array([[       nan,        nan,        nan, ...,        nan,        nan,\n",
              "               nan],\n",
              "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
              "               nan],\n",
              "       [-1.1247305, -1.4289024, -1.4716144, ..., -1.7336361, -1.7187185,\n",
              "        -1.6495545],\n",
              "       ...,\n",
              "       [-1.7470648, -1.7409257, -1.7132384, ..., -1.7103977, -1.7174913,\n",
              "        -1.7176341],\n",
              "       [-1.7337334, -1.7335713, -1.740988 , ..., -1.7035117, -1.7163125,\n",
              "        -1.7244432],\n",
              "       [-1.7108924, -1.7107269, -1.7117507, ..., -1.7120712, -1.7136484,\n",
              "        -1.7127907]], dtype=float32)</pre></div></div></li><li class='xr-section-item'><input id='section-0a1c64c1-e1f4-4f46-952e-05710c1d3b67' class='xr-section-summary-in' type='checkbox'  checked><label for='section-0a1c64c1-e1f4-4f46-952e-05710c1d3b67' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>time</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>9.48e+08</div><input id='attrs-5a610725-39f1-492a-9c50-24c840e57b03' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-5a610725-39f1-492a-9c50-24c840e57b03' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-41cf3d6a-0255-4a3a-8dcf-6930f3e1fda0' class='xr-var-data-in' type='checkbox'><label for='data-41cf3d6a-0255-4a3a-8dcf-6930f3e1fda0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Time</dd><dt><span>actual_range :</span></dt><dd>[3.168288e+08 1.450224e+09]</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>ioos_category :</span></dt><dd>Time</dd><dt><span>long_name :</span></dt><dd>Time</dd><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>time_origin :</span></dt><dd>01-JAN-1970 00:00:00</dd><dt><span>units :</span></dt><dd>seconds since 1970-01-01T00:00:00Z</dd></dl></div><div class='xr-var-data'><pre>array(9.479808e+08)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>depth</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>5.034</div><input id='attrs-14ff8d7e-1faa-4291-8e83-76a6ecdc7edc' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-14ff8d7e-1faa-4291-8e83-76a6ecdc7edc' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3a0a2d9b-a302-48eb-aced-ed7b4ebd9579' class='xr-var-data-in' type='checkbox'><label for='data-3a0a2d9b-a302-48eb-aced-ed7b4ebd9579' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Height</dd><dt><span>_CoordinateZisPositive :</span></dt><dd>down</dd><dt><span>actual_range :</span></dt><dd>[5.03355 5.03355]</dd><dt><span>axis :</span></dt><dd>Z</dd><dt><span>ioos_category :</span></dt><dd>Location</dd><dt><span>long_name :</span></dt><dd>Depth</dd><dt><span>positive :</span></dt><dd>down</dd><dt><span>standard_name :</span></dt><dd>depth</dd><dt><span>units :</span></dt><dd>m</dd></dl></div><div class='xr-var-data'><pre>array(5.03355, dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-74.75 -72.25 ... 85.25 87.75</div><input id='attrs-2aac504e-aef2-47f1-a81f-d67384a1b9b3' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2aac504e-aef2-47f1-a81f-d67384a1b9b3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e744fd60-476e-4f19-b26d-9c116192714e' class='xr-var-data-in' type='checkbox'><label for='data-e744fd60-476e-4f19-b26d-9c116192714e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Lat</dd><dt><span>actual_range :</span></dt><dd>[-74.75  89.75]</dd><dt><span>axis :</span></dt><dd>Y</dd><dt><span>ioos_category :</span></dt><dd>Location</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd></dl></div><div class='xr-var-data'><pre>array([-74.75, -72.25, -69.75, -67.25, -64.75, -62.25, -59.75, -57.25, -54.75,\n",
              "       -52.25, -49.75, -47.25, -44.75, -42.25, -39.75, -37.25, -34.75, -32.25,\n",
              "       -29.75, -27.25, -24.75, -22.25, -19.75, -17.25, -14.75, -12.25,  -9.75,\n",
              "        -7.25,  -4.75,  -2.25,   0.25,   2.75,   5.25,   7.75,  10.25,  12.75,\n",
              "        15.25,  17.75,  20.25,  22.75,  25.25,  27.75,  30.25,  32.75,  35.25,\n",
              "        37.75,  40.25,  42.75,  45.25,  47.75,  50.25,  52.75,  55.25,  57.75,\n",
              "        60.25,  62.75,  65.25,  67.75,  70.25,  72.75,  75.25,  77.75,  80.25,\n",
              "        82.75,  85.25,  87.75], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.25 2.75 5.25 ... 355.2 357.8</div><input id='attrs-16d6fc70-879f-4c56-a5e4-bc6da24da276' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-16d6fc70-879f-4c56-a5e4-bc6da24da276' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b7570337-9a61-48ec-a758-fc706218cf25' class='xr-var-data-in' type='checkbox'><label for='data-b7570337-9a61-48ec-a758-fc706218cf25' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_CoordinateAxisType :</span></dt><dd>Lon</dd><dt><span>actual_range :</span></dt><dd>[2.5000e-01 3.5975e+02]</dd><dt><span>axis :</span></dt><dd>X</dd><dt><span>ioos_category :</span></dt><dd>Location</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>modulo :</span></dt><dd>360.0</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd></dl></div><div class='xr-var-data'><pre>array([2.5000e-01, 2.7500e+00, 5.2500e+00, 7.7500e+00, 1.0250e+01, 1.2750e+01,\n",
              "       1.5250e+01, 1.7750e+01, 2.0250e+01, 2.2750e+01, 2.5250e+01, 2.7750e+01,\n",
              "       3.0250e+01, 3.2750e+01, 3.5250e+01, 3.7750e+01, 4.0250e+01, 4.2750e+01,\n",
              "       4.5250e+01, 4.7750e+01, 5.0250e+01, 5.2750e+01, 5.5250e+01, 5.7750e+01,\n",
              "       6.0250e+01, 6.2750e+01, 6.5250e+01, 6.7750e+01, 7.0250e+01, 7.2750e+01,\n",
              "       7.5250e+01, 7.7750e+01, 8.0250e+01, 8.2750e+01, 8.5250e+01, 8.7750e+01,\n",
              "       9.0250e+01, 9.2750e+01, 9.5250e+01, 9.7750e+01, 1.0025e+02, 1.0275e+02,\n",
              "       1.0525e+02, 1.0775e+02, 1.1025e+02, 1.1275e+02, 1.1525e+02, 1.1775e+02,\n",
              "       1.2025e+02, 1.2275e+02, 1.2525e+02, 1.2775e+02, 1.3025e+02, 1.3275e+02,\n",
              "       1.3525e+02, 1.3775e+02, 1.4025e+02, 1.4275e+02, 1.4525e+02, 1.4775e+02,\n",
              "       1.5025e+02, 1.5275e+02, 1.5525e+02, 1.5775e+02, 1.6025e+02, 1.6275e+02,\n",
              "       1.6525e+02, 1.6775e+02, 1.7025e+02, 1.7275e+02, 1.7525e+02, 1.7775e+02,\n",
              "       1.8025e+02, 1.8275e+02, 1.8525e+02, 1.8775e+02, 1.9025e+02, 1.9275e+02,\n",
              "       1.9525e+02, 1.9775e+02, 2.0025e+02, 2.0275e+02, 2.0525e+02, 2.0775e+02,\n",
              "       2.1025e+02, 2.1275e+02, 2.1525e+02, 2.1775e+02, 2.2025e+02, 2.2275e+02,\n",
              "       2.2525e+02, 2.2775e+02, 2.3025e+02, 2.3275e+02, 2.3525e+02, 2.3775e+02,\n",
              "       2.4025e+02, 2.4275e+02, 2.4525e+02, 2.4775e+02, 2.5025e+02, 2.5275e+02,\n",
              "       2.5525e+02, 2.5775e+02, 2.6025e+02, 2.6275e+02, 2.6525e+02, 2.6775e+02,\n",
              "       2.7025e+02, 2.7275e+02, 2.7525e+02, 2.7775e+02, 2.8025e+02, 2.8275e+02,\n",
              "       2.8525e+02, 2.8775e+02, 2.9025e+02, 2.9275e+02, 2.9525e+02, 2.9775e+02,\n",
              "       3.0025e+02, 3.0275e+02, 3.0525e+02, 3.0775e+02, 3.1025e+02, 3.1275e+02,\n",
              "       3.1525e+02, 3.1775e+02, 3.2025e+02, 3.2275e+02, 3.2525e+02, 3.2775e+02,\n",
              "       3.3025e+02, 3.3275e+02, 3.3525e+02, 3.3775e+02, 3.4025e+02, 3.4275e+02,\n",
              "       3.4525e+02, 3.4775e+02, 3.5025e+02, 3.5275e+02, 3.5525e+02, 3.5775e+02],\n",
              "      dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-ac0a6bad-038c-4e8e-8017-35b693a4e437' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-ac0a6bad-038c-4e8e-8017-35b693a4e437' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
            ],
            "text/plain": [
              "<xarray.DataArray 'temp' (latitude: 66, longitude: 144)>\n",
              "array([[       nan,        nan,        nan, ...,        nan,        nan,\n",
              "               nan],\n",
              "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
              "               nan],\n",
              "       [-1.1247305, -1.4289024, -1.4716144, ..., -1.7336361, -1.7187185,\n",
              "        -1.6495545],\n",
              "       ...,\n",
              "       [-1.7470648, -1.7409257, -1.7132384, ..., -1.7103977, -1.7174913,\n",
              "        -1.7176341],\n",
              "       [-1.7337334, -1.7335713, -1.740988 , ..., -1.7035117, -1.7163125,\n",
              "        -1.7244432],\n",
              "       [-1.7108924, -1.7107269, -1.7117507, ..., -1.7120712, -1.7136484,\n",
              "        -1.7127907]], dtype=float32)\n",
              "Coordinates:\n",
              "    time       float64 9.48e+08\n",
              "    depth      float32 5.034\n",
              "  * latitude   (latitude) float32 -74.75 -72.25 -69.75 ... 82.75 85.25 87.75\n",
              "  * longitude  (longitude) float32 0.25 2.75 5.25 7.75 ... 352.8 355.2 357.8"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soda_masked.values.flatten()[soda_masked.notnull().values.flatten()]\n",
        "\n",
        "len(soda_masked.values.flatten()[soda_masked.notnull().values.flatten()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL6xQqYxfbOl",
        "outputId": "8768cdba-f081-4e3c-c1aa-a963942003c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6924"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(soda_time_1_lons.flatten()[soda_masked.notnull().values.flatten()])\n",
        "print(soda_time_1_lats.flatten()[soda_masked.notnull().values.flatten()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B2IlAKrffdc",
        "outputId": "3942a163-8624-4fb2-c55c-91d32e8c1632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[162.75 165.25 167.75 ... 352.75 355.25 357.75]\n",
            "[-74.75 -74.75 -74.75 ...  87.75  87.75  87.75]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "\n",
        "lons_ocean = soda_time_1_lons.flatten()[soda_masked.notnull().values.flatten()]\n",
        "lons_ocean = lons_ocean[::]\n",
        "\n",
        "lats_ocean = soda_time_1_lats.flatten()[soda_masked.notnull().values.flatten()]\n",
        "lats_ocean = lats_ocean[::]\n",
        "\n",
        "lons_ocean *= np.pi/180\n",
        "lats_ocean *= np.pi/180\n",
        "\n",
        "points_ocean = np.concatenate([np.expand_dims(lats_ocean.flatten(),-1), np.expand_dims(lons_ocean.flatten(),-1)],-1)\n",
        "\n",
        "distance_ocean = 6371*haversine_distances(points_ocean)"
      ],
      "metadata": {
        "id": "pnRxxNzTfiBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance_ocean_diag = distance_ocean\n",
        "distance_ocean_diag[distance_ocean_diag==0] = 1\n",
        "\n",
        "distance_ocean_recip = np.reciprocal(distance_ocean_diag)\n",
        "\n",
        "distance_ocean_recip.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idh7C_j2ft6u",
        "outputId": "fc524c4c-f475-4ef5-ceb3-c5cad3271f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6924, 6924)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjacency_matrix = distance_ocean_recip"
      ],
      "metadata": {
        "id": "58z4jaIkfk3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRW5rM1b1z3C"
      },
      "outputs": [],
      "source": [
        "lead_month = 0\n",
        "\n",
        "feature_matrix = feature_matrix[:,:len(feature_matrix[0])-lead_month:]\n",
        "adjacency_matrix = adjacency_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYwZwpbqnau3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90593f50-8071-4d6c-cf0f-5605e86f786c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats(\"svg\", \"pdf\") # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install --quiet pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_feats = torch.tensor(np.expand_dims(feature_matrix, axis=0)).float()\n",
        "adj_matrix = torch.tensor(np.expand_dims(adjacency_matrix, axis=0)).float()\n",
        "\n",
        "print(node_feats.shape)\n",
        "print(adj_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DarMgxi8gQm2",
        "outputId": "4b1452e7-f5c4-4ba6-f273-8d82adc2d657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6924, 432])\n",
            "torch.Size([1, 6924, 6924])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Linear(c_in, c_out)\n",
        "\n",
        "    def forward(self, node_feats, adj_matrix):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            node_feats - Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
        "            adj_matrix - Batch of adjacency matrices of the graph. If there is an edge from i to j, adj_matrix[b,i,j]=1 else 0.\n",
        "                         Supports directed edges by non-symmetric matrices. Assumes to already have added the identity connections.\n",
        "                         Shape: [batch_size, num_nodes, num_nodes]\n",
        "        \"\"\"\n",
        "        # Num neighbours = number of incoming edges\n",
        "        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
        "        node_feats = self.projection(node_feats)\n",
        "        node_feats = torch.bmm(adj_matrix, node_feats)\n",
        "        node_feats = node_feats / num_neighbours\n",
        "        return node_feats"
      ],
      "metadata": {
        "id": "km_P5S0fg85h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Node features:\\n\", node_feats)\n",
        "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5aEds_0g-hO",
        "outputId": "360dc466-f175-49d6-c2cc-687d33ae5bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features:\n",
            " tensor([[[-7.9552e-02, -7.8261e-02,  4.1625e-02,  ..., -3.3746e-03,\n",
            "           8.1046e-03, -4.8462e-02],\n",
            "         [ 1.1985e+00,  3.5482e-01,  1.2477e-01,  ..., -1.4804e-02,\n",
            "          -9.4055e-03, -1.1167e-01],\n",
            "         [ 1.7171e+00,  1.1768e+00,  1.3464e-01,  ..., -1.2377e-04,\n",
            "           1.9625e-03, -8.1020e-02],\n",
            "         ...,\n",
            "         [-9.9387e-02, -9.5504e-02, -9.8592e-02,  ...,  8.6997e-02,\n",
            "           6.8804e-02,  6.4023e-02],\n",
            "         [-1.0047e-01, -9.3609e-02, -9.5575e-02,  ...,  8.7748e-02,\n",
            "           7.1659e-02,  6.7239e-02],\n",
            "         [-9.4762e-02, -8.9556e-02, -9.3895e-02,  ...,  8.8551e-02,\n",
            "           7.4358e-02,  7.0678e-02]]])\n",
            "\n",
            "Adjacency matrix:\n",
            " tensor([[[1.0000e+00, 1.3677e-02, 6.8402e-03,  ..., 5.3864e-05,\n",
            "          5.3872e-05, 5.3880e-05],\n",
            "         [1.3677e-02, 1.0000e+00, 1.3677e-02,  ..., 5.3859e-05,\n",
            "          5.3864e-05, 5.3872e-05],\n",
            "         [6.8402e-03, 1.3677e-02, 1.0000e+00,  ..., 5.3855e-05,\n",
            "          5.3859e-05, 5.3864e-05],\n",
            "         ...,\n",
            "         [5.3864e-05, 5.3859e-05, 5.3855e-05,  ..., 1.0000e+00,\n",
            "          9.1636e-02, 4.5828e-02],\n",
            "         [5.3872e-05, 5.3864e-05, 5.3859e-05,  ..., 9.1636e-02,\n",
            "          1.0000e+00, 9.1635e-02],\n",
            "         [5.3880e-05, 5.3872e-05, 5.3864e-05,  ..., 4.5828e-02,\n",
            "          9.1635e-02, 1.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_list = []\n",
        "for i in range(0, feature_matrix.shape[1]):\n",
        "  element = [0] * feature_matrix.shape[1]\n",
        "  element[i] = 1\n",
        "  element = [float(item) for item in element] # Convert the type into float.\n",
        "  temp_list.append(element)\n",
        "\n",
        "layer = GCNLayer(c_in=feature_matrix.shape[1], c_out=feature_matrix.shape[1])\n",
        "layer.projection.weight.data = torch.tensor(temp_list)\n",
        "\n",
        "layer.projection.bias.data = torch.Tensor([0] * feature_matrix.shape[1])"
      ],
      "metadata": {
        "id": "Pv8me1ttg-G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out_feats = layer(node_feats, adj_matrix)\n",
        "\n",
        "print(\"Adjacency matrix\")\n",
        "print(np.round(np.array(adj_matrix), decimals=3))\n",
        "print(\"Input features\")\n",
        "print(np.round(np.array(node_feats), decimals=3))\n",
        "print(\"Output features\")\n",
        "print(np.round(np.array(out_feats), decimals=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-KP1n0LhDxr",
        "outputId": "01349b49-7f58-4e9b-e5f5-19983f374c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjacency matrix\n",
            "[[[1.    0.014 0.007 ... 0.    0.    0.   ]\n",
            "  [0.014 1.    0.014 ... 0.    0.    0.   ]\n",
            "  [0.007 0.014 1.    ... 0.    0.    0.   ]\n",
            "  ...\n",
            "  [0.    0.    0.    ... 1.    0.092 0.046]\n",
            "  [0.    0.    0.    ... 0.092 1.    0.092]\n",
            "  [0.    0.    0.    ... 0.046 0.092 1.   ]]]\n",
            "Input features\n",
            "[[[-0.08  -0.078  0.042 ... -0.003  0.008 -0.048]\n",
            "  [ 1.198  0.355  0.125 ... -0.015 -0.009 -0.112]\n",
            "  [ 1.717  1.177  0.135 ... -0.     0.002 -0.081]\n",
            "  ...\n",
            "  [-0.099 -0.096 -0.099 ...  0.087  0.069  0.064]\n",
            "  [-0.1   -0.094 -0.096 ...  0.088  0.072  0.067]\n",
            "  [-0.095 -0.09  -0.094 ...  0.089  0.074  0.071]]]\n",
            "Output features\n",
            "[[[ 0.296  0.161  0.13  ...  0.097  0.094  0.011]\n",
            "  [ 0.9    0.37   0.17  ...  0.091  0.085 -0.019]\n",
            "  [ 1.143  0.759  0.176 ...  0.097  0.09  -0.006]\n",
            "  ...\n",
            "  [-0.085 -0.065 -0.066 ...  0.17   0.134  0.142]\n",
            "  [-0.085 -0.065 -0.065 ...  0.17   0.135  0.143]\n",
            "  [-0.084 -0.064 -0.065 ...  0.171  0.136  0.144]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(soda_time_1_lons.flatten()[soda_masked.notnull().values.flatten()])\n",
        "print(soda_time_1_lats.flatten()[soda_masked.notnull().values.flatten()])\n",
        "\n",
        "lons_smaller = soda_time_1_lons.flatten()[soda_masked.notnull().values.flatten()]\n",
        "lats_smaller = soda_time_1_lats.flatten()[soda_masked.notnull().values.flatten()]\n",
        "\n",
        "for i in range(len(lats_smaller)):\n",
        "  if lats_smaller[i] > -39 and lats_smaller[i] < -34:\n",
        "    print(\"The position: \", str(i), \"; the latitude: \", str(lats_smaller[i]), \"; the longitude: \", str(lons_smaller[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yODkg9JYKkKs",
        "outputId": "891d9cd6-b096-4418-9d4b-a21ac70ca7e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[162.75 165.25 167.75 ... 352.75 355.25 357.75]\n",
            "[-74.75 -74.75 -74.75 ...  87.75  87.75  87.75]\n",
            "The position:  1880 ; the latitude:  -37.25 ; the longitude:  0.25\n",
            "The position:  1881 ; the latitude:  -37.25 ; the longitude:  2.75\n",
            "The position:  1882 ; the latitude:  -37.25 ; the longitude:  5.25\n",
            "The position:  1883 ; the latitude:  -37.25 ; the longitude:  7.75\n",
            "The position:  1884 ; the latitude:  -37.25 ; the longitude:  10.25\n",
            "The position:  1885 ; the latitude:  -37.25 ; the longitude:  12.75\n",
            "The position:  1886 ; the latitude:  -37.25 ; the longitude:  15.25\n",
            "The position:  1887 ; the latitude:  -37.25 ; the longitude:  17.75\n",
            "The position:  1888 ; the latitude:  -37.25 ; the longitude:  20.25\n",
            "The position:  1889 ; the latitude:  -37.25 ; the longitude:  22.75\n",
            "The position:  1890 ; the latitude:  -37.25 ; the longitude:  25.25\n",
            "The position:  1891 ; the latitude:  -37.25 ; the longitude:  27.75\n",
            "The position:  1892 ; the latitude:  -37.25 ; the longitude:  30.25\n",
            "The position:  1893 ; the latitude:  -37.25 ; the longitude:  32.75\n",
            "The position:  1894 ; the latitude:  -37.25 ; the longitude:  35.25\n",
            "The position:  1895 ; the latitude:  -37.25 ; the longitude:  37.75\n",
            "The position:  1896 ; the latitude:  -37.25 ; the longitude:  40.25\n",
            "The position:  1897 ; the latitude:  -37.25 ; the longitude:  42.75\n",
            "The position:  1898 ; the latitude:  -37.25 ; the longitude:  45.25\n",
            "The position:  1899 ; the latitude:  -37.25 ; the longitude:  47.75\n",
            "The position:  1900 ; the latitude:  -37.25 ; the longitude:  50.25\n",
            "The position:  1901 ; the latitude:  -37.25 ; the longitude:  52.75\n",
            "The position:  1902 ; the latitude:  -37.25 ; the longitude:  55.25\n",
            "The position:  1903 ; the latitude:  -37.25 ; the longitude:  57.75\n",
            "The position:  1904 ; the latitude:  -37.25 ; the longitude:  60.25\n",
            "The position:  1905 ; the latitude:  -37.25 ; the longitude:  62.75\n",
            "The position:  1906 ; the latitude:  -37.25 ; the longitude:  65.25\n",
            "The position:  1907 ; the latitude:  -37.25 ; the longitude:  67.75\n",
            "The position:  1908 ; the latitude:  -37.25 ; the longitude:  70.25\n",
            "The position:  1909 ; the latitude:  -37.25 ; the longitude:  72.75\n",
            "The position:  1910 ; the latitude:  -37.25 ; the longitude:  75.25\n",
            "The position:  1911 ; the latitude:  -37.25 ; the longitude:  77.75\n",
            "The position:  1912 ; the latitude:  -37.25 ; the longitude:  80.25\n",
            "The position:  1913 ; the latitude:  -37.25 ; the longitude:  82.75\n",
            "The position:  1914 ; the latitude:  -37.25 ; the longitude:  85.25\n",
            "The position:  1915 ; the latitude:  -37.25 ; the longitude:  87.75\n",
            "The position:  1916 ; the latitude:  -37.25 ; the longitude:  90.25\n",
            "The position:  1917 ; the latitude:  -37.25 ; the longitude:  92.75\n",
            "The position:  1918 ; the latitude:  -37.25 ; the longitude:  95.25\n",
            "The position:  1919 ; the latitude:  -37.25 ; the longitude:  97.75\n",
            "The position:  1920 ; the latitude:  -37.25 ; the longitude:  100.25\n",
            "The position:  1921 ; the latitude:  -37.25 ; the longitude:  102.75\n",
            "The position:  1922 ; the latitude:  -37.25 ; the longitude:  105.25\n",
            "The position:  1923 ; the latitude:  -37.25 ; the longitude:  107.75\n",
            "The position:  1924 ; the latitude:  -37.25 ; the longitude:  110.25\n",
            "The position:  1925 ; the latitude:  -37.25 ; the longitude:  112.75\n",
            "The position:  1926 ; the latitude:  -37.25 ; the longitude:  115.25\n",
            "The position:  1927 ; the latitude:  -37.25 ; the longitude:  117.75\n",
            "The position:  1928 ; the latitude:  -37.25 ; the longitude:  120.25\n",
            "The position:  1929 ; the latitude:  -37.25 ; the longitude:  122.75\n",
            "The position:  1930 ; the latitude:  -37.25 ; the longitude:  125.25\n",
            "The position:  1931 ; the latitude:  -37.25 ; the longitude:  127.75\n",
            "The position:  1932 ; the latitude:  -37.25 ; the longitude:  130.25\n",
            "The position:  1933 ; the latitude:  -37.25 ; the longitude:  132.75\n",
            "The position:  1934 ; the latitude:  -37.25 ; the longitude:  135.25\n",
            "The position:  1935 ; the latitude:  -37.25 ; the longitude:  137.75\n",
            "The position:  1936 ; the latitude:  -37.25 ; the longitude:  140.25\n",
            "The position:  1937 ; the latitude:  -37.25 ; the longitude:  150.25\n",
            "The position:  1938 ; the latitude:  -37.25 ; the longitude:  152.75\n",
            "The position:  1939 ; the latitude:  -37.25 ; the longitude:  155.25\n",
            "The position:  1940 ; the latitude:  -37.25 ; the longitude:  157.75\n",
            "The position:  1941 ; the latitude:  -37.25 ; the longitude:  160.25\n",
            "The position:  1942 ; the latitude:  -37.25 ; the longitude:  162.75\n",
            "The position:  1943 ; the latitude:  -37.25 ; the longitude:  165.25\n",
            "The position:  1944 ; the latitude:  -37.25 ; the longitude:  167.75\n",
            "The position:  1945 ; the latitude:  -37.25 ; the longitude:  170.25\n",
            "The position:  1946 ; the latitude:  -37.25 ; the longitude:  172.75\n",
            "The position:  1947 ; the latitude:  -37.25 ; the longitude:  177.75\n",
            "The position:  1948 ; the latitude:  -37.25 ; the longitude:  180.25\n",
            "The position:  1949 ; the latitude:  -37.25 ; the longitude:  182.75\n",
            "The position:  1950 ; the latitude:  -37.25 ; the longitude:  185.25\n",
            "The position:  1951 ; the latitude:  -37.25 ; the longitude:  187.75\n",
            "The position:  1952 ; the latitude:  -37.25 ; the longitude:  190.25\n",
            "The position:  1953 ; the latitude:  -37.25 ; the longitude:  192.75\n",
            "The position:  1954 ; the latitude:  -37.25 ; the longitude:  195.25\n",
            "The position:  1955 ; the latitude:  -37.25 ; the longitude:  197.75\n",
            "The position:  1956 ; the latitude:  -37.25 ; the longitude:  200.25\n",
            "The position:  1957 ; the latitude:  -37.25 ; the longitude:  202.75\n",
            "The position:  1958 ; the latitude:  -37.25 ; the longitude:  205.25\n",
            "The position:  1959 ; the latitude:  -37.25 ; the longitude:  207.75\n",
            "The position:  1960 ; the latitude:  -37.25 ; the longitude:  210.25\n",
            "The position:  1961 ; the latitude:  -37.25 ; the longitude:  212.75\n",
            "The position:  1962 ; the latitude:  -37.25 ; the longitude:  215.25\n",
            "The position:  1963 ; the latitude:  -37.25 ; the longitude:  217.75\n",
            "The position:  1964 ; the latitude:  -37.25 ; the longitude:  220.25\n",
            "The position:  1965 ; the latitude:  -37.25 ; the longitude:  222.75\n",
            "The position:  1966 ; the latitude:  -37.25 ; the longitude:  225.25\n",
            "The position:  1967 ; the latitude:  -37.25 ; the longitude:  227.75\n",
            "The position:  1968 ; the latitude:  -37.25 ; the longitude:  230.25\n",
            "The position:  1969 ; the latitude:  -37.25 ; the longitude:  232.75\n",
            "The position:  1970 ; the latitude:  -37.25 ; the longitude:  235.25\n",
            "The position:  1971 ; the latitude:  -37.25 ; the longitude:  237.75\n",
            "The position:  1972 ; the latitude:  -37.25 ; the longitude:  240.25\n",
            "The position:  1973 ; the latitude:  -37.25 ; the longitude:  242.75\n",
            "The position:  1974 ; the latitude:  -37.25 ; the longitude:  245.25\n",
            "The position:  1975 ; the latitude:  -37.25 ; the longitude:  247.75\n",
            "The position:  1976 ; the latitude:  -37.25 ; the longitude:  250.25\n",
            "The position:  1977 ; the latitude:  -37.25 ; the longitude:  252.75\n",
            "The position:  1978 ; the latitude:  -37.25 ; the longitude:  255.25\n",
            "The position:  1979 ; the latitude:  -37.25 ; the longitude:  257.75\n",
            "The position:  1980 ; the latitude:  -37.25 ; the longitude:  260.25\n",
            "The position:  1981 ; the latitude:  -37.25 ; the longitude:  262.75\n",
            "The position:  1982 ; the latitude:  -37.25 ; the longitude:  265.25\n",
            "The position:  1983 ; the latitude:  -37.25 ; the longitude:  267.75\n",
            "The position:  1984 ; the latitude:  -37.25 ; the longitude:  270.25\n",
            "The position:  1985 ; the latitude:  -37.25 ; the longitude:  272.75\n",
            "The position:  1986 ; the latitude:  -37.25 ; the longitude:  275.25\n",
            "The position:  1987 ; the latitude:  -37.25 ; the longitude:  277.75\n",
            "The position:  1988 ; the latitude:  -37.25 ; the longitude:  280.25\n",
            "The position:  1989 ; the latitude:  -37.25 ; the longitude:  282.75\n",
            "The position:  1990 ; the latitude:  -37.25 ; the longitude:  285.25\n",
            "The position:  1991 ; the latitude:  -37.25 ; the longitude:  302.75\n",
            "The position:  1992 ; the latitude:  -37.25 ; the longitude:  305.25\n",
            "The position:  1993 ; the latitude:  -37.25 ; the longitude:  307.75\n",
            "The position:  1994 ; the latitude:  -37.25 ; the longitude:  310.25\n",
            "The position:  1995 ; the latitude:  -37.25 ; the longitude:  312.75\n",
            "The position:  1996 ; the latitude:  -37.25 ; the longitude:  315.25\n",
            "The position:  1997 ; the latitude:  -37.25 ; the longitude:  317.75\n",
            "The position:  1998 ; the latitude:  -37.25 ; the longitude:  320.25\n",
            "The position:  1999 ; the latitude:  -37.25 ; the longitude:  322.75\n",
            "The position:  2000 ; the latitude:  -37.25 ; the longitude:  325.25\n",
            "The position:  2001 ; the latitude:  -37.25 ; the longitude:  327.75\n",
            "The position:  2002 ; the latitude:  -37.25 ; the longitude:  330.25\n",
            "The position:  2003 ; the latitude:  -37.25 ; the longitude:  332.75\n",
            "The position:  2004 ; the latitude:  -37.25 ; the longitude:  335.25\n",
            "The position:  2005 ; the latitude:  -37.25 ; the longitude:  337.75\n",
            "The position:  2006 ; the latitude:  -37.25 ; the longitude:  340.25\n",
            "The position:  2007 ; the latitude:  -37.25 ; the longitude:  342.75\n",
            "The position:  2008 ; the latitude:  -37.25 ; the longitude:  345.25\n",
            "The position:  2009 ; the latitude:  -37.25 ; the longitude:  347.75\n",
            "The position:  2010 ; the latitude:  -37.25 ; the longitude:  350.25\n",
            "The position:  2011 ; the latitude:  -37.25 ; the longitude:  352.75\n",
            "The position:  2012 ; the latitude:  -37.25 ; the longitude:  355.25\n",
            "The position:  2013 ; the latitude:  -37.25 ; the longitude:  357.75\n",
            "The position:  2014 ; the latitude:  -34.75 ; the longitude:  0.25\n",
            "The position:  2015 ; the latitude:  -34.75 ; the longitude:  2.75\n",
            "The position:  2016 ; the latitude:  -34.75 ; the longitude:  5.25\n",
            "The position:  2017 ; the latitude:  -34.75 ; the longitude:  7.75\n",
            "The position:  2018 ; the latitude:  -34.75 ; the longitude:  10.25\n",
            "The position:  2019 ; the latitude:  -34.75 ; the longitude:  12.75\n",
            "The position:  2020 ; the latitude:  -34.75 ; the longitude:  15.25\n",
            "The position:  2021 ; the latitude:  -34.75 ; the longitude:  17.75\n",
            "The position:  2022 ; the latitude:  -34.75 ; the longitude:  20.25\n",
            "The position:  2023 ; the latitude:  -34.75 ; the longitude:  22.75\n",
            "The position:  2024 ; the latitude:  -34.75 ; the longitude:  25.25\n",
            "The position:  2025 ; the latitude:  -34.75 ; the longitude:  27.75\n",
            "The position:  2026 ; the latitude:  -34.75 ; the longitude:  30.25\n",
            "The position:  2027 ; the latitude:  -34.75 ; the longitude:  32.75\n",
            "The position:  2028 ; the latitude:  -34.75 ; the longitude:  35.25\n",
            "The position:  2029 ; the latitude:  -34.75 ; the longitude:  37.75\n",
            "The position:  2030 ; the latitude:  -34.75 ; the longitude:  40.25\n",
            "The position:  2031 ; the latitude:  -34.75 ; the longitude:  42.75\n",
            "The position:  2032 ; the latitude:  -34.75 ; the longitude:  45.25\n",
            "The position:  2033 ; the latitude:  -34.75 ; the longitude:  47.75\n",
            "The position:  2034 ; the latitude:  -34.75 ; the longitude:  50.25\n",
            "The position:  2035 ; the latitude:  -34.75 ; the longitude:  52.75\n",
            "The position:  2036 ; the latitude:  -34.75 ; the longitude:  55.25\n",
            "The position:  2037 ; the latitude:  -34.75 ; the longitude:  57.75\n",
            "The position:  2038 ; the latitude:  -34.75 ; the longitude:  60.25\n",
            "The position:  2039 ; the latitude:  -34.75 ; the longitude:  62.75\n",
            "The position:  2040 ; the latitude:  -34.75 ; the longitude:  65.25\n",
            "The position:  2041 ; the latitude:  -34.75 ; the longitude:  67.75\n",
            "The position:  2042 ; the latitude:  -34.75 ; the longitude:  70.25\n",
            "The position:  2043 ; the latitude:  -34.75 ; the longitude:  72.75\n",
            "The position:  2044 ; the latitude:  -34.75 ; the longitude:  75.25\n",
            "The position:  2045 ; the latitude:  -34.75 ; the longitude:  77.75\n",
            "The position:  2046 ; the latitude:  -34.75 ; the longitude:  80.25\n",
            "The position:  2047 ; the latitude:  -34.75 ; the longitude:  82.75\n",
            "The position:  2048 ; the latitude:  -34.75 ; the longitude:  85.25\n",
            "The position:  2049 ; the latitude:  -34.75 ; the longitude:  87.75\n",
            "The position:  2050 ; the latitude:  -34.75 ; the longitude:  90.25\n",
            "The position:  2051 ; the latitude:  -34.75 ; the longitude:  92.75\n",
            "The position:  2052 ; the latitude:  -34.75 ; the longitude:  95.25\n",
            "The position:  2053 ; the latitude:  -34.75 ; the longitude:  97.75\n",
            "The position:  2054 ; the latitude:  -34.75 ; the longitude:  100.25\n",
            "The position:  2055 ; the latitude:  -34.75 ; the longitude:  102.75\n",
            "The position:  2056 ; the latitude:  -34.75 ; the longitude:  105.25\n",
            "The position:  2057 ; the latitude:  -34.75 ; the longitude:  107.75\n",
            "The position:  2058 ; the latitude:  -34.75 ; the longitude:  110.25\n",
            "The position:  2059 ; the latitude:  -34.75 ; the longitude:  112.75\n",
            "The position:  2060 ; the latitude:  -34.75 ; the longitude:  115.25\n",
            "The position:  2061 ; the latitude:  -34.75 ; the longitude:  120.25\n",
            "The position:  2062 ; the latitude:  -34.75 ; the longitude:  122.75\n",
            "The position:  2063 ; the latitude:  -34.75 ; the longitude:  125.25\n",
            "The position:  2064 ; the latitude:  -34.75 ; the longitude:  127.75\n",
            "The position:  2065 ; the latitude:  -34.75 ; the longitude:  130.25\n",
            "The position:  2066 ; the latitude:  -34.75 ; the longitude:  132.75\n",
            "The position:  2067 ; the latitude:  -34.75 ; the longitude:  135.25\n",
            "The position:  2068 ; the latitude:  -34.75 ; the longitude:  137.75\n",
            "The position:  2069 ; the latitude:  -34.75 ; the longitude:  152.75\n",
            "The position:  2070 ; the latitude:  -34.75 ; the longitude:  155.25\n",
            "The position:  2071 ; the latitude:  -34.75 ; the longitude:  157.75\n",
            "The position:  2072 ; the latitude:  -34.75 ; the longitude:  160.25\n",
            "The position:  2073 ; the latitude:  -34.75 ; the longitude:  162.75\n",
            "The position:  2074 ; the latitude:  -34.75 ; the longitude:  165.25\n",
            "The position:  2075 ; the latitude:  -34.75 ; the longitude:  167.75\n",
            "The position:  2076 ; the latitude:  -34.75 ; the longitude:  170.25\n",
            "The position:  2077 ; the latitude:  -34.75 ; the longitude:  172.75\n",
            "The position:  2078 ; the latitude:  -34.75 ; the longitude:  175.25\n",
            "The position:  2079 ; the latitude:  -34.75 ; the longitude:  177.75\n",
            "The position:  2080 ; the latitude:  -34.75 ; the longitude:  180.25\n",
            "The position:  2081 ; the latitude:  -34.75 ; the longitude:  182.75\n",
            "The position:  2082 ; the latitude:  -34.75 ; the longitude:  185.25\n",
            "The position:  2083 ; the latitude:  -34.75 ; the longitude:  187.75\n",
            "The position:  2084 ; the latitude:  -34.75 ; the longitude:  190.25\n",
            "The position:  2085 ; the latitude:  -34.75 ; the longitude:  192.75\n",
            "The position:  2086 ; the latitude:  -34.75 ; the longitude:  195.25\n",
            "The position:  2087 ; the latitude:  -34.75 ; the longitude:  197.75\n",
            "The position:  2088 ; the latitude:  -34.75 ; the longitude:  200.25\n",
            "The position:  2089 ; the latitude:  -34.75 ; the longitude:  202.75\n",
            "The position:  2090 ; the latitude:  -34.75 ; the longitude:  205.25\n",
            "The position:  2091 ; the latitude:  -34.75 ; the longitude:  207.75\n",
            "The position:  2092 ; the latitude:  -34.75 ; the longitude:  210.25\n",
            "The position:  2093 ; the latitude:  -34.75 ; the longitude:  212.75\n",
            "The position:  2094 ; the latitude:  -34.75 ; the longitude:  215.25\n",
            "The position:  2095 ; the latitude:  -34.75 ; the longitude:  217.75\n",
            "The position:  2096 ; the latitude:  -34.75 ; the longitude:  220.25\n",
            "The position:  2097 ; the latitude:  -34.75 ; the longitude:  222.75\n",
            "The position:  2098 ; the latitude:  -34.75 ; the longitude:  225.25\n",
            "The position:  2099 ; the latitude:  -34.75 ; the longitude:  227.75\n",
            "The position:  2100 ; the latitude:  -34.75 ; the longitude:  230.25\n",
            "The position:  2101 ; the latitude:  -34.75 ; the longitude:  232.75\n",
            "The position:  2102 ; the latitude:  -34.75 ; the longitude:  235.25\n",
            "The position:  2103 ; the latitude:  -34.75 ; the longitude:  237.75\n",
            "The position:  2104 ; the latitude:  -34.75 ; the longitude:  240.25\n",
            "The position:  2105 ; the latitude:  -34.75 ; the longitude:  242.75\n",
            "The position:  2106 ; the latitude:  -34.75 ; the longitude:  245.25\n",
            "The position:  2107 ; the latitude:  -34.75 ; the longitude:  247.75\n",
            "The position:  2108 ; the latitude:  -34.75 ; the longitude:  250.25\n",
            "The position:  2109 ; the latitude:  -34.75 ; the longitude:  252.75\n",
            "The position:  2110 ; the latitude:  -34.75 ; the longitude:  255.25\n",
            "The position:  2111 ; the latitude:  -34.75 ; the longitude:  257.75\n",
            "The position:  2112 ; the latitude:  -34.75 ; the longitude:  260.25\n",
            "The position:  2113 ; the latitude:  -34.75 ; the longitude:  262.75\n",
            "The position:  2114 ; the latitude:  -34.75 ; the longitude:  265.25\n",
            "The position:  2115 ; the latitude:  -34.75 ; the longitude:  267.75\n",
            "The position:  2116 ; the latitude:  -34.75 ; the longitude:  270.25\n",
            "The position:  2117 ; the latitude:  -34.75 ; the longitude:  272.75\n",
            "The position:  2118 ; the latitude:  -34.75 ; the longitude:  275.25\n",
            "The position:  2119 ; the latitude:  -34.75 ; the longitude:  277.75\n",
            "The position:  2120 ; the latitude:  -34.75 ; the longitude:  280.25\n",
            "The position:  2121 ; the latitude:  -34.75 ; the longitude:  282.75\n",
            "The position:  2122 ; the latitude:  -34.75 ; the longitude:  285.25\n",
            "The position:  2123 ; the latitude:  -34.75 ; the longitude:  287.75\n",
            "The position:  2124 ; the latitude:  -34.75 ; the longitude:  302.75\n",
            "The position:  2125 ; the latitude:  -34.75 ; the longitude:  305.25\n",
            "The position:  2126 ; the latitude:  -34.75 ; the longitude:  307.75\n",
            "The position:  2127 ; the latitude:  -34.75 ; the longitude:  310.25\n",
            "The position:  2128 ; the latitude:  -34.75 ; the longitude:  312.75\n",
            "The position:  2129 ; the latitude:  -34.75 ; the longitude:  315.25\n",
            "The position:  2130 ; the latitude:  -34.75 ; the longitude:  317.75\n",
            "The position:  2131 ; the latitude:  -34.75 ; the longitude:  320.25\n",
            "The position:  2132 ; the latitude:  -34.75 ; the longitude:  322.75\n",
            "The position:  2133 ; the latitude:  -34.75 ; the longitude:  325.25\n",
            "The position:  2134 ; the latitude:  -34.75 ; the longitude:  327.75\n",
            "The position:  2135 ; the latitude:  -34.75 ; the longitude:  330.25\n",
            "The position:  2136 ; the latitude:  -34.75 ; the longitude:  332.75\n",
            "The position:  2137 ; the latitude:  -34.75 ; the longitude:  335.25\n",
            "The position:  2138 ; the latitude:  -34.75 ; the longitude:  337.75\n",
            "The position:  2139 ; the latitude:  -34.75 ; the longitude:  340.25\n",
            "The position:  2140 ; the latitude:  -34.75 ; the longitude:  342.75\n",
            "The position:  2141 ; the latitude:  -34.75 ; the longitude:  345.25\n",
            "The position:  2142 ; the latitude:  -34.75 ; the longitude:  347.75\n",
            "The position:  2143 ; the latitude:  -34.75 ; the longitude:  350.25\n",
            "The position:  2144 ; the latitude:  -34.75 ; the longitude:  352.75\n",
            "The position:  2145 ; the latitude:  -34.75 ; the longitude:  355.25\n",
            "The position:  2146 ; the latitude:  -34.75 ; the longitude:  357.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The position: 2079; the latitude: -34.75; the longitude: 177.75, which one point in Bay of Plenty\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B_1Enm5L7Vg",
        "outputId": "882b9f4f-5599-40aa-9fdc-c2800ced72ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The position: 2079; the latitude: -34.75; the longitude: 177.75, which one point in Bay of Plenty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_output = np.round(np.array(out_feats), decimals=2)\n",
        "gnn_input = np.round(np.array(node_feats), decimals=2)"
      ],
      "metadata": {
        "id": "b_z6nu8oM-2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_output_bop = gnn_output[0][2079]\n",
        "gnn_input_bop = gnn_input[0][2079]"
      ],
      "metadata": {
        "id": "xnygAccqNZfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "gnn_mse_bop = mean_squared_error(gnn_output_bop, gnn_input_bop)\n",
        "print(gnn_mse_bop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25QDQxV6NxVr",
        "outputId": "50ffe69b-5ef0-4eb2-8ae5-e472a76d084f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08179954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------"
      ],
      "metadata": {
        "id": "_qsx7vKIsSpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst_anomaly.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrCuBBV7sTWP",
        "outputId": "19f4a324-12f9-409f-ed58-61cce11704cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(432, 66, 144)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_input_bop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLZpRBwZt3qa",
        "outputId": "9a908dfd-6749-48f7-89b7-735dbab3b92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.15,  0.17, -0.49, -1.13, -0.54, -0.69, -1.48, -1.35, -0.81,\n",
              "       -0.41, -0.27, -0.43,  0.64,  0.6 ,  0.45,  0.58, -0.02, -0.23,\n",
              "        0.03,  0.27,  0.12,  0.18, -0.69,  0.12,  0.26, -0.65, -0.17,\n",
              "       -0.24, -0.9 , -0.57, -0.02, -0.02, -0.1 , -0.5 , -0.32, -0.36,\n",
              "       -0.72, -0.97,  0.17,  0.36, -0.25, -0.35, -0.07, -0.2 , -0.17,\n",
              "       -0.14, -0.19, -1.02, -0.88, -0.76,  0.07,  0.67,  0.08,  0.28,\n",
              "        0.81,  0.43,  0.78,  0.25,  1.07,  1.29,  1.11, -0.17,  0.12,\n",
              "       -0.21,  0.07, -0.17,  0.44,  0.49,  0.28,  0.35, -0.16, -0.2 ,\n",
              "        0.62,  0.27,  0.53,  0.23,  0.24, -0.18, -0.32, -0.25, -0.2 ,\n",
              "        0.1 , -0.21, -0.83, -0.75, -0.17, -0.37, -0.73, -0.47,  0.16,\n",
              "        0.38,  0.46,  0.34,  0.37,  0.31,  0.21, -0.2 ,  0.78,  0.6 ,\n",
              "        0.07,  0.16,  0.76,  0.9 ,  0.6 ,  0.74,  0.74,  0.53,  1.12,\n",
              "        0.65, -0.25,  0.02,  0.11,  0.56,  0.43,  0.66,  0.7 ,  0.7 ,\n",
              "        0.49,  0.83,  0.03,  0.35,  0.96,  1.29,  0.58,  0.36,  0.1 ,\n",
              "       -0.09,  0.24,  0.1 ,  0.69,  0.72,  0.55, -0.46,  0.46, -0.24,\n",
              "       -0.62, -0.62, -0.46, -1.  , -1.05, -0.96, -0.93, -1.9 , -1.98,\n",
              "       -1.41, -0.31, -1.21, -1.46, -1.63, -1.8 , -1.46, -1.36, -1.36,\n",
              "       -1.53, -0.7 , -0.62, -0.75, -1.66, -1.63, -0.9 , -0.68, -0.31,\n",
              "        0.19,  0.18, -0.73, -0.61, -0.82, -0.83,  0.97, -1.07, -1.07,\n",
              "       -1.21, -1.07, -0.85, -0.38, -0.14, -0.15, -0.22,  0.3 ,  0.39,\n",
              "       -0.25, -0.06,  0.24,  0.56,  0.31, -0.03, -0.34,  0.09, -0.01,\n",
              "        0.02,  0.34,  1.01,  0.75,  0.93,  0.19,  0.39,  0.66,  0.02,\n",
              "        0.24,  0.09,  0.08, -0.13, -0.23, -0.26, -0.75, -1.02, -0.84,\n",
              "       -0.9 , -0.74, -0.32,  0.17,  0.24,  0.  , -0.06,  0.29,  0.95,\n",
              "        0.2 ,  1.61,  1.21,  1.25,  1.21,  1.25,  0.92,  1.4 ,  1.44,\n",
              "        1.43,  0.87,  0.17,  0.06, -0.5 , -0.15,  0.76,  0.9 ,  1.07,\n",
              "        0.51, -0.15,  0.58,  1.08,  0.78, -0.16, -0.67, -0.51, -0.06,\n",
              "       -0.04,  0.19,  0.05,  0.15, -0.11, -0.15, -0.31, -0.75, -0.38,\n",
              "       -0.19,  0.09,  0.05, -0.31,  0.28, -0.02, -0.06,  0.05,  0.07,\n",
              "        0.54,  0.85,  0.79,  0.28, -0.16,  0.26,  0.64,  0.59,  0.51,\n",
              "        0.6 ,  0.25,  0.11, -0.46, -0.9 , -0.4 , -0.28, -0.01,  0.25,\n",
              "        0.48,  0.27,  0.58,  0.36,  0.26, -0.03, -0.03,  0.09,  0.78,\n",
              "        1.  ,  0.48, -0.54, -0.52, -0.29,  0.14, -0.33,  0.02, -0.33,\n",
              "       -0.34,  0.32, -1.4 , -1.5 , -0.55,  0.62,  1.02,  0.26, -0.28,\n",
              "       -0.1 ,  0.02,  0.26,  0.  ,  0.4 ,  0.2 ,  0.41,  1.05,  0.38,\n",
              "        0.37,  0.15, -0.22, -0.5 , -0.31,  0.51,  0.09, -0.2 , -0.93,\n",
              "       -0.39, -0.04,  0.37,  0.29,  0.14,  0.28,  0.29,  0.05,  0.09,\n",
              "       -0.17, -0.21, -0.08, -0.03, -0.13, -0.  ,  0.14, -0.01, -0.48,\n",
              "       -0.61, -0.53, -0.29, -0.18, -0.09,  0.59,  0.9 ,  1.08,  0.68,\n",
              "       -0.05, -0.48, -0.73, -0.84, -0.51, -0.08, -0.22, -0.16,  0.24,\n",
              "       -0.22,  0.63,  0.15, -0.4 , -0.04, -0.07, -0.3 , -0.11, -0.46,\n",
              "        0.06, -0.37,  0.38,  0.97,  1.45,  0.79,  0.08,  0.31,  0.44,\n",
              "        0.08, -0.24, -0.19,  0.3 ,  0.37, -0.35, -0.37, -0.21, -0.77,\n",
              "       -0.46, -0.17,  0.15,  0.26,  0.5 ,  0.32, -0.06, -0.3 ,  0.29,\n",
              "       -0.16, -0.54, -0.58,  0.36,  0.46,  0.44,  0.  ,  0.38, -0.04,\n",
              "        0.1 ,  0.58,  1.21,  0.46, -0.5 , -0.14,  0.28,  0.65,  1.09,\n",
              "        0.51, -0.4 , -0.18, -0.35, -0.08,  0.17,  0.5 , -0.29, -0.18,\n",
              "       -0.03,  0.04,  0.03,  0.4 ,  0.  , -0.26, -0.14, -0.11, -0.28],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soda_sst_anomaly.shape\n",
        "\n",
        "soda_sst_anomaly = np.nan_to_num(soda_sst_anomaly, nan=0)\n",
        "\n",
        "soda_sst_anomaly_CNN = np.expand_dims(soda_sst_anomaly, axis=1)\n",
        "\n",
        "print(soda_sst_anomaly_CNN.shape)\n",
        "print(soda_sst_bop_anomaly.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqJRDcQy-fQP",
        "outputId": "87537b03-6368-437b-82f1-c2948bb1c17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(432, 1, 66, 144)\n",
            "(432,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "\n",
        "for i in range(len(soda_sst_anomaly_CNN)):\n",
        "  train_data.append((soda_sst_anomaly_CNN[i], soda_sst_bop_anomaly[i]))"
      ],
      "metadata": {
        "id": "wqTjZwFWHJmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as Data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "EPOCH = 10\n",
        "BATCH_SIZE = len(soda_sst_anomaly_CNN) # 8, 16, 32, 64, ...\n",
        "LR = 0.00001\n",
        "\n",
        "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "train_all_loader = Data.DataLoader(dataset=train_data, batch_size=len(train_data), shuffle=False)"
      ],
      "metadata": {
        "id": "cDpchepnGANm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=32,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "            ),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 16, 3, 1, 1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.out = nn.Linear(38016, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        output = self.out(x)\n",
        "        return output, x\n",
        "\n",
        "cnn = CNN().double()\n",
        "\n",
        "print(cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g4Nd0MmGzSH",
        "outputId": "a92c5a5a-800f-4692-d915-7b095895a8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Tanh()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (out): Linear(in_features=38016, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
        "loss_func = nn.MSELoss() "
      ],
      "metadata": {
        "id": "v-8x5CpAG4ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCH):\n",
        "    for step, (x, y) in enumerate(train_loader):\n",
        "        b_x = Variable(x)\n",
        "        b_y = Variable(y)\n",
        "\n",
        "        output = cnn(b_x)[0]\n",
        "        output = output.reshape(-1) # To avoid different sizes\n",
        "        loss = loss_func(output, b_y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    for step, (x, y) in enumerate(train_all_loader):\n",
        "        c_x = Variable(x)\n",
        "        c_y = Variable(y)\n",
        "\n",
        "    #for step, (x, y) in enumerate(test_loader):\n",
        "        #d_x = Variable(x)\n",
        "        #d_y = Variable(y)\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            \n",
        "            pred_train_y, last_layer = cnn(c_x)\n",
        "            train_mse = loss_func(pred_train_y, c_y)\n",
        "\n",
        "            #pred_test_y, last_layer = cnn(d_x)\n",
        "            #test_mse = loss_func(pred_test_y, d_y)\n",
        "\n",
        "            print(\"Epoch:\", epoch, \"| trainig loss: %.4f\" % loss.data, \"| training MSE: %.4f\" % train_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbHPnwhiG6M5",
        "outputId": "d04c71e7-6f4e-476e-e389-dbf3aa6629ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([432])) that is different to the input size (torch.Size([432, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | trainig loss: 0.3820 | training MSE: 0.3832\n",
            "Epoch: 1 | trainig loss: 0.3749 | training MSE: 0.3824\n",
            "Epoch: 2 | trainig loss: 0.3689 | training MSE: 0.3824\n",
            "Epoch: 3 | trainig loss: 0.3636 | training MSE: 0.3826\n",
            "Epoch: 4 | trainig loss: 0.3584 | training MSE: 0.3830\n",
            "Epoch: 5 | trainig loss: 0.3533 | training MSE: 0.3834\n",
            "Epoch: 6 | trainig loss: 0.3482 | training MSE: 0.3838\n",
            "Epoch: 7 | trainig loss: 0.3432 | training MSE: 0.3843\n",
            "Epoch: 8 | trainig loss: 0.3382 | training MSE: 0.3850\n",
            "Epoch: 9 | trainig loss: 0.3334 | training MSE: 0.3859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------"
      ],
      "metadata": {
        "id": "r5pr6uf4KG4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(soda_sst_anomaly.shape)\n",
        "print(soda_sst_bop_anomaly.shape)\n",
        "\n",
        "soda_sst_anomaly_by_month = []\n",
        "soda_sst_bop_anomaly_by_month = []\n",
        "\n",
        "for month in range(12):\n",
        "  soda_sst_anomaly_by_month.append(soda_sst_anomaly[month::12])\n",
        "  soda_sst_bop_anomaly_by_month.append(soda_sst_bop_anomaly[month+1::12])\n",
        "\n",
        "soda_sst_anomaly_by_month[-1] = soda_sst_anomaly_by_month[-1][:-1] # Remove December in the last year."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddvX5b0gFs-I",
        "outputId": "83d27069-a7cc-4d40-a46f-f6b3b1e595e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(432, 66, 144)\n",
            "(432,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(soda_sst_anomaly_by_month[0].shape)\n",
        "print(soda_sst_bop_anomaly_by_month[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InKk7N46NhVs",
        "outputId": "9fa268e2-af94-4d89-ede8-87f639191082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36, 66, 144)\n",
            "(36,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(soda_sst_anomaly_by_month[month])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqQthQT6WnSk",
        "outputId": "31167913-0329-41c8-fbc3-1e6236579041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(soda_sst_anomaly_CNN[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGZvmkjaWgl2",
        "outputId": "d2db06e5-b447-4a20-c5b0-706b017b0db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_mse_by_month = []\n",
        "\n",
        "for month in range(12):\n",
        "  print()\n",
        "  print(\"Start Month\", str(month+1))\n",
        "\n",
        "  soda_sst_anomaly_CNN = np.expand_dims(soda_sst_anomaly_by_month[month], axis=1)\n",
        "  train_data = []\n",
        "  test_data = []\n",
        "  for year in range(len(soda_sst_anomaly_CNN)):\n",
        "    if year < 28:\n",
        "      train_data.append((soda_sst_anomaly_CNN[year], soda_sst_bop_anomaly_by_month[month][year]))\n",
        "    else:\n",
        "      test_data.append((soda_sst_anomaly_CNN[year], soda_sst_bop_anomaly_by_month[month][year]))\n",
        "    year += 1\n",
        "  \n",
        "  #print(len(train_data))\n",
        "  #print(len(test_data))\n",
        "  \n",
        "  EPOCH = 20\n",
        "  BATCH_SIZE = len(train_data) # 8\n",
        "  LR = 0.00001\n",
        "  NUM_MODEL = 5\n",
        "  \n",
        "  train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "  test_loader = Data.DataLoader(dataset=test_data, batch_size=len(test_data), shuffle=False)\n",
        "\n",
        "  sum_test_mse = 0\n",
        "\n",
        "  for time in range(NUM_MODEL):\n",
        "    \n",
        "    print()\n",
        "    print(\"Start training Model\", str(time+1))\n",
        "\n",
        "    cnn = CNN().double()\n",
        "\n",
        "    optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
        "    loss_func = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(EPOCH):\n",
        "      for step, (x, y) in enumerate(train_loader):\n",
        "          b_x = Variable(x)\n",
        "          b_y = Variable(y)\n",
        "\n",
        "          output = cnn(b_x)[0]\n",
        "          output = output.reshape(-1) # To avoid different sizes\n",
        "          loss = loss_func(output, b_y)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      for step, (x, y) in enumerate(train_loader):\n",
        "          c_x = Variable(x)\n",
        "          c_y = Variable(y)\n",
        "\n",
        "      for step, (x, y) in enumerate(test_loader):\n",
        "          d_x = Variable(x)\n",
        "          d_y = Variable(y)\n",
        "\n",
        "          if step % 100 == 0:\n",
        "            \n",
        "              pred_train_y, last_layer = cnn(c_x)\n",
        "              train_mse = loss_func(pred_train_y, c_y)\n",
        "\n",
        "              pred_test_y, last_layer = cnn(d_x)\n",
        "              test_mse = loss_func(pred_test_y, d_y)\n",
        "\n",
        "              print(\"Epoch: \", epoch+1, \"| trainig loss: %.4f\" % loss.data, \"| test MSE: %.4f\" % test_mse)\n",
        "    \n",
        "    sum_test_mse += test_mse.cpu().detach().numpy()\n",
        "    #print(sum_test_mse)\n",
        "\n",
        "  test_mse_by_month.append(sum_test_mse / NUM_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDj0J3FbM3LV",
        "outputId": "26840676-99cc-410a-8b57-99e7eb30ae66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start Month 1\n",
            "\n",
            "Start training Model 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([28])) that is different to the input size (torch.Size([28, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 | trainig loss: 0.5223 | test MSE: 0.5662\n",
            "Epoch:  2 | trainig loss: 0.5120 | test MSE: 0.5706\n",
            "Epoch:  3 | trainig loss: 0.5023 | test MSE: 0.5742\n",
            "Epoch:  4 | trainig loss: 0.4933 | test MSE: 0.5768\n",
            "Epoch:  5 | trainig loss: 0.4846 | test MSE: 0.5782\n",
            "Epoch:  6 | trainig loss: 0.4762 | test MSE: 0.5784\n",
            "Epoch:  7 | trainig loss: 0.4680 | test MSE: 0.5776\n",
            "Epoch:  8 | trainig loss: 0.4598 | test MSE: 0.5759\n",
            "Epoch:  9 | trainig loss: 0.4516 | test MSE: 0.5735\n",
            "Epoch:  10 | trainig loss: 0.4435 | test MSE: 0.5706\n",
            "Epoch:  11 | trainig loss: 0.4355 | test MSE: 0.5674\n",
            "Epoch:  12 | trainig loss: 0.4276 | test MSE: 0.5641\n",
            "Epoch:  13 | trainig loss: 0.4197 | test MSE: 0.5608\n",
            "Epoch:  14 | trainig loss: 0.4120 | test MSE: 0.5575\n",
            "Epoch:  15 | trainig loss: 0.4044 | test MSE: 0.5546\n",
            "Epoch:  16 | trainig loss: 0.3970 | test MSE: 0.5519\n",
            "Epoch:  17 | trainig loss: 0.3897 | test MSE: 0.5496\n",
            "Epoch:  18 | trainig loss: 0.3824 | test MSE: 0.5476\n",
            "Epoch:  19 | trainig loss: 0.3753 | test MSE: 0.5460\n",
            "Epoch:  20 | trainig loss: 0.3683 | test MSE: 0.5447\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.5700 | test MSE: 0.5704\n",
            "Epoch:  2 | trainig loss: 0.5587 | test MSE: 0.5720\n",
            "Epoch:  3 | trainig loss: 0.5479 | test MSE: 0.5725\n",
            "Epoch:  4 | trainig loss: 0.5374 | test MSE: 0.5717\n",
            "Epoch:  5 | trainig loss: 0.5272 | test MSE: 0.5698\n",
            "Epoch:  6 | trainig loss: 0.5172 | test MSE: 0.5671\n",
            "Epoch:  7 | trainig loss: 0.5073 | test MSE: 0.5637\n",
            "Epoch:  8 | trainig loss: 0.4976 | test MSE: 0.5601\n",
            "Epoch:  9 | trainig loss: 0.4880 | test MSE: 0.5565\n",
            "Epoch:  10 | trainig loss: 0.4785 | test MSE: 0.5529\n",
            "Epoch:  11 | trainig loss: 0.4692 | test MSE: 0.5496\n",
            "Epoch:  12 | trainig loss: 0.4601 | test MSE: 0.5467\n",
            "Epoch:  13 | trainig loss: 0.4512 | test MSE: 0.5441\n",
            "Epoch:  14 | trainig loss: 0.4424 | test MSE: 0.5420\n",
            "Epoch:  15 | trainig loss: 0.4338 | test MSE: 0.5403\n",
            "Epoch:  16 | trainig loss: 0.4253 | test MSE: 0.5389\n",
            "Epoch:  17 | trainig loss: 0.4170 | test MSE: 0.5379\n",
            "Epoch:  18 | trainig loss: 0.4088 | test MSE: 0.5370\n",
            "Epoch:  19 | trainig loss: 0.4007 | test MSE: 0.5364\n",
            "Epoch:  20 | trainig loss: 0.3928 | test MSE: 0.5359\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.5335 | test MSE: 0.5864\n",
            "Epoch:  2 | trainig loss: 0.5223 | test MSE: 0.5755\n",
            "Epoch:  3 | trainig loss: 0.5118 | test MSE: 0.5668\n",
            "Epoch:  4 | trainig loss: 0.5017 | test MSE: 0.5601\n",
            "Epoch:  5 | trainig loss: 0.4921 | test MSE: 0.5552\n",
            "Epoch:  6 | trainig loss: 0.4826 | test MSE: 0.5516\n",
            "Epoch:  7 | trainig loss: 0.4732 | test MSE: 0.5491\n",
            "Epoch:  8 | trainig loss: 0.4640 | test MSE: 0.5475\n",
            "Epoch:  9 | trainig loss: 0.4548 | test MSE: 0.5464\n",
            "Epoch:  10 | trainig loss: 0.4458 | test MSE: 0.5458\n",
            "Epoch:  11 | trainig loss: 0.4368 | test MSE: 0.5454\n",
            "Epoch:  12 | trainig loss: 0.4281 | test MSE: 0.5451\n",
            "Epoch:  13 | trainig loss: 0.4195 | test MSE: 0.5448\n",
            "Epoch:  14 | trainig loss: 0.4111 | test MSE: 0.5443\n",
            "Epoch:  15 | trainig loss: 0.4028 | test MSE: 0.5438\n",
            "Epoch:  16 | trainig loss: 0.3946 | test MSE: 0.5430\n",
            "Epoch:  17 | trainig loss: 0.3866 | test MSE: 0.5421\n",
            "Epoch:  18 | trainig loss: 0.3787 | test MSE: 0.5411\n",
            "Epoch:  19 | trainig loss: 0.3710 | test MSE: 0.5400\n",
            "Epoch:  20 | trainig loss: 0.3633 | test MSE: 0.5389\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.5470 | test MSE: 0.5548\n",
            "Epoch:  2 | trainig loss: 0.5378 | test MSE: 0.5604\n",
            "Epoch:  3 | trainig loss: 0.5295 | test MSE: 0.5647\n",
            "Epoch:  4 | trainig loss: 0.5217 | test MSE: 0.5675\n",
            "Epoch:  5 | trainig loss: 0.5141 | test MSE: 0.5688\n",
            "Epoch:  6 | trainig loss: 0.5068 | test MSE: 0.5687\n",
            "Epoch:  7 | trainig loss: 0.4994 | test MSE: 0.5673\n",
            "Epoch:  8 | trainig loss: 0.4920 | test MSE: 0.5652\n",
            "Epoch:  9 | trainig loss: 0.4846 | test MSE: 0.5625\n",
            "Epoch:  10 | trainig loss: 0.4773 | test MSE: 0.5595\n",
            "Epoch:  11 | trainig loss: 0.4700 | test MSE: 0.5564\n",
            "Epoch:  12 | trainig loss: 0.4628 | test MSE: 0.5535\n",
            "Epoch:  13 | trainig loss: 0.4557 | test MSE: 0.5508\n",
            "Epoch:  14 | trainig loss: 0.4487 | test MSE: 0.5484\n",
            "Epoch:  15 | trainig loss: 0.4418 | test MSE: 0.5464\n",
            "Epoch:  16 | trainig loss: 0.4350 | test MSE: 0.5448\n",
            "Epoch:  17 | trainig loss: 0.4282 | test MSE: 0.5436\n",
            "Epoch:  18 | trainig loss: 0.4215 | test MSE: 0.5427\n",
            "Epoch:  19 | trainig loss: 0.4149 | test MSE: 0.5421\n",
            "Epoch:  20 | trainig loss: 0.4083 | test MSE: 0.5418\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.5347 | test MSE: 0.5855\n",
            "Epoch:  2 | trainig loss: 0.5228 | test MSE: 0.5728\n",
            "Epoch:  3 | trainig loss: 0.5121 | test MSE: 0.5621\n",
            "Epoch:  4 | trainig loss: 0.5023 | test MSE: 0.5532\n",
            "Epoch:  5 | trainig loss: 0.4933 | test MSE: 0.5459\n",
            "Epoch:  6 | trainig loss: 0.4850 | test MSE: 0.5401\n",
            "Epoch:  7 | trainig loss: 0.4771 | test MSE: 0.5355\n",
            "Epoch:  8 | trainig loss: 0.4695 | test MSE: 0.5320\n",
            "Epoch:  9 | trainig loss: 0.4620 | test MSE: 0.5293\n",
            "Epoch:  10 | trainig loss: 0.4546 | test MSE: 0.5274\n",
            "Epoch:  11 | trainig loss: 0.4473 | test MSE: 0.5259\n",
            "Epoch:  12 | trainig loss: 0.4400 | test MSE: 0.5249\n",
            "Epoch:  13 | trainig loss: 0.4326 | test MSE: 0.5243\n",
            "Epoch:  14 | trainig loss: 0.4253 | test MSE: 0.5239\n",
            "Epoch:  15 | trainig loss: 0.4180 | test MSE: 0.5237\n",
            "Epoch:  16 | trainig loss: 0.4108 | test MSE: 0.5236\n",
            "Epoch:  17 | trainig loss: 0.4036 | test MSE: 0.5236\n",
            "Epoch:  18 | trainig loss: 0.3966 | test MSE: 0.5237\n",
            "Epoch:  19 | trainig loss: 0.3897 | test MSE: 0.5238\n",
            "Epoch:  20 | trainig loss: 0.3830 | test MSE: 0.5239\n",
            "\n",
            "Start Month 2\n",
            "\n",
            "Start training Model 1\n",
            "Epoch:  1 | trainig loss: 0.4070 | test MSE: 0.2681\n",
            "Epoch:  2 | trainig loss: 0.3984 | test MSE: 0.2680\n",
            "Epoch:  3 | trainig loss: 0.3900 | test MSE: 0.2674\n",
            "Epoch:  4 | trainig loss: 0.3817 | test MSE: 0.2665\n",
            "Epoch:  5 | trainig loss: 0.3735 | test MSE: 0.2657\n",
            "Epoch:  6 | trainig loss: 0.3655 | test MSE: 0.2650\n",
            "Epoch:  7 | trainig loss: 0.3576 | test MSE: 0.2645\n",
            "Epoch:  8 | trainig loss: 0.3499 | test MSE: 0.2641\n",
            "Epoch:  9 | trainig loss: 0.3422 | test MSE: 0.2639\n",
            "Epoch:  10 | trainig loss: 0.3347 | test MSE: 0.2637\n",
            "Epoch:  11 | trainig loss: 0.3274 | test MSE: 0.2636\n",
            "Epoch:  12 | trainig loss: 0.3201 | test MSE: 0.2635\n",
            "Epoch:  13 | trainig loss: 0.3130 | test MSE: 0.2635\n",
            "Epoch:  14 | trainig loss: 0.3060 | test MSE: 0.2635\n",
            "Epoch:  15 | trainig loss: 0.2991 | test MSE: 0.2636\n",
            "Epoch:  16 | trainig loss: 0.2924 | test MSE: 0.2637\n",
            "Epoch:  17 | trainig loss: 0.2858 | test MSE: 0.2640\n",
            "Epoch:  18 | trainig loss: 0.2793 | test MSE: 0.2642\n",
            "Epoch:  19 | trainig loss: 0.2729 | test MSE: 0.2646\n",
            "Epoch:  20 | trainig loss: 0.2666 | test MSE: 0.2649\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.3999 | test MSE: 0.2688\n",
            "Epoch:  2 | trainig loss: 0.3899 | test MSE: 0.2672\n",
            "Epoch:  3 | trainig loss: 0.3810 | test MSE: 0.2662\n",
            "Epoch:  4 | trainig loss: 0.3730 | test MSE: 0.2657\n",
            "Epoch:  5 | trainig loss: 0.3655 | test MSE: 0.2655\n",
            "Epoch:  6 | trainig loss: 0.3583 | test MSE: 0.2654\n",
            "Epoch:  7 | trainig loss: 0.3514 | test MSE: 0.2653\n",
            "Epoch:  8 | trainig loss: 0.3445 | test MSE: 0.2653\n",
            "Epoch:  9 | trainig loss: 0.3376 | test MSE: 0.2653\n",
            "Epoch:  10 | trainig loss: 0.3307 | test MSE: 0.2654\n",
            "Epoch:  11 | trainig loss: 0.3238 | test MSE: 0.2656\n",
            "Epoch:  12 | trainig loss: 0.3170 | test MSE: 0.2659\n",
            "Epoch:  13 | trainig loss: 0.3103 | test MSE: 0.2663\n",
            "Epoch:  14 | trainig loss: 0.3037 | test MSE: 0.2669\n",
            "Epoch:  15 | trainig loss: 0.2972 | test MSE: 0.2676\n",
            "Epoch:  16 | trainig loss: 0.2909 | test MSE: 0.2683\n",
            "Epoch:  17 | trainig loss: 0.2847 | test MSE: 0.2691\n",
            "Epoch:  18 | trainig loss: 0.2786 | test MSE: 0.2698\n",
            "Epoch:  19 | trainig loss: 0.2726 | test MSE: 0.2705\n",
            "Epoch:  20 | trainig loss: 0.2667 | test MSE: 0.2711\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.3956 | test MSE: 0.2704\n",
            "Epoch:  2 | trainig loss: 0.3864 | test MSE: 0.2672\n",
            "Epoch:  3 | trainig loss: 0.3784 | test MSE: 0.2657\n",
            "Epoch:  4 | trainig loss: 0.3709 | test MSE: 0.2650\n",
            "Epoch:  5 | trainig loss: 0.3636 | test MSE: 0.2648\n",
            "Epoch:  6 | trainig loss: 0.3563 | test MSE: 0.2648\n",
            "Epoch:  7 | trainig loss: 0.3489 | test MSE: 0.2648\n",
            "Epoch:  8 | trainig loss: 0.3416 | test MSE: 0.2650\n",
            "Epoch:  9 | trainig loss: 0.3343 | test MSE: 0.2651\n",
            "Epoch:  10 | trainig loss: 0.3273 | test MSE: 0.2653\n",
            "Epoch:  11 | trainig loss: 0.3204 | test MSE: 0.2654\n",
            "Epoch:  12 | trainig loss: 0.3136 | test MSE: 0.2655\n",
            "Epoch:  13 | trainig loss: 0.3070 | test MSE: 0.2656\n",
            "Epoch:  14 | trainig loss: 0.3005 | test MSE: 0.2658\n",
            "Epoch:  15 | trainig loss: 0.2940 | test MSE: 0.2660\n",
            "Epoch:  16 | trainig loss: 0.2876 | test MSE: 0.2663\n",
            "Epoch:  17 | trainig loss: 0.2813 | test MSE: 0.2667\n",
            "Epoch:  18 | trainig loss: 0.2751 | test MSE: 0.2673\n",
            "Epoch:  19 | trainig loss: 0.2691 | test MSE: 0.2679\n",
            "Epoch:  20 | trainig loss: 0.2632 | test MSE: 0.2686\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.4469 | test MSE: 0.2651\n",
            "Epoch:  2 | trainig loss: 0.4375 | test MSE: 0.2651\n",
            "Epoch:  3 | trainig loss: 0.4286 | test MSE: 0.2651\n",
            "Epoch:  4 | trainig loss: 0.4200 | test MSE: 0.2651\n",
            "Epoch:  5 | trainig loss: 0.4117 | test MSE: 0.2651\n",
            "Epoch:  6 | trainig loss: 0.4036 | test MSE: 0.2650\n",
            "Epoch:  7 | trainig loss: 0.3956 | test MSE: 0.2649\n",
            "Epoch:  8 | trainig loss: 0.3878 | test MSE: 0.2647\n",
            "Epoch:  9 | trainig loss: 0.3801 | test MSE: 0.2646\n",
            "Epoch:  10 | trainig loss: 0.3725 | test MSE: 0.2646\n",
            "Epoch:  11 | trainig loss: 0.3650 | test MSE: 0.2646\n",
            "Epoch:  12 | trainig loss: 0.3577 | test MSE: 0.2647\n",
            "Epoch:  13 | trainig loss: 0.3504 | test MSE: 0.2649\n",
            "Epoch:  14 | trainig loss: 0.3433 | test MSE: 0.2652\n",
            "Epoch:  15 | trainig loss: 0.3363 | test MSE: 0.2656\n",
            "Epoch:  16 | trainig loss: 0.3295 | test MSE: 0.2662\n",
            "Epoch:  17 | trainig loss: 0.3227 | test MSE: 0.2667\n",
            "Epoch:  18 | trainig loss: 0.3161 | test MSE: 0.2673\n",
            "Epoch:  19 | trainig loss: 0.3096 | test MSE: 0.2680\n",
            "Epoch:  20 | trainig loss: 0.3032 | test MSE: 0.2686\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.3838 | test MSE: 0.2677\n",
            "Epoch:  2 | trainig loss: 0.3741 | test MSE: 0.2683\n",
            "Epoch:  3 | trainig loss: 0.3651 | test MSE: 0.2694\n",
            "Epoch:  4 | trainig loss: 0.3565 | test MSE: 0.2709\n",
            "Epoch:  5 | trainig loss: 0.3483 | test MSE: 0.2723\n",
            "Epoch:  6 | trainig loss: 0.3403 | test MSE: 0.2736\n",
            "Epoch:  7 | trainig loss: 0.3324 | test MSE: 0.2747\n",
            "Epoch:  8 | trainig loss: 0.3245 | test MSE: 0.2756\n",
            "Epoch:  9 | trainig loss: 0.3168 | test MSE: 0.2763\n",
            "Epoch:  10 | trainig loss: 0.3092 | test MSE: 0.2769\n",
            "Epoch:  11 | trainig loss: 0.3017 | test MSE: 0.2774\n",
            "Epoch:  12 | trainig loss: 0.2943 | test MSE: 0.2779\n",
            "Epoch:  13 | trainig loss: 0.2871 | test MSE: 0.2785\n",
            "Epoch:  14 | trainig loss: 0.2801 | test MSE: 0.2791\n",
            "Epoch:  15 | trainig loss: 0.2733 | test MSE: 0.2800\n",
            "Epoch:  16 | trainig loss: 0.2665 | test MSE: 0.2810\n",
            "Epoch:  17 | trainig loss: 0.2599 | test MSE: 0.2822\n",
            "Epoch:  18 | trainig loss: 0.2535 | test MSE: 0.2836\n",
            "Epoch:  19 | trainig loss: 0.2471 | test MSE: 0.2852\n",
            "Epoch:  20 | trainig loss: 0.2409 | test MSE: 0.2870\n",
            "\n",
            "Start Month 3\n",
            "\n",
            "Start training Model 1\n",
            "Epoch:  1 | trainig loss: 0.4969 | test MSE: 0.0863\n",
            "Epoch:  2 | trainig loss: 0.4841 | test MSE: 0.0825\n",
            "Epoch:  3 | trainig loss: 0.4733 | test MSE: 0.0808\n",
            "Epoch:  4 | trainig loss: 0.4640 | test MSE: 0.0805\n",
            "Epoch:  5 | trainig loss: 0.4555 | test MSE: 0.0810\n",
            "Epoch:  6 | trainig loss: 0.4473 | test MSE: 0.0818\n",
            "Epoch:  7 | trainig loss: 0.4392 | test MSE: 0.0825\n",
            "Epoch:  8 | trainig loss: 0.4310 | test MSE: 0.0830\n",
            "Epoch:  9 | trainig loss: 0.4227 | test MSE: 0.0834\n",
            "Epoch:  10 | trainig loss: 0.4143 | test MSE: 0.0836\n",
            "Epoch:  11 | trainig loss: 0.4059 | test MSE: 0.0837\n",
            "Epoch:  12 | trainig loss: 0.3977 | test MSE: 0.0839\n",
            "Epoch:  13 | trainig loss: 0.3897 | test MSE: 0.0840\n",
            "Epoch:  14 | trainig loss: 0.3818 | test MSE: 0.0843\n",
            "Epoch:  15 | trainig loss: 0.3741 | test MSE: 0.0846\n",
            "Epoch:  16 | trainig loss: 0.3666 | test MSE: 0.0851\n",
            "Epoch:  17 | trainig loss: 0.3592 | test MSE: 0.0858\n",
            "Epoch:  18 | trainig loss: 0.3518 | test MSE: 0.0867\n",
            "Epoch:  19 | trainig loss: 0.3445 | test MSE: 0.0878\n",
            "Epoch:  20 | trainig loss: 0.3372 | test MSE: 0.0891\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.5518 | test MSE: 0.0904\n",
            "Epoch:  2 | trainig loss: 0.5382 | test MSE: 0.0878\n",
            "Epoch:  3 | trainig loss: 0.5261 | test MSE: 0.0862\n",
            "Epoch:  4 | trainig loss: 0.5151 | test MSE: 0.0853\n",
            "Epoch:  5 | trainig loss: 0.5051 | test MSE: 0.0849\n",
            "Epoch:  6 | trainig loss: 0.4958 | test MSE: 0.0850\n",
            "Epoch:  7 | trainig loss: 0.4870 | test MSE: 0.0852\n",
            "Epoch:  8 | trainig loss: 0.4785 | test MSE: 0.0856\n",
            "Epoch:  9 | trainig loss: 0.4702 | test MSE: 0.0861\n",
            "Epoch:  10 | trainig loss: 0.4619 | test MSE: 0.0866\n",
            "Epoch:  11 | trainig loss: 0.4536 | test MSE: 0.0873\n",
            "Epoch:  12 | trainig loss: 0.4453 | test MSE: 0.0880\n",
            "Epoch:  13 | trainig loss: 0.4369 | test MSE: 0.0889\n",
            "Epoch:  14 | trainig loss: 0.4286 | test MSE: 0.0900\n",
            "Epoch:  15 | trainig loss: 0.4204 | test MSE: 0.0913\n",
            "Epoch:  16 | trainig loss: 0.4122 | test MSE: 0.0929\n",
            "Epoch:  17 | trainig loss: 0.4042 | test MSE: 0.0947\n",
            "Epoch:  18 | trainig loss: 0.3963 | test MSE: 0.0966\n",
            "Epoch:  19 | trainig loss: 0.3886 | test MSE: 0.0988\n",
            "Epoch:  20 | trainig loss: 0.3811 | test MSE: 0.1010\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.4859 | test MSE: 0.0778\n",
            "Epoch:  2 | trainig loss: 0.4764 | test MSE: 0.0777\n",
            "Epoch:  3 | trainig loss: 0.4670 | test MSE: 0.0777\n",
            "Epoch:  4 | trainig loss: 0.4578 | test MSE: 0.0779\n",
            "Epoch:  5 | trainig loss: 0.4487 | test MSE: 0.0782\n",
            "Epoch:  6 | trainig loss: 0.4397 | test MSE: 0.0785\n",
            "Epoch:  7 | trainig loss: 0.4308 | test MSE: 0.0789\n",
            "Epoch:  8 | trainig loss: 0.4220 | test MSE: 0.0794\n",
            "Epoch:  9 | trainig loss: 0.4134 | test MSE: 0.0798\n",
            "Epoch:  10 | trainig loss: 0.4048 | test MSE: 0.0804\n",
            "Epoch:  11 | trainig loss: 0.3964 | test MSE: 0.0810\n",
            "Epoch:  12 | trainig loss: 0.3880 | test MSE: 0.0816\n",
            "Epoch:  13 | trainig loss: 0.3798 | test MSE: 0.0824\n",
            "Epoch:  14 | trainig loss: 0.3717 | test MSE: 0.0832\n",
            "Epoch:  15 | trainig loss: 0.3637 | test MSE: 0.0841\n",
            "Epoch:  16 | trainig loss: 0.3558 | test MSE: 0.0851\n",
            "Epoch:  17 | trainig loss: 0.3480 | test MSE: 0.0861\n",
            "Epoch:  18 | trainig loss: 0.3403 | test MSE: 0.0873\n",
            "Epoch:  19 | trainig loss: 0.3328 | test MSE: 0.0885\n",
            "Epoch:  20 | trainig loss: 0.3253 | test MSE: 0.0898\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.4947 | test MSE: 0.0810\n",
            "Epoch:  2 | trainig loss: 0.4843 | test MSE: 0.0815\n",
            "Epoch:  3 | trainig loss: 0.4747 | test MSE: 0.0824\n",
            "Epoch:  4 | trainig loss: 0.4656 | test MSE: 0.0834\n",
            "Epoch:  5 | trainig loss: 0.4566 | test MSE: 0.0842\n",
            "Epoch:  6 | trainig loss: 0.4477 | test MSE: 0.0847\n",
            "Epoch:  7 | trainig loss: 0.4388 | test MSE: 0.0849\n",
            "Epoch:  8 | trainig loss: 0.4299 | test MSE: 0.0851\n",
            "Epoch:  9 | trainig loss: 0.4212 | test MSE: 0.0852\n",
            "Epoch:  10 | trainig loss: 0.4126 | test MSE: 0.0855\n",
            "Epoch:  11 | trainig loss: 0.4042 | test MSE: 0.0858\n",
            "Epoch:  12 | trainig loss: 0.3959 | test MSE: 0.0864\n",
            "Epoch:  13 | trainig loss: 0.3877 | test MSE: 0.0872\n",
            "Epoch:  14 | trainig loss: 0.3796 | test MSE: 0.0882\n",
            "Epoch:  15 | trainig loss: 0.3716 | test MSE: 0.0895\n",
            "Epoch:  16 | trainig loss: 0.3637 | test MSE: 0.0911\n",
            "Epoch:  17 | trainig loss: 0.3559 | test MSE: 0.0929\n",
            "Epoch:  18 | trainig loss: 0.3483 | test MSE: 0.0947\n",
            "Epoch:  19 | trainig loss: 0.3407 | test MSE: 0.0966\n",
            "Epoch:  20 | trainig loss: 0.3333 | test MSE: 0.0985\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.4967 | test MSE: 0.0959\n",
            "Epoch:  2 | trainig loss: 0.4859 | test MSE: 0.0941\n",
            "Epoch:  3 | trainig loss: 0.4756 | test MSE: 0.0928\n",
            "Epoch:  4 | trainig loss: 0.4655 | test MSE: 0.0920\n",
            "Epoch:  5 | trainig loss: 0.4558 | test MSE: 0.0916\n",
            "Epoch:  6 | trainig loss: 0.4461 | test MSE: 0.0916\n",
            "Epoch:  7 | trainig loss: 0.4367 | test MSE: 0.0920\n",
            "Epoch:  8 | trainig loss: 0.4273 | test MSE: 0.0928\n",
            "Epoch:  9 | trainig loss: 0.4180 | test MSE: 0.0940\n",
            "Epoch:  10 | trainig loss: 0.4089 | test MSE: 0.0954\n",
            "Epoch:  11 | trainig loss: 0.3998 | test MSE: 0.0972\n",
            "Epoch:  12 | trainig loss: 0.3910 | test MSE: 0.0991\n",
            "Epoch:  13 | trainig loss: 0.3822 | test MSE: 0.1010\n",
            "Epoch:  14 | trainig loss: 0.3736 | test MSE: 0.1030\n",
            "Epoch:  15 | trainig loss: 0.3652 | test MSE: 0.1050\n",
            "Epoch:  16 | trainig loss: 0.3568 | test MSE: 0.1068\n",
            "Epoch:  17 | trainig loss: 0.3486 | test MSE: 0.1085\n",
            "Epoch:  18 | trainig loss: 0.3406 | test MSE: 0.1100\n",
            "Epoch:  19 | trainig loss: 0.3326 | test MSE: 0.1115\n",
            "Epoch:  20 | trainig loss: 0.3248 | test MSE: 0.1128\n",
            "\n",
            "Start Month 4\n",
            "\n",
            "Start training Model 1\n",
            "Epoch:  1 | trainig loss: 0.3691 | test MSE: 0.1648\n",
            "Epoch:  2 | trainig loss: 0.3588 | test MSE: 0.1596\n",
            "Epoch:  3 | trainig loss: 0.3488 | test MSE: 0.1554\n",
            "Epoch:  4 | trainig loss: 0.3392 | test MSE: 0.1522\n",
            "Epoch:  5 | trainig loss: 0.3298 | test MSE: 0.1498\n",
            "Epoch:  6 | trainig loss: 0.3206 | test MSE: 0.1481\n",
            "Epoch:  7 | trainig loss: 0.3115 | test MSE: 0.1469\n",
            "Epoch:  8 | trainig loss: 0.3027 | test MSE: 0.1462\n",
            "Epoch:  9 | trainig loss: 0.2939 | test MSE: 0.1458\n",
            "Epoch:  10 | trainig loss: 0.2854 | test MSE: 0.1456\n",
            "Epoch:  11 | trainig loss: 0.2770 | test MSE: 0.1456\n",
            "Epoch:  12 | trainig loss: 0.2688 | test MSE: 0.1457\n",
            "Epoch:  13 | trainig loss: 0.2607 | test MSE: 0.1459\n",
            "Epoch:  14 | trainig loss: 0.2529 | test MSE: 0.1461\n",
            "Epoch:  15 | trainig loss: 0.2452 | test MSE: 0.1464\n",
            "Epoch:  16 | trainig loss: 0.2377 | test MSE: 0.1466\n",
            "Epoch:  17 | trainig loss: 0.2303 | test MSE: 0.1470\n",
            "Epoch:  18 | trainig loss: 0.2231 | test MSE: 0.1473\n",
            "Epoch:  19 | trainig loss: 0.2161 | test MSE: 0.1477\n",
            "Epoch:  20 | trainig loss: 0.2093 | test MSE: 0.1483\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.3875 | test MSE: 0.1281\n",
            "Epoch:  2 | trainig loss: 0.3793 | test MSE: 0.1279\n",
            "Epoch:  3 | trainig loss: 0.3712 | test MSE: 0.1270\n",
            "Epoch:  4 | trainig loss: 0.3632 | test MSE: 0.1259\n",
            "Epoch:  5 | trainig loss: 0.3554 | test MSE: 0.1249\n",
            "Epoch:  6 | trainig loss: 0.3476 | test MSE: 0.1240\n",
            "Epoch:  7 | trainig loss: 0.3399 | test MSE: 0.1234\n",
            "Epoch:  8 | trainig loss: 0.3323 | test MSE: 0.1230\n",
            "Epoch:  9 | trainig loss: 0.3249 | test MSE: 0.1227\n",
            "Epoch:  10 | trainig loss: 0.3175 | test MSE: 0.1226\n",
            "Epoch:  11 | trainig loss: 0.3103 | test MSE: 0.1224\n",
            "Epoch:  12 | trainig loss: 0.3031 | test MSE: 0.1223\n",
            "Epoch:  13 | trainig loss: 0.2961 | test MSE: 0.1222\n",
            "Epoch:  14 | trainig loss: 0.2891 | test MSE: 0.1221\n",
            "Epoch:  15 | trainig loss: 0.2823 | test MSE: 0.1221\n",
            "Epoch:  16 | trainig loss: 0.2756 | test MSE: 0.1221\n",
            "Epoch:  17 | trainig loss: 0.2690 | test MSE: 0.1222\n",
            "Epoch:  18 | trainig loss: 0.2624 | test MSE: 0.1224\n",
            "Epoch:  19 | trainig loss: 0.2560 | test MSE: 0.1227\n",
            "Epoch:  20 | trainig loss: 0.2497 | test MSE: 0.1231\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.3593 | test MSE: 0.1385\n",
            "Epoch:  2 | trainig loss: 0.3481 | test MSE: 0.1316\n",
            "Epoch:  3 | trainig loss: 0.3378 | test MSE: 0.1267\n",
            "Epoch:  4 | trainig loss: 0.3282 | test MSE: 0.1234\n",
            "Epoch:  5 | trainig loss: 0.3191 | test MSE: 0.1212\n",
            "Epoch:  6 | trainig loss: 0.3102 | test MSE: 0.1200\n",
            "Epoch:  7 | trainig loss: 0.3014 | test MSE: 0.1193\n",
            "Epoch:  8 | trainig loss: 0.2927 | test MSE: 0.1190\n",
            "Epoch:  9 | trainig loss: 0.2840 | test MSE: 0.1189\n",
            "Epoch:  10 | trainig loss: 0.2755 | test MSE: 0.1190\n",
            "Epoch:  11 | trainig loss: 0.2672 | test MSE: 0.1192\n",
            "Epoch:  12 | trainig loss: 0.2591 | test MSE: 0.1194\n",
            "Epoch:  13 | trainig loss: 0.2511 | test MSE: 0.1197\n",
            "Epoch:  14 | trainig loss: 0.2434 | test MSE: 0.1200\n",
            "Epoch:  15 | trainig loss: 0.2359 | test MSE: 0.1203\n",
            "Epoch:  16 | trainig loss: 0.2285 | test MSE: 0.1207\n",
            "Epoch:  17 | trainig loss: 0.2213 | test MSE: 0.1211\n",
            "Epoch:  18 | trainig loss: 0.2142 | test MSE: 0.1217\n",
            "Epoch:  19 | trainig loss: 0.2073 | test MSE: 0.1224\n",
            "Epoch:  20 | trainig loss: 0.2005 | test MSE: 0.1233\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.4237 | test MSE: 0.1373\n",
            "Epoch:  2 | trainig loss: 0.4113 | test MSE: 0.1415\n",
            "Epoch:  3 | trainig loss: 0.4002 | test MSE: 0.1452\n",
            "Epoch:  4 | trainig loss: 0.3900 | test MSE: 0.1484\n",
            "Epoch:  5 | trainig loss: 0.3806 | test MSE: 0.1506\n",
            "Epoch:  6 | trainig loss: 0.3718 | test MSE: 0.1518\n",
            "Epoch:  7 | trainig loss: 0.3632 | test MSE: 0.1520\n",
            "Epoch:  8 | trainig loss: 0.3547 | test MSE: 0.1513\n",
            "Epoch:  9 | trainig loss: 0.3463 | test MSE: 0.1497\n",
            "Epoch:  10 | trainig loss: 0.3379 | test MSE: 0.1476\n",
            "Epoch:  11 | trainig loss: 0.3296 | test MSE: 0.1450\n",
            "Epoch:  12 | trainig loss: 0.3213 | test MSE: 0.1423\n",
            "Epoch:  13 | trainig loss: 0.3131 | test MSE: 0.1396\n",
            "Epoch:  14 | trainig loss: 0.3050 | test MSE: 0.1369\n",
            "Epoch:  15 | trainig loss: 0.2971 | test MSE: 0.1345\n",
            "Epoch:  16 | trainig loss: 0.2894 | test MSE: 0.1324\n",
            "Epoch:  17 | trainig loss: 0.2818 | test MSE: 0.1306\n",
            "Epoch:  18 | trainig loss: 0.2744 | test MSE: 0.1292\n",
            "Epoch:  19 | trainig loss: 0.2672 | test MSE: 0.1281\n",
            "Epoch:  20 | trainig loss: 0.2601 | test MSE: 0.1274\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.3710 | test MSE: 0.1334\n",
            "Epoch:  2 | trainig loss: 0.3617 | test MSE: 0.1339\n",
            "Epoch:  3 | trainig loss: 0.3527 | test MSE: 0.1335\n",
            "Epoch:  4 | trainig loss: 0.3439 | test MSE: 0.1325\n",
            "Epoch:  5 | trainig loss: 0.3353 | test MSE: 0.1312\n",
            "Epoch:  6 | trainig loss: 0.3267 | test MSE: 0.1299\n",
            "Epoch:  7 | trainig loss: 0.3182 | test MSE: 0.1287\n",
            "Epoch:  8 | trainig loss: 0.3099 | test MSE: 0.1278\n",
            "Epoch:  9 | trainig loss: 0.3018 | test MSE: 0.1271\n",
            "Epoch:  10 | trainig loss: 0.2938 | test MSE: 0.1267\n",
            "Epoch:  11 | trainig loss: 0.2859 | test MSE: 0.1265\n",
            "Epoch:  12 | trainig loss: 0.2782 | test MSE: 0.1264\n",
            "Epoch:  13 | trainig loss: 0.2705 | test MSE: 0.1265\n",
            "Epoch:  14 | trainig loss: 0.2631 | test MSE: 0.1267\n",
            "Epoch:  15 | trainig loss: 0.2557 | test MSE: 0.1270\n",
            "Epoch:  16 | trainig loss: 0.2485 | test MSE: 0.1273\n",
            "Epoch:  17 | trainig loss: 0.2414 | test MSE: 0.1276\n",
            "Epoch:  18 | trainig loss: 0.2345 | test MSE: 0.1280\n",
            "Epoch:  19 | trainig loss: 0.2277 | test MSE: 0.1284\n",
            "Epoch:  20 | trainig loss: 0.2210 | test MSE: 0.1289\n",
            "\n",
            "Start Month 5\n",
            "\n",
            "Start training Model 1\n",
            "Epoch:  1 | trainig loss: 0.3572 | test MSE: 0.2931\n",
            "Epoch:  2 | trainig loss: 0.3466 | test MSE: 0.2959\n",
            "Epoch:  3 | trainig loss: 0.3371 | test MSE: 0.2984\n",
            "Epoch:  4 | trainig loss: 0.3284 | test MSE: 0.3004\n",
            "Epoch:  5 | trainig loss: 0.3203 | test MSE: 0.3018\n",
            "Epoch:  6 | trainig loss: 0.3125 | test MSE: 0.3024\n",
            "Epoch:  7 | trainig loss: 0.3049 | test MSE: 0.3023\n",
            "Epoch:  8 | trainig loss: 0.2974 | test MSE: 0.3017\n",
            "Epoch:  9 | trainig loss: 0.2899 | test MSE: 0.3006\n",
            "Epoch:  10 | trainig loss: 0.2824 | test MSE: 0.2992\n",
            "Epoch:  11 | trainig loss: 0.2751 | test MSE: 0.2977\n",
            "Epoch:  12 | trainig loss: 0.2678 | test MSE: 0.2963\n",
            "Epoch:  13 | trainig loss: 0.2607 | test MSE: 0.2950\n",
            "Epoch:  14 | trainig loss: 0.2537 | test MSE: 0.2939\n",
            "Epoch:  15 | trainig loss: 0.2469 | test MSE: 0.2931\n",
            "Epoch:  16 | trainig loss: 0.2403 | test MSE: 0.2925\n",
            "Epoch:  17 | trainig loss: 0.2338 | test MSE: 0.2922\n",
            "Epoch:  18 | trainig loss: 0.2275 | test MSE: 0.2920\n",
            "Epoch:  19 | trainig loss: 0.2213 | test MSE: 0.2921\n",
            "Epoch:  20 | trainig loss: 0.2152 | test MSE: 0.2923\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.3484 | test MSE: 0.2922\n",
            "Epoch:  2 | trainig loss: 0.3366 | test MSE: 0.2947\n",
            "Epoch:  3 | trainig loss: 0.3262 | test MSE: 0.2976\n",
            "Epoch:  4 | trainig loss: 0.3171 | test MSE: 0.3005\n",
            "Epoch:  5 | trainig loss: 0.3089 | test MSE: 0.3033\n",
            "Epoch:  6 | trainig loss: 0.3015 | test MSE: 0.3055\n",
            "Epoch:  7 | trainig loss: 0.2946 | test MSE: 0.3072\n",
            "Epoch:  8 | trainig loss: 0.2878 | test MSE: 0.3082\n",
            "Epoch:  9 | trainig loss: 0.2812 | test MSE: 0.3085\n",
            "Epoch:  10 | trainig loss: 0.2746 | test MSE: 0.3083\n",
            "Epoch:  11 | trainig loss: 0.2679 | test MSE: 0.3077\n",
            "Epoch:  12 | trainig loss: 0.2611 | test MSE: 0.3068\n",
            "Epoch:  13 | trainig loss: 0.2544 | test MSE: 0.3057\n",
            "Epoch:  14 | trainig loss: 0.2477 | test MSE: 0.3047\n",
            "Epoch:  15 | trainig loss: 0.2412 | test MSE: 0.3037\n",
            "Epoch:  16 | trainig loss: 0.2348 | test MSE: 0.3029\n",
            "Epoch:  17 | trainig loss: 0.2286 | test MSE: 0.3024\n",
            "Epoch:  18 | trainig loss: 0.2225 | test MSE: 0.3021\n",
            "Epoch:  19 | trainig loss: 0.2166 | test MSE: 0.3020\n",
            "Epoch:  20 | trainig loss: 0.2109 | test MSE: 0.3022\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.3571 | test MSE: 0.3048\n",
            "Epoch:  2 | trainig loss: 0.3475 | test MSE: 0.3069\n",
            "Epoch:  3 | trainig loss: 0.3383 | test MSE: 0.3087\n",
            "Epoch:  4 | trainig loss: 0.3296 | test MSE: 0.3102\n",
            "Epoch:  5 | trainig loss: 0.3212 | test MSE: 0.3112\n",
            "Epoch:  6 | trainig loss: 0.3130 | test MSE: 0.3117\n",
            "Epoch:  7 | trainig loss: 0.3051 | test MSE: 0.3118\n",
            "Epoch:  8 | trainig loss: 0.2973 | test MSE: 0.3115\n",
            "Epoch:  9 | trainig loss: 0.2896 | test MSE: 0.3108\n",
            "Epoch:  10 | trainig loss: 0.2821 | test MSE: 0.3099\n",
            "Epoch:  11 | trainig loss: 0.2747 | test MSE: 0.3089\n",
            "Epoch:  12 | trainig loss: 0.2673 | test MSE: 0.3077\n",
            "Epoch:  13 | trainig loss: 0.2601 | test MSE: 0.3065\n",
            "Epoch:  14 | trainig loss: 0.2531 | test MSE: 0.3054\n",
            "Epoch:  15 | trainig loss: 0.2461 | test MSE: 0.3044\n",
            "Epoch:  16 | trainig loss: 0.2394 | test MSE: 0.3036\n",
            "Epoch:  17 | trainig loss: 0.2327 | test MSE: 0.3030\n",
            "Epoch:  18 | trainig loss: 0.2263 | test MSE: 0.3025\n",
            "Epoch:  19 | trainig loss: 0.2199 | test MSE: 0.3023\n",
            "Epoch:  20 | trainig loss: 0.2137 | test MSE: 0.3022\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.3728 | test MSE: 0.3008\n",
            "Epoch:  2 | trainig loss: 0.3591 | test MSE: 0.3030\n",
            "Epoch:  3 | trainig loss: 0.3466 | test MSE: 0.3051\n",
            "Epoch:  4 | trainig loss: 0.3352 | test MSE: 0.3068\n",
            "Epoch:  5 | trainig loss: 0.3247 | test MSE: 0.3081\n",
            "Epoch:  6 | trainig loss: 0.3147 | test MSE: 0.3087\n",
            "Epoch:  7 | trainig loss: 0.3052 | test MSE: 0.3086\n",
            "Epoch:  8 | trainig loss: 0.2959 | test MSE: 0.3079\n",
            "Epoch:  9 | trainig loss: 0.2867 | test MSE: 0.3068\n",
            "Epoch:  10 | trainig loss: 0.2776 | test MSE: 0.3054\n",
            "Epoch:  11 | trainig loss: 0.2687 | test MSE: 0.3038\n",
            "Epoch:  12 | trainig loss: 0.2599 | test MSE: 0.3022\n",
            "Epoch:  13 | trainig loss: 0.2513 | test MSE: 0.3007\n",
            "Epoch:  14 | trainig loss: 0.2429 | test MSE: 0.2996\n",
            "Epoch:  15 | trainig loss: 0.2348 | test MSE: 0.2987\n",
            "Epoch:  16 | trainig loss: 0.2269 | test MSE: 0.2982\n",
            "Epoch:  17 | trainig loss: 0.2193 | test MSE: 0.2981\n",
            "Epoch:  18 | trainig loss: 0.2119 | test MSE: 0.2982\n",
            "Epoch:  19 | trainig loss: 0.2048 | test MSE: 0.2987\n",
            "Epoch:  20 | trainig loss: 0.1979 | test MSE: 0.2994\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.3727 | test MSE: 0.3010\n",
            "Epoch:  2 | trainig loss: 0.3611 | test MSE: 0.3038\n",
            "Epoch:  3 | trainig loss: 0.3503 | test MSE: 0.3065\n",
            "Epoch:  4 | trainig loss: 0.3403 | test MSE: 0.3089\n",
            "Epoch:  5 | trainig loss: 0.3309 | test MSE: 0.3107\n",
            "Epoch:  6 | trainig loss: 0.3221 | test MSE: 0.3119\n",
            "Epoch:  7 | trainig loss: 0.3135 | test MSE: 0.3125\n",
            "Epoch:  8 | trainig loss: 0.3052 | test MSE: 0.3123\n",
            "Epoch:  9 | trainig loss: 0.2971 | test MSE: 0.3116\n",
            "Epoch:  10 | trainig loss: 0.2890 | test MSE: 0.3104\n",
            "Epoch:  11 | trainig loss: 0.2811 | test MSE: 0.3087\n",
            "Epoch:  12 | trainig loss: 0.2732 | test MSE: 0.3069\n",
            "Epoch:  13 | trainig loss: 0.2654 | test MSE: 0.3049\n",
            "Epoch:  14 | trainig loss: 0.2578 | test MSE: 0.3029\n",
            "Epoch:  15 | trainig loss: 0.2504 | test MSE: 0.3011\n",
            "Epoch:  16 | trainig loss: 0.2431 | test MSE: 0.2994\n",
            "Epoch:  17 | trainig loss: 0.2360 | test MSE: 0.2979\n",
            "Epoch:  18 | trainig loss: 0.2291 | test MSE: 0.2966\n",
            "Epoch:  19 | trainig loss: 0.2224 | test MSE: 0.2957\n",
            "Epoch:  20 | trainig loss: 0.2158 | test MSE: 0.2950\n",
            "\n",
            "Start Month 6\n",
            "\n",
            "Start training Model 1\n",
            "Epoch:  1 | trainig loss: 0.4010 | test MSE: 0.2187\n",
            "Epoch:  2 | trainig loss: 0.3908 | test MSE: 0.2181\n",
            "Epoch:  3 | trainig loss: 0.3808 | test MSE: 0.2187\n",
            "Epoch:  4 | trainig loss: 0.3711 | test MSE: 0.2200\n",
            "Epoch:  5 | trainig loss: 0.3615 | test MSE: 0.2216\n",
            "Epoch:  6 | trainig loss: 0.3520 | test MSE: 0.2234\n",
            "Epoch:  7 | trainig loss: 0.3428 | test MSE: 0.2251\n",
            "Epoch:  8 | trainig loss: 0.3337 | test MSE: 0.2265\n",
            "Epoch:  9 | trainig loss: 0.3249 | test MSE: 0.2276\n",
            "Epoch:  10 | trainig loss: 0.3161 | test MSE: 0.2284\n",
            "Epoch:  11 | trainig loss: 0.3076 | test MSE: 0.2292\n",
            "Epoch:  12 | trainig loss: 0.2992 | test MSE: 0.2301\n",
            "Epoch:  13 | trainig loss: 0.2910 | test MSE: 0.2311\n",
            "Epoch:  14 | trainig loss: 0.2830 | test MSE: 0.2323\n",
            "Epoch:  15 | trainig loss: 0.2752 | test MSE: 0.2338\n",
            "Epoch:  16 | trainig loss: 0.2675 | test MSE: 0.2355\n",
            "Epoch:  17 | trainig loss: 0.2599 | test MSE: 0.2373\n",
            "Epoch:  18 | trainig loss: 0.2526 | test MSE: 0.2391\n",
            "Epoch:  19 | trainig loss: 0.2454 | test MSE: 0.2408\n",
            "Epoch:  20 | trainig loss: 0.2384 | test MSE: 0.2424\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.3905 | test MSE: 0.2395\n",
            "Epoch:  2 | trainig loss: 0.3793 | test MSE: 0.2338\n",
            "Epoch:  3 | trainig loss: 0.3697 | test MSE: 0.2312\n",
            "Epoch:  4 | trainig loss: 0.3605 | test MSE: 0.2307\n",
            "Epoch:  5 | trainig loss: 0.3513 | test MSE: 0.2318\n",
            "Epoch:  6 | trainig loss: 0.3420 | test MSE: 0.2339\n",
            "Epoch:  7 | trainig loss: 0.3328 | test MSE: 0.2365\n",
            "Epoch:  8 | trainig loss: 0.3238 | test MSE: 0.2393\n",
            "Epoch:  9 | trainig loss: 0.3150 | test MSE: 0.2418\n",
            "Epoch:  10 | trainig loss: 0.3065 | test MSE: 0.2437\n",
            "Epoch:  11 | trainig loss: 0.2982 | test MSE: 0.2448\n",
            "Epoch:  12 | trainig loss: 0.2900 | test MSE: 0.2452\n",
            "Epoch:  13 | trainig loss: 0.2818 | test MSE: 0.2450\n",
            "Epoch:  14 | trainig loss: 0.2739 | test MSE: 0.2446\n",
            "Epoch:  15 | trainig loss: 0.2661 | test MSE: 0.2441\n",
            "Epoch:  16 | trainig loss: 0.2585 | test MSE: 0.2438\n",
            "Epoch:  17 | trainig loss: 0.2511 | test MSE: 0.2440\n",
            "Epoch:  18 | trainig loss: 0.2438 | test MSE: 0.2447\n",
            "Epoch:  19 | trainig loss: 0.2368 | test MSE: 0.2460\n",
            "Epoch:  20 | trainig loss: 0.2298 | test MSE: 0.2477\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.3786 | test MSE: 0.2285\n",
            "Epoch:  2 | trainig loss: 0.3705 | test MSE: 0.2298\n",
            "Epoch:  3 | trainig loss: 0.3626 | test MSE: 0.2309\n",
            "Epoch:  4 | trainig loss: 0.3547 | test MSE: 0.2317\n",
            "Epoch:  5 | trainig loss: 0.3470 | test MSE: 0.2325\n",
            "Epoch:  6 | trainig loss: 0.3394 | test MSE: 0.2332\n",
            "Epoch:  7 | trainig loss: 0.3319 | test MSE: 0.2340\n",
            "Epoch:  8 | trainig loss: 0.3245 | test MSE: 0.2349\n",
            "Epoch:  9 | trainig loss: 0.3172 | test MSE: 0.2360\n",
            "Epoch:  10 | trainig loss: 0.3100 | test MSE: 0.2371\n",
            "Epoch:  11 | trainig loss: 0.3030 | test MSE: 0.2384\n",
            "Epoch:  12 | trainig loss: 0.2961 | test MSE: 0.2396\n",
            "Epoch:  13 | trainig loss: 0.2892 | test MSE: 0.2409\n",
            "Epoch:  14 | trainig loss: 0.2825 | test MSE: 0.2421\n",
            "Epoch:  15 | trainig loss: 0.2759 | test MSE: 0.2433\n",
            "Epoch:  16 | trainig loss: 0.2694 | test MSE: 0.2444\n",
            "Epoch:  17 | trainig loss: 0.2630 | test MSE: 0.2456\n",
            "Epoch:  18 | trainig loss: 0.2567 | test MSE: 0.2467\n",
            "Epoch:  19 | trainig loss: 0.2506 | test MSE: 0.2479\n",
            "Epoch:  20 | trainig loss: 0.2445 | test MSE: 0.2491\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.3425 | test MSE: 0.2084\n",
            "Epoch:  2 | trainig loss: 0.3338 | test MSE: 0.2108\n",
            "Epoch:  3 | trainig loss: 0.3259 | test MSE: 0.2131\n",
            "Epoch:  4 | trainig loss: 0.3185 | test MSE: 0.2150\n",
            "Epoch:  5 | trainig loss: 0.3111 | test MSE: 0.2163\n",
            "Epoch:  6 | trainig loss: 0.3039 | test MSE: 0.2171\n",
            "Epoch:  7 | trainig loss: 0.2966 | test MSE: 0.2176\n",
            "Epoch:  8 | trainig loss: 0.2894 | test MSE: 0.2178\n",
            "Epoch:  9 | trainig loss: 0.2824 | test MSE: 0.2179\n",
            "Epoch:  10 | trainig loss: 0.2754 | test MSE: 0.2181\n",
            "Epoch:  11 | trainig loss: 0.2686 | test MSE: 0.2185\n",
            "Epoch:  12 | trainig loss: 0.2620 | test MSE: 0.2190\n",
            "Epoch:  13 | trainig loss: 0.2555 | test MSE: 0.2198\n",
            "Epoch:  14 | trainig loss: 0.2490 | test MSE: 0.2209\n",
            "Epoch:  15 | trainig loss: 0.2427 | test MSE: 0.2222\n",
            "Epoch:  16 | trainig loss: 0.2365 | test MSE: 0.2237\n",
            "Epoch:  17 | trainig loss: 0.2303 | test MSE: 0.2253\n",
            "Epoch:  18 | trainig loss: 0.2243 | test MSE: 0.2271\n",
            "Epoch:  19 | trainig loss: 0.2184 | test MSE: 0.2289\n",
            "Epoch:  20 | trainig loss: 0.2126 | test MSE: 0.2307\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.3568 | test MSE: 0.2186\n",
            "Epoch:  2 | trainig loss: 0.3467 | test MSE: 0.2247\n",
            "Epoch:  3 | trainig loss: 0.3379 | test MSE: 0.2306\n",
            "Epoch:  4 | trainig loss: 0.3300 | test MSE: 0.2358\n",
            "Epoch:  5 | trainig loss: 0.3226 | test MSE: 0.2399\n",
            "Epoch:  6 | trainig loss: 0.3154 | test MSE: 0.2429\n",
            "Epoch:  7 | trainig loss: 0.3083 | test MSE: 0.2446\n",
            "Epoch:  8 | trainig loss: 0.3012 | test MSE: 0.2454\n",
            "Epoch:  9 | trainig loss: 0.2940 | test MSE: 0.2454\n",
            "Epoch:  10 | trainig loss: 0.2869 | test MSE: 0.2449\n",
            "Epoch:  11 | trainig loss: 0.2799 | test MSE: 0.2441\n",
            "Epoch:  12 | trainig loss: 0.2730 | test MSE: 0.2433\n",
            "Epoch:  13 | trainig loss: 0.2663 | test MSE: 0.2425\n",
            "Epoch:  14 | trainig loss: 0.2598 | test MSE: 0.2421\n",
            "Epoch:  15 | trainig loss: 0.2534 | test MSE: 0.2420\n",
            "Epoch:  16 | trainig loss: 0.2471 | test MSE: 0.2423\n",
            "Epoch:  17 | trainig loss: 0.2409 | test MSE: 0.2431\n",
            "Epoch:  18 | trainig loss: 0.2349 | test MSE: 0.2443\n",
            "Epoch:  19 | trainig loss: 0.2289 | test MSE: 0.2460\n",
            "Epoch:  20 | trainig loss: 0.2230 | test MSE: 0.2479\n",
            "\n",
            "Start Month 7\n",
            "\n",
            "Start training Model 1\n",
            "Epoch:  1 | trainig loss: 0.3215 | test MSE: 0.1603\n",
            "Epoch:  2 | trainig loss: 0.3124 | test MSE: 0.1665\n",
            "Epoch:  3 | trainig loss: 0.3043 | test MSE: 0.1712\n",
            "Epoch:  4 | trainig loss: 0.2966 | test MSE: 0.1741\n",
            "Epoch:  5 | trainig loss: 0.2889 | test MSE: 0.1755\n",
            "Epoch:  6 | trainig loss: 0.2813 | test MSE: 0.1759\n",
            "Epoch:  7 | trainig loss: 0.2737 | test MSE: 0.1756\n",
            "Epoch:  8 | trainig loss: 0.2662 | test MSE: 0.1753\n",
            "Epoch:  9 | trainig loss: 0.2590 | test MSE: 0.1752\n",
            "Epoch:  10 | trainig loss: 0.2519 | test MSE: 0.1757\n",
            "Epoch:  11 | trainig loss: 0.2449 | test MSE: 0.1768\n",
            "Epoch:  12 | trainig loss: 0.2381 | test MSE: 0.1785\n",
            "Epoch:  13 | trainig loss: 0.2314 | test MSE: 0.1809\n",
            "Epoch:  14 | trainig loss: 0.2247 | test MSE: 0.1838\n",
            "Epoch:  15 | trainig loss: 0.2183 | test MSE: 0.1869\n",
            "Epoch:  16 | trainig loss: 0.2119 | test MSE: 0.1900\n",
            "Epoch:  17 | trainig loss: 0.2057 | test MSE: 0.1930\n",
            "Epoch:  18 | trainig loss: 0.1997 | test MSE: 0.1956\n",
            "Epoch:  19 | trainig loss: 0.1938 | test MSE: 0.1977\n",
            "Epoch:  20 | trainig loss: 0.1880 | test MSE: 0.1993\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.3477 | test MSE: 0.1446\n",
            "Epoch:  2 | trainig loss: 0.3392 | test MSE: 0.1464\n",
            "Epoch:  3 | trainig loss: 0.3311 | test MSE: 0.1480\n",
            "Epoch:  4 | trainig loss: 0.3230 | test MSE: 0.1492\n",
            "Epoch:  5 | trainig loss: 0.3151 | test MSE: 0.1502\n",
            "Epoch:  6 | trainig loss: 0.3074 | test MSE: 0.1510\n",
            "Epoch:  7 | trainig loss: 0.2997 | test MSE: 0.1518\n",
            "Epoch:  8 | trainig loss: 0.2922 | test MSE: 0.1527\n",
            "Epoch:  9 | trainig loss: 0.2849 | test MSE: 0.1537\n",
            "Epoch:  10 | trainig loss: 0.2776 | test MSE: 0.1549\n",
            "Epoch:  11 | trainig loss: 0.2706 | test MSE: 0.1563\n",
            "Epoch:  12 | trainig loss: 0.2636 | test MSE: 0.1579\n",
            "Epoch:  13 | trainig loss: 0.2568 | test MSE: 0.1597\n",
            "Epoch:  14 | trainig loss: 0.2501 | test MSE: 0.1615\n",
            "Epoch:  15 | trainig loss: 0.2435 | test MSE: 0.1632\n",
            "Epoch:  16 | trainig loss: 0.2371 | test MSE: 0.1649\n",
            "Epoch:  17 | trainig loss: 0.2307 | test MSE: 0.1665\n",
            "Epoch:  18 | trainig loss: 0.2246 | test MSE: 0.1680\n",
            "Epoch:  19 | trainig loss: 0.2185 | test MSE: 0.1693\n",
            "Epoch:  20 | trainig loss: 0.2126 | test MSE: 0.1706\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.3315 | test MSE: 0.1471\n",
            "Epoch:  2 | trainig loss: 0.3180 | test MSE: 0.1564\n",
            "Epoch:  3 | trainig loss: 0.3081 | test MSE: 0.1670\n",
            "Epoch:  4 | trainig loss: 0.3008 | test MSE: 0.1772\n",
            "Epoch:  5 | trainig loss: 0.2949 | test MSE: 0.1855\n",
            "Epoch:  6 | trainig loss: 0.2896 | test MSE: 0.1913\n",
            "Epoch:  7 | trainig loss: 0.2840 | test MSE: 0.1945\n",
            "Epoch:  8 | trainig loss: 0.2781 | test MSE: 0.1954\n",
            "Epoch:  9 | trainig loss: 0.2718 | test MSE: 0.1945\n",
            "Epoch:  10 | trainig loss: 0.2652 | test MSE: 0.1924\n",
            "Epoch:  11 | trainig loss: 0.2587 | test MSE: 0.1897\n",
            "Epoch:  12 | trainig loss: 0.2523 | test MSE: 0.1867\n",
            "Epoch:  13 | trainig loss: 0.2462 | test MSE: 0.1841\n",
            "Epoch:  14 | trainig loss: 0.2404 | test MSE: 0.1819\n",
            "Epoch:  15 | trainig loss: 0.2349 | test MSE: 0.1805\n",
            "Epoch:  16 | trainig loss: 0.2296 | test MSE: 0.1800\n",
            "Epoch:  17 | trainig loss: 0.2243 | test MSE: 0.1804\n",
            "Epoch:  18 | trainig loss: 0.2191 | test MSE: 0.1818\n",
            "Epoch:  19 | trainig loss: 0.2138 | test MSE: 0.1840\n",
            "Epoch:  20 | trainig loss: 0.2085 | test MSE: 0.1870\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.3563 | test MSE: 0.1440\n",
            "Epoch:  2 | trainig loss: 0.3427 | test MSE: 0.1511\n",
            "Epoch:  3 | trainig loss: 0.3313 | test MSE: 0.1595\n",
            "Epoch:  4 | trainig loss: 0.3218 | test MSE: 0.1685\n",
            "Epoch:  5 | trainig loss: 0.3138 | test MSE: 0.1773\n",
            "Epoch:  6 | trainig loss: 0.3068 | test MSE: 0.1853\n",
            "Epoch:  7 | trainig loss: 0.3002 | test MSE: 0.1918\n",
            "Epoch:  8 | trainig loss: 0.2939 | test MSE: 0.1967\n",
            "Epoch:  9 | trainig loss: 0.2875 | test MSE: 0.1999\n",
            "Epoch:  10 | trainig loss: 0.2809 | test MSE: 0.2015\n",
            "Epoch:  11 | trainig loss: 0.2742 | test MSE: 0.2019\n",
            "Epoch:  12 | trainig loss: 0.2674 | test MSE: 0.2012\n",
            "Epoch:  13 | trainig loss: 0.2606 | test MSE: 0.1999\n",
            "Epoch:  14 | trainig loss: 0.2539 | test MSE: 0.1981\n",
            "Epoch:  15 | trainig loss: 0.2473 | test MSE: 0.1961\n",
            "Epoch:  16 | trainig loss: 0.2410 | test MSE: 0.1943\n",
            "Epoch:  17 | trainig loss: 0.2348 | test MSE: 0.1927\n",
            "Epoch:  18 | trainig loss: 0.2289 | test MSE: 0.1915\n",
            "Epoch:  19 | trainig loss: 0.2232 | test MSE: 0.1909\n",
            "Epoch:  20 | trainig loss: 0.2177 | test MSE: 0.1909\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.3054 | test MSE: 0.1670\n",
            "Epoch:  2 | trainig loss: 0.2951 | test MSE: 0.1593\n",
            "Epoch:  3 | trainig loss: 0.2871 | test MSE: 0.1544\n",
            "Epoch:  4 | trainig loss: 0.2804 | test MSE: 0.1519\n",
            "Epoch:  5 | trainig loss: 0.2743 | test MSE: 0.1511\n",
            "Epoch:  6 | trainig loss: 0.2682 | test MSE: 0.1517\n",
            "Epoch:  7 | trainig loss: 0.2620 | test MSE: 0.1533\n",
            "Epoch:  8 | trainig loss: 0.2556 | test MSE: 0.1558\n",
            "Epoch:  9 | trainig loss: 0.2491 | test MSE: 0.1590\n",
            "Epoch:  10 | trainig loss: 0.2427 | test MSE: 0.1628\n",
            "Epoch:  11 | trainig loss: 0.2365 | test MSE: 0.1669\n",
            "Epoch:  12 | trainig loss: 0.2305 | test MSE: 0.1711\n",
            "Epoch:  13 | trainig loss: 0.2247 | test MSE: 0.1750\n",
            "Epoch:  14 | trainig loss: 0.2191 | test MSE: 0.1784\n",
            "Epoch:  15 | trainig loss: 0.2136 | test MSE: 0.1811\n",
            "Epoch:  16 | trainig loss: 0.2081 | test MSE: 0.1830\n",
            "Epoch:  17 | trainig loss: 0.2027 | test MSE: 0.1842\n",
            "Epoch:  18 | trainig loss: 0.1974 | test MSE: 0.1848\n",
            "Epoch:  19 | trainig loss: 0.1921 | test MSE: 0.1850\n",
            "Epoch:  20 | trainig loss: 0.1869 | test MSE: 0.1849\n",
            "\n",
            "Start Month 8\n",
            "\n",
            "Start training Model 1\n",
            "Epoch:  1 | trainig loss: 0.3507 | test MSE: 0.0500\n",
            "Epoch:  2 | trainig loss: 0.3322 | test MSE: 0.0558\n",
            "Epoch:  3 | trainig loss: 0.3174 | test MSE: 0.0644\n",
            "Epoch:  4 | trainig loss: 0.3060 | test MSE: 0.0748\n",
            "Epoch:  5 | trainig loss: 0.2973 | test MSE: 0.0860\n",
            "Epoch:  6 | trainig loss: 0.2904 | test MSE: 0.0969\n",
            "Epoch:  7 | trainig loss: 0.2847 | test MSE: 0.1067\n",
            "Epoch:  8 | trainig loss: 0.2793 | test MSE: 0.1145\n",
            "Epoch:  9 | trainig loss: 0.2739 | test MSE: 0.1203\n",
            "Epoch:  10 | trainig loss: 0.2681 | test MSE: 0.1240\n",
            "Epoch:  11 | trainig loss: 0.2618 | test MSE: 0.1257\n",
            "Epoch:  12 | trainig loss: 0.2552 | test MSE: 0.1259\n",
            "Epoch:  13 | trainig loss: 0.2485 | test MSE: 0.1249\n",
            "Epoch:  14 | trainig loss: 0.2416 | test MSE: 0.1230\n",
            "Epoch:  15 | trainig loss: 0.2349 | test MSE: 0.1208\n",
            "Epoch:  16 | trainig loss: 0.2284 | test MSE: 0.1184\n",
            "Epoch:  17 | trainig loss: 0.2222 | test MSE: 0.1162\n",
            "Epoch:  18 | trainig loss: 0.2164 | test MSE: 0.1145\n",
            "Epoch:  19 | trainig loss: 0.2108 | test MSE: 0.1135\n",
            "Epoch:  20 | trainig loss: 0.2055 | test MSE: 0.1133\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.3831 | test MSE: 0.1462\n",
            "Epoch:  2 | trainig loss: 0.3696 | test MSE: 0.1398\n",
            "Epoch:  3 | trainig loss: 0.3572 | test MSE: 0.1343\n",
            "Epoch:  4 | trainig loss: 0.3459 | test MSE: 0.1298\n",
            "Epoch:  5 | trainig loss: 0.3355 | test MSE: 0.1263\n",
            "Epoch:  6 | trainig loss: 0.3258 | test MSE: 0.1240\n",
            "Epoch:  7 | trainig loss: 0.3167 | test MSE: 0.1228\n",
            "Epoch:  8 | trainig loss: 0.3080 | test MSE: 0.1227\n",
            "Epoch:  9 | trainig loss: 0.2995 | test MSE: 0.1238\n",
            "Epoch:  10 | trainig loss: 0.2912 | test MSE: 0.1259\n",
            "Epoch:  11 | trainig loss: 0.2830 | test MSE: 0.1289\n",
            "Epoch:  12 | trainig loss: 0.2749 | test MSE: 0.1329\n",
            "Epoch:  13 | trainig loss: 0.2669 | test MSE: 0.1377\n",
            "Epoch:  14 | trainig loss: 0.2589 | test MSE: 0.1432\n",
            "Epoch:  15 | trainig loss: 0.2511 | test MSE: 0.1494\n",
            "Epoch:  16 | trainig loss: 0.2435 | test MSE: 0.1561\n",
            "Epoch:  17 | trainig loss: 0.2360 | test MSE: 0.1632\n",
            "Epoch:  18 | trainig loss: 0.2288 | test MSE: 0.1706\n",
            "Epoch:  19 | trainig loss: 0.2217 | test MSE: 0.1781\n",
            "Epoch:  20 | trainig loss: 0.2149 | test MSE: 0.1856\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.3278 | test MSE: 0.0972\n",
            "Epoch:  2 | trainig loss: 0.3160 | test MSE: 0.1125\n",
            "Epoch:  3 | trainig loss: 0.3058 | test MSE: 0.1270\n",
            "Epoch:  4 | trainig loss: 0.2968 | test MSE: 0.1397\n",
            "Epoch:  5 | trainig loss: 0.2884 | test MSE: 0.1499\n",
            "Epoch:  6 | trainig loss: 0.2803 | test MSE: 0.1575\n",
            "Epoch:  7 | trainig loss: 0.2722 | test MSE: 0.1628\n",
            "Epoch:  8 | trainig loss: 0.2641 | test MSE: 0.1662\n",
            "Epoch:  9 | trainig loss: 0.2560 | test MSE: 0.1681\n",
            "Epoch:  10 | trainig loss: 0.2480 | test MSE: 0.1690\n",
            "Epoch:  11 | trainig loss: 0.2401 | test MSE: 0.1693\n",
            "Epoch:  12 | trainig loss: 0.2325 | test MSE: 0.1696\n",
            "Epoch:  13 | trainig loss: 0.2251 | test MSE: 0.1701\n",
            "Epoch:  14 | trainig loss: 0.2179 | test MSE: 0.1713\n",
            "Epoch:  15 | trainig loss: 0.2110 | test MSE: 0.1733\n",
            "Epoch:  16 | trainig loss: 0.2042 | test MSE: 0.1763\n",
            "Epoch:  17 | trainig loss: 0.1976 | test MSE: 0.1803\n",
            "Epoch:  18 | trainig loss: 0.1911 | test MSE: 0.1855\n",
            "Epoch:  19 | trainig loss: 0.1847 | test MSE: 0.1916\n",
            "Epoch:  20 | trainig loss: 0.1785 | test MSE: 0.1986\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.3103 | test MSE: 0.0860\n",
            "Epoch:  2 | trainig loss: 0.2991 | test MSE: 0.1006\n",
            "Epoch:  3 | trainig loss: 0.2896 | test MSE: 0.1137\n",
            "Epoch:  4 | trainig loss: 0.2809 | test MSE: 0.1243\n",
            "Epoch:  5 | trainig loss: 0.2724 | test MSE: 0.1322\n",
            "Epoch:  6 | trainig loss: 0.2639 | test MSE: 0.1379\n",
            "Epoch:  7 | trainig loss: 0.2554 | test MSE: 0.1419\n",
            "Epoch:  8 | trainig loss: 0.2469 | test MSE: 0.1449\n",
            "Epoch:  9 | trainig loss: 0.2387 | test MSE: 0.1475\n",
            "Epoch:  10 | trainig loss: 0.2306 | test MSE: 0.1502\n",
            "Epoch:  11 | trainig loss: 0.2229 | test MSE: 0.1534\n",
            "Epoch:  12 | trainig loss: 0.2154 | test MSE: 0.1577\n",
            "Epoch:  13 | trainig loss: 0.2081 | test MSE: 0.1631\n",
            "Epoch:  14 | trainig loss: 0.2009 | test MSE: 0.1699\n",
            "Epoch:  15 | trainig loss: 0.1939 | test MSE: 0.1779\n",
            "Epoch:  16 | trainig loss: 0.1871 | test MSE: 0.1871\n",
            "Epoch:  17 | trainig loss: 0.1804 | test MSE: 0.1971\n",
            "Epoch:  18 | trainig loss: 0.1739 | test MSE: 0.2077\n",
            "Epoch:  19 | trainig loss: 0.1676 | test MSE: 0.2184\n",
            "Epoch:  20 | trainig loss: 0.1615 | test MSE: 0.2288\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.3000 | test MSE: 0.1191\n",
            "Epoch:  2 | trainig loss: 0.2920 | test MSE: 0.1237\n",
            "Epoch:  3 | trainig loss: 0.2841 | test MSE: 0.1278\n",
            "Epoch:  4 | trainig loss: 0.2764 | test MSE: 0.1316\n",
            "Epoch:  5 | trainig loss: 0.2689 | test MSE: 0.1352\n",
            "Epoch:  6 | trainig loss: 0.2614 | test MSE: 0.1387\n",
            "Epoch:  7 | trainig loss: 0.2541 | test MSE: 0.1423\n",
            "Epoch:  8 | trainig loss: 0.2470 | test MSE: 0.1461\n",
            "Epoch:  9 | trainig loss: 0.2400 | test MSE: 0.1501\n",
            "Epoch:  10 | trainig loss: 0.2331 | test MSE: 0.1544\n",
            "Epoch:  11 | trainig loss: 0.2263 | test MSE: 0.1588\n",
            "Epoch:  12 | trainig loss: 0.2197 | test MSE: 0.1633\n",
            "Epoch:  13 | trainig loss: 0.2132 | test MSE: 0.1679\n",
            "Epoch:  14 | trainig loss: 0.2068 | test MSE: 0.1723\n",
            "Epoch:  15 | trainig loss: 0.2006 | test MSE: 0.1767\n",
            "Epoch:  16 | trainig loss: 0.1945 | test MSE: 0.1811\n",
            "Epoch:  17 | trainig loss: 0.1886 | test MSE: 0.1853\n",
            "Epoch:  18 | trainig loss: 0.1827 | test MSE: 0.1896\n",
            "Epoch:  19 | trainig loss: 0.1770 | test MSE: 0.1939\n",
            "Epoch:  20 | trainig loss: 0.1715 | test MSE: 0.1982\n",
            "\n",
            "Start Month 9\n",
            "\n",
            "Start training Model 1\n",
            "Epoch:  1 | trainig loss: 0.3384 | test MSE: 0.0597\n",
            "Epoch:  2 | trainig loss: 0.3293 | test MSE: 0.0651\n",
            "Epoch:  3 | trainig loss: 0.3208 | test MSE: 0.0692\n",
            "Epoch:  4 | trainig loss: 0.3126 | test MSE: 0.0721\n",
            "Epoch:  5 | trainig loss: 0.3045 | test MSE: 0.0739\n",
            "Epoch:  6 | trainig loss: 0.2965 | test MSE: 0.0751\n",
            "Epoch:  7 | trainig loss: 0.2885 | test MSE: 0.0758\n",
            "Epoch:  8 | trainig loss: 0.2807 | test MSE: 0.0764\n",
            "Epoch:  9 | trainig loss: 0.2730 | test MSE: 0.0771\n",
            "Epoch:  10 | trainig loss: 0.2655 | test MSE: 0.0780\n",
            "Epoch:  11 | trainig loss: 0.2582 | test MSE: 0.0793\n",
            "Epoch:  12 | trainig loss: 0.2510 | test MSE: 0.0810\n",
            "Epoch:  13 | trainig loss: 0.2439 | test MSE: 0.0832\n",
            "Epoch:  14 | trainig loss: 0.2369 | test MSE: 0.0859\n",
            "Epoch:  15 | trainig loss: 0.2301 | test MSE: 0.0890\n",
            "Epoch:  16 | trainig loss: 0.2234 | test MSE: 0.0923\n",
            "Epoch:  17 | trainig loss: 0.2169 | test MSE: 0.0958\n",
            "Epoch:  18 | trainig loss: 0.2105 | test MSE: 0.0992\n",
            "Epoch:  19 | trainig loss: 0.2042 | test MSE: 0.1026\n",
            "Epoch:  20 | trainig loss: 0.1981 | test MSE: 0.1057\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.3935 | test MSE: 0.0587\n",
            "Epoch:  2 | trainig loss: 0.3759 | test MSE: 0.0511\n",
            "Epoch:  3 | trainig loss: 0.3605 | test MSE: 0.0459\n",
            "Epoch:  4 | trainig loss: 0.3473 | test MSE: 0.0428\n",
            "Epoch:  5 | trainig loss: 0.3359 | test MSE: 0.0415\n",
            "Epoch:  6 | trainig loss: 0.3262 | test MSE: 0.0419\n",
            "Epoch:  7 | trainig loss: 0.3180 | test MSE: 0.0435\n",
            "Epoch:  8 | trainig loss: 0.3107 | test MSE: 0.0460\n",
            "Epoch:  9 | trainig loss: 0.3043 | test MSE: 0.0491\n",
            "Epoch:  10 | trainig loss: 0.2983 | test MSE: 0.0524\n",
            "Epoch:  11 | trainig loss: 0.2926 | test MSE: 0.0558\n",
            "Epoch:  12 | trainig loss: 0.2870 | test MSE: 0.0590\n",
            "Epoch:  13 | trainig loss: 0.2813 | test MSE: 0.0619\n",
            "Epoch:  14 | trainig loss: 0.2755 | test MSE: 0.0644\n",
            "Epoch:  15 | trainig loss: 0.2695 | test MSE: 0.0665\n",
            "Epoch:  16 | trainig loss: 0.2634 | test MSE: 0.0682\n",
            "Epoch:  17 | trainig loss: 0.2573 | test MSE: 0.0696\n",
            "Epoch:  18 | trainig loss: 0.2511 | test MSE: 0.0707\n",
            "Epoch:  19 | trainig loss: 0.2449 | test MSE: 0.0715\n",
            "Epoch:  20 | trainig loss: 0.2388 | test MSE: 0.0722\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.3235 | test MSE: 0.0410\n",
            "Epoch:  2 | trainig loss: 0.3149 | test MSE: 0.0431\n",
            "Epoch:  3 | trainig loss: 0.3069 | test MSE: 0.0451\n",
            "Epoch:  4 | trainig loss: 0.2991 | test MSE: 0.0470\n",
            "Epoch:  5 | trainig loss: 0.2914 | test MSE: 0.0485\n",
            "Epoch:  6 | trainig loss: 0.2839 | test MSE: 0.0498\n",
            "Epoch:  7 | trainig loss: 0.2764 | test MSE: 0.0509\n",
            "Epoch:  8 | trainig loss: 0.2690 | test MSE: 0.0519\n",
            "Epoch:  9 | trainig loss: 0.2617 | test MSE: 0.0530\n",
            "Epoch:  10 | trainig loss: 0.2547 | test MSE: 0.0542\n",
            "Epoch:  11 | trainig loss: 0.2477 | test MSE: 0.0557\n",
            "Epoch:  12 | trainig loss: 0.2409 | test MSE: 0.0574\n",
            "Epoch:  13 | trainig loss: 0.2342 | test MSE: 0.0595\n",
            "Epoch:  14 | trainig loss: 0.2276 | test MSE: 0.0618\n",
            "Epoch:  15 | trainig loss: 0.2212 | test MSE: 0.0644\n",
            "Epoch:  16 | trainig loss: 0.2149 | test MSE: 0.0673\n",
            "Epoch:  17 | trainig loss: 0.2087 | test MSE: 0.0702\n",
            "Epoch:  18 | trainig loss: 0.2026 | test MSE: 0.0732\n",
            "Epoch:  19 | trainig loss: 0.1967 | test MSE: 0.0762\n",
            "Epoch:  20 | trainig loss: 0.1909 | test MSE: 0.0790\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.3594 | test MSE: 0.0407\n",
            "Epoch:  2 | trainig loss: 0.3496 | test MSE: 0.0413\n",
            "Epoch:  3 | trainig loss: 0.3400 | test MSE: 0.0422\n",
            "Epoch:  4 | trainig loss: 0.3306 | test MSE: 0.0432\n",
            "Epoch:  5 | trainig loss: 0.3214 | test MSE: 0.0444\n",
            "Epoch:  6 | trainig loss: 0.3123 | test MSE: 0.0458\n",
            "Epoch:  7 | trainig loss: 0.3035 | test MSE: 0.0474\n",
            "Epoch:  8 | trainig loss: 0.2948 | test MSE: 0.0491\n",
            "Epoch:  9 | trainig loss: 0.2863 | test MSE: 0.0510\n",
            "Epoch:  10 | trainig loss: 0.2780 | test MSE: 0.0531\n",
            "Epoch:  11 | trainig loss: 0.2699 | test MSE: 0.0554\n",
            "Epoch:  12 | trainig loss: 0.2620 | test MSE: 0.0579\n",
            "Epoch:  13 | trainig loss: 0.2542 | test MSE: 0.0606\n",
            "Epoch:  14 | trainig loss: 0.2466 | test MSE: 0.0634\n",
            "Epoch:  15 | trainig loss: 0.2392 | test MSE: 0.0663\n",
            "Epoch:  16 | trainig loss: 0.2320 | test MSE: 0.0693\n",
            "Epoch:  17 | trainig loss: 0.2249 | test MSE: 0.0725\n",
            "Epoch:  18 | trainig loss: 0.2180 | test MSE: 0.0757\n",
            "Epoch:  19 | trainig loss: 0.2113 | test MSE: 0.0790\n",
            "Epoch:  20 | trainig loss: 0.2048 | test MSE: 0.0823\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.3492 | test MSE: 0.1076\n",
            "Epoch:  2 | trainig loss: 0.3393 | test MSE: 0.1139\n",
            "Epoch:  3 | trainig loss: 0.3296 | test MSE: 0.1182\n",
            "Epoch:  4 | trainig loss: 0.3201 | test MSE: 0.1211\n",
            "Epoch:  5 | trainig loss: 0.3108 | test MSE: 0.1235\n",
            "Epoch:  6 | trainig loss: 0.3016 | test MSE: 0.1259\n",
            "Epoch:  7 | trainig loss: 0.2927 | test MSE: 0.1288\n",
            "Epoch:  8 | trainig loss: 0.2839 | test MSE: 0.1324\n",
            "Epoch:  9 | trainig loss: 0.2753 | test MSE: 0.1368\n",
            "Epoch:  10 | trainig loss: 0.2669 | test MSE: 0.1418\n",
            "Epoch:  11 | trainig loss: 0.2587 | test MSE: 0.1471\n",
            "Epoch:  12 | trainig loss: 0.2506 | test MSE: 0.1525\n",
            "Epoch:  13 | trainig loss: 0.2428 | test MSE: 0.1576\n",
            "Epoch:  14 | trainig loss: 0.2351 | test MSE: 0.1624\n",
            "Epoch:  15 | trainig loss: 0.2276 | test MSE: 0.1667\n",
            "Epoch:  16 | trainig loss: 0.2203 | test MSE: 0.1708\n",
            "Epoch:  17 | trainig loss: 0.2131 | test MSE: 0.1747\n",
            "Epoch:  18 | trainig loss: 0.2061 | test MSE: 0.1788\n",
            "Epoch:  19 | trainig loss: 0.1993 | test MSE: 0.1831\n",
            "Epoch:  20 | trainig loss: 0.1927 | test MSE: 0.1877\n",
            "\n",
            "Start Month 10\n",
            "\n",
            "Start training Model 1\n",
            "Epoch:  1 | trainig loss: 0.4614 | test MSE: 0.0995\n",
            "Epoch:  2 | trainig loss: 0.4470 | test MSE: 0.0966\n",
            "Epoch:  3 | trainig loss: 0.4346 | test MSE: 0.0963\n",
            "Epoch:  4 | trainig loss: 0.4236 | test MSE: 0.0979\n",
            "Epoch:  5 | trainig loss: 0.4137 | test MSE: 0.1006\n",
            "Epoch:  6 | trainig loss: 0.4043 | test MSE: 0.1038\n",
            "Epoch:  7 | trainig loss: 0.3952 | test MSE: 0.1070\n",
            "Epoch:  8 | trainig loss: 0.3861 | test MSE: 0.1099\n",
            "Epoch:  9 | trainig loss: 0.3770 | test MSE: 0.1124\n",
            "Epoch:  10 | trainig loss: 0.3679 | test MSE: 0.1146\n",
            "Epoch:  11 | trainig loss: 0.3589 | test MSE: 0.1165\n",
            "Epoch:  12 | trainig loss: 0.3501 | test MSE: 0.1182\n",
            "Epoch:  13 | trainig loss: 0.3414 | test MSE: 0.1198\n",
            "Epoch:  14 | trainig loss: 0.3330 | test MSE: 0.1216\n",
            "Epoch:  15 | trainig loss: 0.3249 | test MSE: 0.1235\n",
            "Epoch:  16 | trainig loss: 0.3170 | test MSE: 0.1257\n",
            "Epoch:  17 | trainig loss: 0.3093 | test MSE: 0.1283\n",
            "Epoch:  18 | trainig loss: 0.3018 | test MSE: 0.1314\n",
            "Epoch:  19 | trainig loss: 0.2945 | test MSE: 0.1350\n",
            "Epoch:  20 | trainig loss: 0.2873 | test MSE: 0.1391\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.4431 | test MSE: 0.0957\n",
            "Epoch:  2 | trainig loss: 0.4339 | test MSE: 0.0953\n",
            "Epoch:  3 | trainig loss: 0.4253 | test MSE: 0.0958\n",
            "Epoch:  4 | trainig loss: 0.4173 | test MSE: 0.0967\n",
            "Epoch:  5 | trainig loss: 0.4096 | test MSE: 0.0979\n",
            "Epoch:  6 | trainig loss: 0.4020 | test MSE: 0.0990\n",
            "Epoch:  7 | trainig loss: 0.3945 | test MSE: 0.1001\n",
            "Epoch:  8 | trainig loss: 0.3870 | test MSE: 0.1010\n",
            "Epoch:  9 | trainig loss: 0.3796 | test MSE: 0.1018\n",
            "Epoch:  10 | trainig loss: 0.3723 | test MSE: 0.1025\n",
            "Epoch:  11 | trainig loss: 0.3651 | test MSE: 0.1032\n",
            "Epoch:  12 | trainig loss: 0.3580 | test MSE: 0.1040\n",
            "Epoch:  13 | trainig loss: 0.3511 | test MSE: 0.1048\n",
            "Epoch:  14 | trainig loss: 0.3442 | test MSE: 0.1059\n",
            "Epoch:  15 | trainig loss: 0.3375 | test MSE: 0.1072\n",
            "Epoch:  16 | trainig loss: 0.3309 | test MSE: 0.1087\n",
            "Epoch:  17 | trainig loss: 0.3244 | test MSE: 0.1105\n",
            "Epoch:  18 | trainig loss: 0.3179 | test MSE: 0.1126\n",
            "Epoch:  19 | trainig loss: 0.3116 | test MSE: 0.1150\n",
            "Epoch:  20 | trainig loss: 0.3053 | test MSE: 0.1176\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.4379 | test MSE: 0.1074\n",
            "Epoch:  2 | trainig loss: 0.4269 | test MSE: 0.1065\n",
            "Epoch:  3 | trainig loss: 0.4166 | test MSE: 0.1065\n",
            "Epoch:  4 | trainig loss: 0.4069 | test MSE: 0.1073\n",
            "Epoch:  5 | trainig loss: 0.3974 | test MSE: 0.1089\n",
            "Epoch:  6 | trainig loss: 0.3881 | test MSE: 0.1112\n",
            "Epoch:  7 | trainig loss: 0.3789 | test MSE: 0.1144\n",
            "Epoch:  8 | trainig loss: 0.3699 | test MSE: 0.1181\n",
            "Epoch:  9 | trainig loss: 0.3609 | test MSE: 0.1225\n",
            "Epoch:  10 | trainig loss: 0.3522 | test MSE: 0.1273\n",
            "Epoch:  11 | trainig loss: 0.3437 | test MSE: 0.1324\n",
            "Epoch:  12 | trainig loss: 0.3353 | test MSE: 0.1376\n",
            "Epoch:  13 | trainig loss: 0.3272 | test MSE: 0.1426\n",
            "Epoch:  14 | trainig loss: 0.3192 | test MSE: 0.1474\n",
            "Epoch:  15 | trainig loss: 0.3114 | test MSE: 0.1519\n",
            "Epoch:  16 | trainig loss: 0.3038 | test MSE: 0.1561\n",
            "Epoch:  17 | trainig loss: 0.2963 | test MSE: 0.1600\n",
            "Epoch:  18 | trainig loss: 0.2889 | test MSE: 0.1637\n",
            "Epoch:  19 | trainig loss: 0.2817 | test MSE: 0.1674\n",
            "Epoch:  20 | trainig loss: 0.2747 | test MSE: 0.1711\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.4427 | test MSE: 0.0983\n",
            "Epoch:  2 | trainig loss: 0.4339 | test MSE: 0.0979\n",
            "Epoch:  3 | trainig loss: 0.4253 | test MSE: 0.0979\n",
            "Epoch:  4 | trainig loss: 0.4170 | test MSE: 0.0980\n",
            "Epoch:  5 | trainig loss: 0.4087 | test MSE: 0.0983\n",
            "Epoch:  6 | trainig loss: 0.4006 | test MSE: 0.0986\n",
            "Epoch:  7 | trainig loss: 0.3926 | test MSE: 0.0991\n",
            "Epoch:  8 | trainig loss: 0.3847 | test MSE: 0.0996\n",
            "Epoch:  9 | trainig loss: 0.3769 | test MSE: 0.1003\n",
            "Epoch:  10 | trainig loss: 0.3693 | test MSE: 0.1012\n",
            "Epoch:  11 | trainig loss: 0.3618 | test MSE: 0.1023\n",
            "Epoch:  12 | trainig loss: 0.3545 | test MSE: 0.1037\n",
            "Epoch:  13 | trainig loss: 0.3472 | test MSE: 0.1052\n",
            "Epoch:  14 | trainig loss: 0.3401 | test MSE: 0.1070\n",
            "Epoch:  15 | trainig loss: 0.3331 | test MSE: 0.1089\n",
            "Epoch:  16 | trainig loss: 0.3262 | test MSE: 0.1108\n",
            "Epoch:  17 | trainig loss: 0.3194 | test MSE: 0.1128\n",
            "Epoch:  18 | trainig loss: 0.3127 | test MSE: 0.1148\n",
            "Epoch:  19 | trainig loss: 0.3062 | test MSE: 0.1168\n",
            "Epoch:  20 | trainig loss: 0.2998 | test MSE: 0.1188\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.4549 | test MSE: 0.1065\n",
            "Epoch:  2 | trainig loss: 0.4420 | test MSE: 0.1008\n",
            "Epoch:  3 | trainig loss: 0.4329 | test MSE: 0.0980\n",
            "Epoch:  4 | trainig loss: 0.4260 | test MSE: 0.0968\n",
            "Epoch:  5 | trainig loss: 0.4198 | test MSE: 0.0967\n",
            "Epoch:  6 | trainig loss: 0.4134 | test MSE: 0.0972\n",
            "Epoch:  7 | trainig loss: 0.4065 | test MSE: 0.0984\n",
            "Epoch:  8 | trainig loss: 0.3992 | test MSE: 0.1002\n",
            "Epoch:  9 | trainig loss: 0.3918 | test MSE: 0.1028\n",
            "Epoch:  10 | trainig loss: 0.3844 | test MSE: 0.1060\n",
            "Epoch:  11 | trainig loss: 0.3774 | test MSE: 0.1097\n",
            "Epoch:  12 | trainig loss: 0.3706 | test MSE: 0.1137\n",
            "Epoch:  13 | trainig loss: 0.3641 | test MSE: 0.1174\n",
            "Epoch:  14 | trainig loss: 0.3578 | test MSE: 0.1208\n",
            "Epoch:  15 | trainig loss: 0.3515 | test MSE: 0.1235\n",
            "Epoch:  16 | trainig loss: 0.3452 | test MSE: 0.1255\n",
            "Epoch:  17 | trainig loss: 0.3388 | test MSE: 0.1269\n",
            "Epoch:  18 | trainig loss: 0.3325 | test MSE: 0.1278\n",
            "Epoch:  19 | trainig loss: 0.3262 | test MSE: 0.1285\n",
            "Epoch:  20 | trainig loss: 0.3200 | test MSE: 0.1290\n",
            "\n",
            "Start Month 11\n",
            "\n",
            "Start training Model 1\n",
            "Epoch:  1 | trainig loss: 0.5881 | test MSE: 0.2919\n",
            "Epoch:  2 | trainig loss: 0.5745 | test MSE: 0.3041\n",
            "Epoch:  3 | trainig loss: 0.5626 | test MSE: 0.3157\n",
            "Epoch:  4 | trainig loss: 0.5521 | test MSE: 0.3259\n",
            "Epoch:  5 | trainig loss: 0.5428 | test MSE: 0.3343\n",
            "Epoch:  6 | trainig loss: 0.5343 | test MSE: 0.3407\n",
            "Epoch:  7 | trainig loss: 0.5262 | test MSE: 0.3448\n",
            "Epoch:  8 | trainig loss: 0.5182 | test MSE: 0.3466\n",
            "Epoch:  9 | trainig loss: 0.5103 | test MSE: 0.3465\n",
            "Epoch:  10 | trainig loss: 0.5023 | test MSE: 0.3446\n",
            "Epoch:  11 | trainig loss: 0.4942 | test MSE: 0.3413\n",
            "Epoch:  12 | trainig loss: 0.4860 | test MSE: 0.3370\n",
            "Epoch:  13 | trainig loss: 0.4779 | test MSE: 0.3320\n",
            "Epoch:  14 | trainig loss: 0.4697 | test MSE: 0.3267\n",
            "Epoch:  15 | trainig loss: 0.4617 | test MSE: 0.3213\n",
            "Epoch:  16 | trainig loss: 0.4539 | test MSE: 0.3161\n",
            "Epoch:  17 | trainig loss: 0.4462 | test MSE: 0.3112\n",
            "Epoch:  18 | trainig loss: 0.4386 | test MSE: 0.3069\n",
            "Epoch:  19 | trainig loss: 0.4312 | test MSE: 0.3032\n",
            "Epoch:  20 | trainig loss: 0.4240 | test MSE: 0.3002\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.5996 | test MSE: 0.2362\n",
            "Epoch:  2 | trainig loss: 0.5771 | test MSE: 0.2462\n",
            "Epoch:  3 | trainig loss: 0.5584 | test MSE: 0.2576\n",
            "Epoch:  4 | trainig loss: 0.5433 | test MSE: 0.2699\n",
            "Epoch:  5 | trainig loss: 0.5314 | test MSE: 0.2824\n",
            "Epoch:  6 | trainig loss: 0.5221 | test MSE: 0.2942\n",
            "Epoch:  7 | trainig loss: 0.5149 | test MSE: 0.3046\n",
            "Epoch:  8 | trainig loss: 0.5089 | test MSE: 0.3129\n",
            "Epoch:  9 | trainig loss: 0.5036 | test MSE: 0.3189\n",
            "Epoch:  10 | trainig loss: 0.4983 | test MSE: 0.3222\n",
            "Epoch:  11 | trainig loss: 0.4927 | test MSE: 0.3232\n",
            "Epoch:  12 | trainig loss: 0.4866 | test MSE: 0.3220\n",
            "Epoch:  13 | trainig loss: 0.4800 | test MSE: 0.3190\n",
            "Epoch:  14 | trainig loss: 0.4729 | test MSE: 0.3147\n",
            "Epoch:  15 | trainig loss: 0.4655 | test MSE: 0.3095\n",
            "Epoch:  16 | trainig loss: 0.4579 | test MSE: 0.3037\n",
            "Epoch:  17 | trainig loss: 0.4504 | test MSE: 0.2977\n",
            "Epoch:  18 | trainig loss: 0.4431 | test MSE: 0.2918\n",
            "Epoch:  19 | trainig loss: 0.4360 | test MSE: 0.2862\n",
            "Epoch:  20 | trainig loss: 0.4293 | test MSE: 0.2812\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.6066 | test MSE: 0.3469\n",
            "Epoch:  2 | trainig loss: 0.5960 | test MSE: 0.3325\n",
            "Epoch:  3 | trainig loss: 0.5862 | test MSE: 0.3206\n",
            "Epoch:  4 | trainig loss: 0.5769 | test MSE: 0.3111\n",
            "Epoch:  5 | trainig loss: 0.5681 | test MSE: 0.3037\n",
            "Epoch:  6 | trainig loss: 0.5596 | test MSE: 0.2982\n",
            "Epoch:  7 | trainig loss: 0.5511 | test MSE: 0.2943\n",
            "Epoch:  8 | trainig loss: 0.5427 | test MSE: 0.2917\n",
            "Epoch:  9 | trainig loss: 0.5343 | test MSE: 0.2901\n",
            "Epoch:  10 | trainig loss: 0.5260 | test MSE: 0.2893\n",
            "Epoch:  11 | trainig loss: 0.5177 | test MSE: 0.2891\n",
            "Epoch:  12 | trainig loss: 0.5095 | test MSE: 0.2891\n",
            "Epoch:  13 | trainig loss: 0.5014 | test MSE: 0.2894\n",
            "Epoch:  14 | trainig loss: 0.4935 | test MSE: 0.2896\n",
            "Epoch:  15 | trainig loss: 0.4856 | test MSE: 0.2896\n",
            "Epoch:  16 | trainig loss: 0.4779 | test MSE: 0.2894\n",
            "Epoch:  17 | trainig loss: 0.4702 | test MSE: 0.2888\n",
            "Epoch:  18 | trainig loss: 0.4627 | test MSE: 0.2878\n",
            "Epoch:  19 | trainig loss: 0.4552 | test MSE: 0.2864\n",
            "Epoch:  20 | trainig loss: 0.4478 | test MSE: 0.2847\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.6410 | test MSE: 0.2396\n",
            "Epoch:  2 | trainig loss: 0.6204 | test MSE: 0.2504\n",
            "Epoch:  3 | trainig loss: 0.6029 | test MSE: 0.2623\n",
            "Epoch:  4 | trainig loss: 0.5885 | test MSE: 0.2747\n",
            "Epoch:  5 | trainig loss: 0.5766 | test MSE: 0.2868\n",
            "Epoch:  6 | trainig loss: 0.5668 | test MSE: 0.2980\n",
            "Epoch:  7 | trainig loss: 0.5586 | test MSE: 0.3074\n",
            "Epoch:  8 | trainig loss: 0.5514 | test MSE: 0.3148\n",
            "Epoch:  9 | trainig loss: 0.5446 | test MSE: 0.3197\n",
            "Epoch:  10 | trainig loss: 0.5379 | test MSE: 0.3222\n",
            "Epoch:  11 | trainig loss: 0.5310 | test MSE: 0.3223\n",
            "Epoch:  12 | trainig loss: 0.5237 | test MSE: 0.3205\n",
            "Epoch:  13 | trainig loss: 0.5162 | test MSE: 0.3171\n",
            "Epoch:  14 | trainig loss: 0.5084 | test MSE: 0.3123\n",
            "Epoch:  15 | trainig loss: 0.5004 | test MSE: 0.3067\n",
            "Epoch:  16 | trainig loss: 0.4923 | test MSE: 0.3005\n",
            "Epoch:  17 | trainig loss: 0.4843 | test MSE: 0.2942\n",
            "Epoch:  18 | trainig loss: 0.4764 | test MSE: 0.2879\n",
            "Epoch:  19 | trainig loss: 0.4687 | test MSE: 0.2820\n",
            "Epoch:  20 | trainig loss: 0.4613 | test MSE: 0.2765\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.6277 | test MSE: 0.3077\n",
            "Epoch:  2 | trainig loss: 0.6083 | test MSE: 0.3207\n",
            "Epoch:  3 | trainig loss: 0.5915 | test MSE: 0.3329\n",
            "Epoch:  4 | trainig loss: 0.5768 | test MSE: 0.3436\n",
            "Epoch:  5 | trainig loss: 0.5639 | test MSE: 0.3523\n",
            "Epoch:  6 | trainig loss: 0.5522 | test MSE: 0.3585\n",
            "Epoch:  7 | trainig loss: 0.5414 | test MSE: 0.3619\n",
            "Epoch:  8 | trainig loss: 0.5309 | test MSE: 0.3626\n",
            "Epoch:  9 | trainig loss: 0.5206 | test MSE: 0.3608\n",
            "Epoch:  10 | trainig loss: 0.5103 | test MSE: 0.3569\n",
            "Epoch:  11 | trainig loss: 0.4999 | test MSE: 0.3513\n",
            "Epoch:  12 | trainig loss: 0.4894 | test MSE: 0.3444\n",
            "Epoch:  13 | trainig loss: 0.4789 | test MSE: 0.3368\n",
            "Epoch:  14 | trainig loss: 0.4685 | test MSE: 0.3289\n",
            "Epoch:  15 | trainig loss: 0.4582 | test MSE: 0.3209\n",
            "Epoch:  16 | trainig loss: 0.4482 | test MSE: 0.3133\n",
            "Epoch:  17 | trainig loss: 0.4384 | test MSE: 0.3062\n",
            "Epoch:  18 | trainig loss: 0.4290 | test MSE: 0.2999\n",
            "Epoch:  19 | trainig loss: 0.4198 | test MSE: 0.2944\n",
            "Epoch:  20 | trainig loss: 0.4108 | test MSE: 0.2897\n",
            "\n",
            "Start Month 12\n",
            "\n",
            "Start training Model 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([7])) that is different to the input size (torch.Size([7, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 | trainig loss: 0.5421 | test MSE: 0.2947\n",
            "Epoch:  2 | trainig loss: 0.5165 | test MSE: 0.3156\n",
            "Epoch:  3 | trainig loss: 0.4967 | test MSE: 0.3391\n",
            "Epoch:  4 | trainig loss: 0.4820 | test MSE: 0.3637\n",
            "Epoch:  5 | trainig loss: 0.4716 | test MSE: 0.3872\n",
            "Epoch:  6 | trainig loss: 0.4644 | test MSE: 0.4076\n",
            "Epoch:  7 | trainig loss: 0.4590 | test MSE: 0.4234\n",
            "Epoch:  8 | trainig loss: 0.4542 | test MSE: 0.4339\n",
            "Epoch:  9 | trainig loss: 0.4492 | test MSE: 0.4389\n",
            "Epoch:  10 | trainig loss: 0.4435 | test MSE: 0.4389\n",
            "Epoch:  11 | trainig loss: 0.4369 | test MSE: 0.4349\n",
            "Epoch:  12 | trainig loss: 0.4296 | test MSE: 0.4277\n",
            "Epoch:  13 | trainig loss: 0.4219 | test MSE: 0.4184\n",
            "Epoch:  14 | trainig loss: 0.4141 | test MSE: 0.4079\n",
            "Epoch:  15 | trainig loss: 0.4063 | test MSE: 0.3971\n",
            "Epoch:  16 | trainig loss: 0.3990 | test MSE: 0.3867\n",
            "Epoch:  17 | trainig loss: 0.3921 | test MSE: 0.3771\n",
            "Epoch:  18 | trainig loss: 0.3856 | test MSE: 0.3689\n",
            "Epoch:  19 | trainig loss: 0.3796 | test MSE: 0.3621\n",
            "Epoch:  20 | trainig loss: 0.3739 | test MSE: 0.3571\n",
            "\n",
            "Start training Model 2\n",
            "Epoch:  1 | trainig loss: 0.5066 | test MSE: 0.3144\n",
            "Epoch:  2 | trainig loss: 0.4902 | test MSE: 0.3350\n",
            "Epoch:  3 | trainig loss: 0.4789 | test MSE: 0.3549\n",
            "Epoch:  4 | trainig loss: 0.4712 | test MSE: 0.3710\n",
            "Epoch:  5 | trainig loss: 0.4655 | test MSE: 0.3814\n",
            "Epoch:  6 | trainig loss: 0.4601 | test MSE: 0.3857\n",
            "Epoch:  7 | trainig loss: 0.4541 | test MSE: 0.3847\n",
            "Epoch:  8 | trainig loss: 0.4473 | test MSE: 0.3798\n",
            "Epoch:  9 | trainig loss: 0.4399 | test MSE: 0.3724\n",
            "Epoch:  10 | trainig loss: 0.4323 | test MSE: 0.3636\n",
            "Epoch:  11 | trainig loss: 0.4249 | test MSE: 0.3547\n",
            "Epoch:  12 | trainig loss: 0.4179 | test MSE: 0.3464\n",
            "Epoch:  13 | trainig loss: 0.4114 | test MSE: 0.3394\n",
            "Epoch:  14 | trainig loss: 0.4053 | test MSE: 0.3341\n",
            "Epoch:  15 | trainig loss: 0.3993 | test MSE: 0.3306\n",
            "Epoch:  16 | trainig loss: 0.3934 | test MSE: 0.3289\n",
            "Epoch:  17 | trainig loss: 0.3874 | test MSE: 0.3289\n",
            "Epoch:  18 | trainig loss: 0.3813 | test MSE: 0.3303\n",
            "Epoch:  19 | trainig loss: 0.3751 | test MSE: 0.3329\n",
            "Epoch:  20 | trainig loss: 0.3689 | test MSE: 0.3363\n",
            "\n",
            "Start training Model 3\n",
            "Epoch:  1 | trainig loss: 0.5016 | test MSE: 0.3938\n",
            "Epoch:  2 | trainig loss: 0.4924 | test MSE: 0.4075\n",
            "Epoch:  3 | trainig loss: 0.4843 | test MSE: 0.4181\n",
            "Epoch:  4 | trainig loss: 0.4770 | test MSE: 0.4254\n",
            "Epoch:  5 | trainig loss: 0.4700 | test MSE: 0.4291\n",
            "Epoch:  6 | trainig loss: 0.4631 | test MSE: 0.4298\n",
            "Epoch:  7 | trainig loss: 0.4561 | test MSE: 0.4280\n",
            "Epoch:  8 | trainig loss: 0.4491 | test MSE: 0.4244\n",
            "Epoch:  9 | trainig loss: 0.4421 | test MSE: 0.4196\n",
            "Epoch:  10 | trainig loss: 0.4351 | test MSE: 0.4144\n",
            "Epoch:  11 | trainig loss: 0.4283 | test MSE: 0.4091\n",
            "Epoch:  12 | trainig loss: 0.4215 | test MSE: 0.4043\n",
            "Epoch:  13 | trainig loss: 0.4149 | test MSE: 0.4002\n",
            "Epoch:  14 | trainig loss: 0.4084 | test MSE: 0.3971\n",
            "Epoch:  15 | trainig loss: 0.4020 | test MSE: 0.3949\n",
            "Epoch:  16 | trainig loss: 0.3957 | test MSE: 0.3938\n",
            "Epoch:  17 | trainig loss: 0.3893 | test MSE: 0.3936\n",
            "Epoch:  18 | trainig loss: 0.3831 | test MSE: 0.3941\n",
            "Epoch:  19 | trainig loss: 0.3769 | test MSE: 0.3951\n",
            "Epoch:  20 | trainig loss: 0.3707 | test MSE: 0.3963\n",
            "\n",
            "Start training Model 4\n",
            "Epoch:  1 | trainig loss: 0.5202 | test MSE: 0.3937\n",
            "Epoch:  2 | trainig loss: 0.5075 | test MSE: 0.4013\n",
            "Epoch:  3 | trainig loss: 0.4956 | test MSE: 0.4079\n",
            "Epoch:  4 | trainig loss: 0.4845 | test MSE: 0.4133\n",
            "Epoch:  5 | trainig loss: 0.4738 | test MSE: 0.4175\n",
            "Epoch:  6 | trainig loss: 0.4636 | test MSE: 0.4202\n",
            "Epoch:  7 | trainig loss: 0.4538 | test MSE: 0.4214\n",
            "Epoch:  8 | trainig loss: 0.4441 | test MSE: 0.4214\n",
            "Epoch:  9 | trainig loss: 0.4347 | test MSE: 0.4200\n",
            "Epoch:  10 | trainig loss: 0.4254 | test MSE: 0.4177\n",
            "Epoch:  11 | trainig loss: 0.4162 | test MSE: 0.4145\n",
            "Epoch:  12 | trainig loss: 0.4072 | test MSE: 0.4107\n",
            "Epoch:  13 | trainig loss: 0.3983 | test MSE: 0.4065\n",
            "Epoch:  14 | trainig loss: 0.3896 | test MSE: 0.4021\n",
            "Epoch:  15 | trainig loss: 0.3811 | test MSE: 0.3977\n",
            "Epoch:  16 | trainig loss: 0.3728 | test MSE: 0.3935\n",
            "Epoch:  17 | trainig loss: 0.3648 | test MSE: 0.3896\n",
            "Epoch:  18 | trainig loss: 0.3569 | test MSE: 0.3861\n",
            "Epoch:  19 | trainig loss: 0.3491 | test MSE: 0.3831\n",
            "Epoch:  20 | trainig loss: 0.3416 | test MSE: 0.3806\n",
            "\n",
            "Start training Model 5\n",
            "Epoch:  1 | trainig loss: 0.5266 | test MSE: 0.3692\n",
            "Epoch:  2 | trainig loss: 0.5153 | test MSE: 0.3807\n",
            "Epoch:  3 | trainig loss: 0.5053 | test MSE: 0.3906\n",
            "Epoch:  4 | trainig loss: 0.4963 | test MSE: 0.3984\n",
            "Epoch:  5 | trainig loss: 0.4881 | test MSE: 0.4037\n",
            "Epoch:  6 | trainig loss: 0.4802 | test MSE: 0.4065\n",
            "Epoch:  7 | trainig loss: 0.4724 | test MSE: 0.4069\n",
            "Epoch:  8 | trainig loss: 0.4646 | test MSE: 0.4053\n",
            "Epoch:  9 | trainig loss: 0.4568 | test MSE: 0.4020\n",
            "Epoch:  10 | trainig loss: 0.4490 | test MSE: 0.3977\n",
            "Epoch:  11 | trainig loss: 0.4412 | test MSE: 0.3926\n",
            "Epoch:  12 | trainig loss: 0.4335 | test MSE: 0.3873\n",
            "Epoch:  13 | trainig loss: 0.4259 | test MSE: 0.3820\n",
            "Epoch:  14 | trainig loss: 0.4186 | test MSE: 0.3771\n",
            "Epoch:  15 | trainig loss: 0.4114 | test MSE: 0.3728\n",
            "Epoch:  16 | trainig loss: 0.4043 | test MSE: 0.3692\n",
            "Epoch:  17 | trainig loss: 0.3974 | test MSE: 0.3664\n",
            "Epoch:  18 | trainig loss: 0.3906 | test MSE: 0.3644\n",
            "Epoch:  19 | trainig loss: 0.3839 | test MSE: 0.3632\n",
            "Epoch:  20 | trainig loss: 0.3772 | test MSE: 0.3626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "month_list = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"Jan\"]\n",
        "\n",
        "print(\"CNN test MSEs by month:\")\n",
        "for i in range(len(test_mse_by_month)):\n",
        "  print(\"Use global SSTAs in\", month_list[i], \"to predict Bay of Plenty SSTAs in\", month_list[i+1])\n",
        "  print(\"MSE =\", np.round(test_mse_by_month[i], decimals=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3bwdP-4YXmk",
        "outputId": "e510c99c-1838-42db-e803-9bd338b47cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN test MSEs by month:\n",
            "Use global SSTAs in Jan to predict Bay of Plenty SSTAs in Feb\n",
            "MSE = 0.537\n",
            "Use global SSTAs in Feb to predict Bay of Plenty SSTAs in Mar\n",
            "MSE = 0.2721\n",
            "Use global SSTAs in Mar to predict Bay of Plenty SSTAs in Apr\n",
            "MSE = 0.0982\n",
            "Use global SSTAs in Apr to predict Bay of Plenty SSTAs in May\n",
            "MSE = 0.1302\n",
            "Use global SSTAs in May to predict Bay of Plenty SSTAs in Jun\n",
            "MSE = 0.2982\n",
            "Use global SSTAs in Jun to predict Bay of Plenty SSTAs in Jul\n",
            "MSE = 0.2436\n",
            "Use global SSTAs in Jul to predict Bay of Plenty SSTAs in Aug\n",
            "MSE = 0.1866\n",
            "Use global SSTAs in Aug to predict Bay of Plenty SSTAs in Sep\n",
            "MSE = 0.1849\n",
            "Use global SSTAs in Sep to predict Bay of Plenty SSTAs in Oct\n",
            "MSE = 0.1054\n",
            "Use global SSTAs in Oct to predict Bay of Plenty SSTAs in Nov\n",
            "MSE = 0.1351\n",
            "Use global SSTAs in Nov to predict Bay of Plenty SSTAs in Dec\n",
            "MSE = 0.2865\n",
            "Use global SSTAs in Dec to predict Bay of Plenty SSTAs in Jan\n",
            "MSE = 0.3666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------"
      ],
      "metadata": {
        "id": "HCDQyizxM1oJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4cpX9evJM0y1",
        "outputId": "e9a33eb0-ef96-456f-9e77-6d786dfc9cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t_HJ-7ZMZyg",
        "outputId": "30d0d35a-faa7-41e6-8442-5b102110b40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (59.5.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 740 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=be14049e48715aae1519cb871c4506649473702d79bc5743ae4c35afdbf29c00\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5rCfc-mVB8q",
        "outputId": "59fa68bb-9cbc-4255-a618-171720a365d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (747 kB)\n",
            "\u001b[K     |████████████████████████████████| 747 kB 3.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data\n",
        "from torch_geometric.data import Data"
      ],
      "metadata": {
        "id": "Org99MFYVccM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_layer_by_name = {\n",
        "    \"GCN\": geom_nn.GCNConv,\n",
        "    \"GAT\": geom_nn.GATConv,\n",
        "    \"GraphConv\": geom_nn.GraphConv\n",
        "}"
      ],
      "metadata": {
        "id": "ynCyClznVrQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lead_month = 1\n",
        "\n",
        "label_vector = soda_sst_bop_anomaly[lead_month:]\n",
        "\n",
        "feature_matrix_tensor = torch.from_numpy(feature_matrix[:,:-lead_month]).to(torch.float)\n",
        "adjacency_matrix_tensor = torch.from_numpy(adjacency_matrix).to(torch.float)\n",
        "label_vector_tensor = torch.from_numpy(label_vector).to(torch.float)"
      ],
      "metadata": {
        "id": "LEFAoCjIXVlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = torch.tensor(adjacency_matrix).nonzero(as_tuple=False)"
      ],
      "metadata": {
        "id": "k6wk_CgSlhB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Data(x=feature_matrix_tensor, edge_index=edges, num_nodes=feature_matrix.shape[0], y=label_vector_tensor)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzS6B-ZMWikI",
        "outputId": "55dea271-439b-4504-9bf1-9203f4a027e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[6924, 431], edge_index=[47941776, 2], y=[431], num_nodes=6924)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GCN\", dp_rate=0.1, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of the output features. Usually number of classes in classification\n",
        "            num_layers - Number of \"hidden\" graph layers\n",
        "            layer_name - String of the graph layer to use\n",
        "            dp_rate - Dropout rate to apply throughout the network\n",
        "            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        gnn_layer = gnn_layer_by_name[layer_name]\n",
        "\n",
        "        layers = []\n",
        "        in_channels, out_channels = c_in, c_hidden\n",
        "        for l_idx in range(num_layers-1):\n",
        "            layers += [\n",
        "                gnn_layer(in_channels=in_channels,\n",
        "                          out_channels=out_channels,\n",
        "                          **kwargs),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dp_rate)\n",
        "            ]\n",
        "            in_channels = c_hidden\n",
        "        layers += [gnn_layer(in_channels=in_channels,\n",
        "                             out_channels=c_out,\n",
        "                             **kwargs)]\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "        \"\"\"\n",
        "        for l in self.layers:\n",
        "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
        "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
        "            # we can simply check the class type.\n",
        "            if isinstance(l, geom_nn.MessagePassing):\n",
        "                x = l(x, edge_index)\n",
        "            else:\n",
        "                x = l(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3WZnwVReOuNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NodeLevelGNN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model_name, **model_kwargs):\n",
        "        super().__init__()\n",
        "        # Saving hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        if model_name == \"MLP\":\n",
        "            self.model = MLPModel(**model_kwargs)\n",
        "        else:\n",
        "            self.model = GNNModel(**model_kwargs)\n",
        "        self.loss_module = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.model(x, edge_index)\n",
        "\n",
        "        # Only calculate the loss on the nodes corresponding to the mask\n",
        "        if mode == \"train\":\n",
        "            mask = data.train_mask\n",
        "        elif mode == \"val\":\n",
        "            mask = data.val_mask\n",
        "        elif mode == \"test\":\n",
        "            mask = data.test_mask\n",
        "        else:\n",
        "            assert False, f\"Unknown forward mode: {mode}\"\n",
        "\n",
        "        loss = self.loss_module(x[mask], data.y[mask])\n",
        "        acc = (x[mask].argmax(dim=-1) == data.y[mask]).sum().float() / mask.sum()\n",
        "        return loss, acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # We use SGD here, but Adam works as well\n",
        "        optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-3)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self.forward(batch, mode=\"train\")\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"val\")\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"test\")\n",
        "        self.log('test_acc', acc)"
      ],
      "metadata": {
        "id": "sSldjyD1bi7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_node_classifier(model_name, dataset, **model_kwargs):\n",
        "    pl.seed_everything(42)\n",
        "    node_data_loader = geom_data.DataLoader(dataset, batch_size=1)\n",
        "\n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    root_dir = os.path.join(CHECKPOINT_PATH, \"NodeLevel\" + model_name)\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
        "                         gpus=1 if str(device).startswith(\"cuda\") else 0,\n",
        "                         max_epochs=200,\n",
        "                         progress_bar_refresh_rate=0) # 0 because epoch size is 1\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"NodeLevel{model_name}.ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(\"Found pretrained model, loading...\")\n",
        "        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything()\n",
        "        model = NodeLevelGNN(model_name=model_name, c_in=dataset.num_node_features, c_out=dataset.num_classes, **model_kwargs)\n",
        "        trainer.fit(model, node_data_loader, node_data_loader)\n",
        "        model = NodeLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "\n",
        "    # Test best model on the test set\n",
        "    test_result = trainer.test(model, test_dataloaders=node_data_loader, verbose=False)\n",
        "    batch = next(iter(node_data_loader))\n",
        "    batch = batch.to(model.device)\n",
        "    _, train_acc = model.forward(batch, mode=\"train\")\n",
        "    _, val_acc = model.forward(batch, mode=\"val\")\n",
        "    result = {\"train\": train_acc,\n",
        "              \"val\": val_acc,\n",
        "              \"test\": test_result[0]['test_acc']}\n",
        "    return model, result"
      ],
      "metadata": {
        "id": "fvI8kjQqbo0k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}